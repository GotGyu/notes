# 数据结构

1. **红黑树**

   插入删除时间复杂度：O(1)

   平衡指每条路上的黑色节点

   自平衡的二叉搜索树，为了解决有序数据退化成链表的问题

   插入删除要左旋右旋

   **相比AVL树**：

   - 插入/删除需要的旋转操作更少
   - 查询稍慢但仍在O(log n)
   - 更适合频繁修改的场景


# 操作系统

1. **操作系统都有哪些结构**

   - 内核、shell、文件系统，形成了基本的操作系统结构

   - 结构种类：微内核、宏内核

2. **用户态与内核态**

   | 特性           | 用户态             | 内核态               |
   | :------------- | :----------------- | :------------------- |
   | **权限级别**   | Ring 3(受限)       | Ring 0(完全权限)     |
   | **内存访问**   | 只能访问用户空间   | 可访问全部内存空间   |
   | **指令集**     | 受限指令集         | 可执行特权指令       |
   | **稳定性影响** | 崩溃只影响当前进程 | 崩溃导致整个系统崩溃 |

   **用户态→内核态** 触发场景：

   1. 系统调用(如 `read`/`write`)
   2. 硬件中断(如时钟中断)
   3. 异常(如缺页异常)

   **内核态→用户态** 触发场景：

   1. 系统调用返回
   2. 中断处理完成
   3. 任务调度切换回用户进程

   ```assembly
   ; 示例汇编代码
   ; 系统调用进入内核态
   mov eax, 1    ; 系统调用号
   mov ebx, arg1 ; 参数
   int 0x80      ; 软中断触发切换
   
   ; 内核返回用户态
   iret          ; 中断返回指令
   ```

3. 关键系统调用

   进程管理

   | 系统调用 | 作用       | 内核函数                   |
   | :------- | :--------- | :------------------------- |
   | fork     | 创建子进程 | kernel/fork.c:_do_fork()   |
   | clone    | 创建线程   | kernel/fork.c:sys_clone () |
   | execve   | 执行程序   | fs/exec.c:do_execve ()     |
   | exit     | 终止进程   | kernel/exit.c:do_exit ()   |

   文件操作

   | 系统调用 | 作用     | 内核路径                    |
   | :------- | :------- | :-------------------------- |
   | openat   | 打开文件 | fs/open.c:do_sys_openat2 () |
   | close    | 关闭文件 | fs/file.c:__close_fd()      |
   | mmap     | 内存映射 | mm/mmap.c:do_mmap ()        |
   | fsync    | 强制刷盘 | fs/sync.c:do_fsync ()       |

   内存管理

   | 系统调用 | 作用         | 内核路径                      |
   | :------- | :----------- | :---------------------------- |
   | brk      | 调整堆大小   | mm/mmap.c:sys_brk ()          |
   | madvise  | 内存使用建议 | mm/madvise.c:sys_madvise ()   |
   | mprotect | 修改内存保护 | mm/mprotect.c:sys_mprotect () |

   网络通信

   | 系统调用 | 作用       | 内核路径                    |
   | :------- | :--------- | :-------------------------- |
   | socket   | 创建套接字 | net/socket.c:sys_socket ()  |
   | connect  | 建立连接   | net/socket.c:sys_connect () |
   | sendmsg  | 发送数据   | net/socket.c:sys_sendmsg () |

   特殊机制

   | 系统调用 | 作用           | 内核路径                      |
   | :------- | :------------- | :---------------------------- |
   | ioctl    | 设备控制       | fs/ioctl.c:sys_ioctl ()       |
   | ptrace   | 进程调试       | kernel/ptrace.c:sys_ptrace () |
   | futex    | 快速用户态互斥 | kernel/futex.c:sys_futex ()   |

4. **对OS整体理解**

   关键设计思想：

   - **抽象**：进程、文件、socket 等抽象屏蔽硬件细节
   - **隔离**：通过虚拟化（CPU/内存/设备）实现多任务安全
   - **并发控制**：锁、RCU、无锁数据结构等
   - **性能优化**：缓存（页缓存、inode 缓存）、预读、异步 I/O

5. **发生系统调用时，内核发生了什么？**

   1. 用户态发起系统调用，触发软中断
   2. 进入内核态：
      - CPU切换到内核栈、保存用户态寄存器、根据终端号查找系统调用入口
      - 系统调用号在x86通过 `eax` 寄存器传递
   3. 系统调用分发
   4. 内核处理，将用户态的数据复制到内核态
   5. 数据拷贝
      - 检查用户缓冲区可写（`access_ok()`）
      - 内核通过 `copy_to_user()`/`copy_from_user()` 与用户空间交换数据
   6. 返回用户态
      - 恢复保存的寄存器
      - 执行 `iret` 指令
      - CPU 切换回用户栈，继续执行下条指令

## 进程管理 SCHED

1. **操作系统进程切换过程**

   - 触发切换：
     - 时间片用完 -> 系统调用阻塞 ->更高优先级进程就绪 -> 硬件中断
   - 切换流程：
     - 保存当前进程上下文（用户寄存器、栈指针、程序计数器、状态寄存器、MMU）
     - 更新内核数据结构（将当前进程状态保存到PCB，将进程移入适当队列）
     - 选择新进程（调度算法选择下一个进程）
     - 恢复新进程上下文（加载新进程的寄存器、更新MMU、恢复栈指针、设置程序计数器）
     - 刷新TLB和CPU缓存

2. **进程、线程、协程的区别**

   | **特性**     | **进程**                                      | **线程**                                         | **协程**                                     |
   | :----------- | :-------------------------------------------- | :----------------------------------------------- | :------------------------------------------- |
   | **定义**     | OS资源分配的基本单位，独立内存空间            | 程序执行的最小单位，共享进程内存                 | 用户态轻量级线程，由程序控制调度             |
   | **资源占用** | 高（独立内存、文件句柄等）                    | 中（共享进程内存，但需内核调度）                 | 极低（通常KB级栈内存，无内核切换）           |
   | **切换开销** | 高（需切换虚拟地址空间、内核态介入）          | 中（需内核调度，但共享内存）                     | 极低（用户态切换，无内核介入）               |
   | **并发性**   | 多进程并行（依赖多核）                        | 多线程并行（依赖多核）                           | 单线程内高并发（适合I/O密集型）              |
   | **通信方式** | 管道、消息队列、共享内存、信号等（借助OS）    | 直接（读写进程数据段，需同步机制）               | 直接共享变量（无需同步）                     |
   | **调度者**   | 操作系统内核                                  | 操作系统内核                                     | 用户程序（如事件循环）                       |
   | **独立性**   | 完全独立（崩溃不影响其他进程）                | 共享进程资源（一个线程崩溃可能导致整个进程退出） | 完全共享（协程崩溃可能影响同线程内其他协程） |
   | **适用场景** | CPU密集型、需要隔离的任务（如浏览器多标签页） | CPU密集型、需要并行的任务（如计算任务拆分）      | I/O密集型、高并发任务（如网络爬虫、微服务）  |
   | **创销开销** | 高                                            | 中                                               | 极低                                         |
   | **典型实现** | `fork()`                                      | POSIX的`pthread`、C++的`std::thread`             | C++20的`coroutine`, Rust 的 `tokio`          |

3. **Linux 时间片分配机制**

   - **分配对象**：

     - 现代Linux(CFS调度器)主要按**任务**(task)分配
     - 包含线程和传统进程，每个线程有独立的时间片

   - **CFS调度器特点**：

     - 不固定时间片长度
     - 基于"虚拟运行时间"(vruntime)分配CPU
     - 权重机制(nice值影响分配比例)
     - 目标：公平性(而非均等时间)

   - **计算公式**：

     ```
     时间片 = (调度周期 * 任务权重) / 所有运行队列任务权重总和   # 调度周期通常20ms
     ```

   - **特殊场景**：

     - 实时进程(RT)优先于普通进程
     - CPU绑定任务有独立队列

   

## 内存管理 MM

1. **为进程分配内存的过程**

   当为进程分配内存时，如 `mmap` 和 `malloc`，OS首先为其分配虚拟内存，在进程真正访问相应内存时通过缺页中断机制为其分配真正的物理内存，并通过页表建立虚拟内存到物理内存的映射

2. **虚拟内存**

   - **是什么？**
     - OS 提供的抽象层，使得每个进程拥有独立的地址空间，与物理内存分离，核心机制：
       - **地址转换**：通过MMU将虚拟地址转为物理地址
       - **分页管理**：内存被划分为固定大小的页（通常4KB）
       - **按需加载**：只有实际使用的页才会占用物理内存
   - **为什么要用？**
     - 解决物理内存不足的问题，为多个进程提供足够的内存空间
     - 隔离不同进程的访问权限，提高系统的安全性
     - 可以为进程提供独立的内存空间并引入多层的页表结构将虚拟内存翻译成物理内存，进程之间可以共享物理内存减少开销，也能简化程序的链接装载以及内存分配过程
   - **优缺点？**
     - **优点**：
       - 进程隔离（一个进程崩溃不影响其他进程）
       - 更大的地址空间（超过物理内存限制）
       - 内存共享（动态库、进程间通信）
       - 高效的物理内存管理（按需分页、页面置换）
     - **缺点**：
       - 地址转换开销（需要TLB加速）
       - 页面置换可能引起抖动（thrashing）
       - 实现复杂度高
   - **怎么实现？**

3. **虚拟内存、分页、页表的组织形式**

   - **地址转换**：CPU 的 MMU 通过页表将虚拟地址 → 物理地址
   - **分页**：内存被划分为固定大小的页（通常 4KB）
   - **页表层级**（以 x86-64 四级页表为例）
   - 缺页异常处理流程
     - CPU 触发缺页异常（Page Fault）
     - 内核调用 `do_page_fault()`
     - 检查地址合法性（是否在 vma 区域内）
     - 若合法：
       - 文件映射：从磁盘读取数据到内存页（`filemap_fault()`）
       - 匿名页：分配新物理页并清零
     - 更新页表项，重新执行指令

4. **介绍 `mmap` 和 `munmap` **

   这两个是用于**内存映射**的系统调用，用于将文件或设备映射到进程的地址空间，或者申请匿名内存

   - `mmap`

     - 用于将 **文件、设备** 或 **匿名内存** 映射到进程的虚拟地址空间，使其可以像操作内存一样访问文件内容，提高 I/O 性能。此外，也可用于 **分配大块内存**，替代 `malloc`

     - `mmap` 映射成功，返回映射的 **虚拟地址指针**；失败则返回 `MAP_FAILED` 并设置 `errno`

     - 参数中的 `flags` 可以控制映射方式，如共享映射、私有映射、匿名映射等

     - 应用场景：

       - 大文件高效访问（避免 `read()` 和 `write()` 的拷贝开销）
       - 匿名共享内存（IPC）
       - 动态库加载（如 `ld.so` 使用 `mmap` 加载 `.so` 文件）

     - 和 `malloc` 的比较

       | 特性     | `mmap`                                        | `malloc`                  |
       | -------- | --------------------------------------------- | ------------------------- |
       | 内存来源 | 直接从 **虚拟内存（内核管理）** 分配          | 由 **堆（heap）** 管理    |
       | 内存大小 | 适用于 **大块内存**                           | 适用于 **小块内存**       |
       | 释放方式 | 需要手动 `munmap`                             | `free()` 自动释放         |
       | 性能     | **减少 `malloc`/`free` 开销**，大数据量下更快 | 适用于 **小对象频繁分配** |

   - `munmap`

     - 用于解除 `mmap` 创建的映射，释放映射的虚拟内存区域。若不 `munmap`，映射区域会 **持续占用虚拟地址空间**，直到进程终止

5. `brk()` 系统调用

   - 被 glibc 进一步封装为 `malloc` 接口，申请的用户空间属于堆空间
   - 在申请的空间较小时会用这个函数

## 网络接口 net

1. **NIO（同步非阻塞IO）和BIO（同步阻塞IO）**

   - BIO
     - 当进程调用 `read()`/`write()` 等系统调用时，如果数据未就绪，进程被放入等待队列，进入 **TASK_INTERRUPTIBLE** 状态
     - 当数据到达或缓冲区可写时，内核通过中断处理程序**唤醒**等待队列中的进程
     - **优点**：实现简单，CPU 利用率高（进程睡眠时不占用 CPU）
     - **缺点**：每个连接需要一个线程/进程，高并发时资源消耗大
   - NIO
     - 系统调用不阻塞，调用立即返回，需轮询检查状态
     - **优点**：单线程可处理多个连接
     - **缺点**：需要轮询检查状态，CPU 利用率低（忙等待问题）

2. **I/O多路复用**

   - 核心特点
     - **事件驱动**：内核通知就绪事件，避免轮询，在事件检测时会阻塞
     - **多路分离**：单线程监控多个文件描述符
     - **高性能**：支撑高并发连接的关键技术
   - 主要实现有 select, poll, epoll

3. **关于 epoll**

   - **是什么：**

     - Linux 特有的 I/O 事件通知机制，为解决Linux内核处理大量文件描述符而提出的方案
     - 属于Linux下多路I/O复用接口中 select/poll 的增强，用于监控多个fd上的I/O事件
     - 属于边缘触发(ET)或水平触发(LT)的就绪通知系统

   - 工作流程：

     ```
     应用线程 → epoll_create创建实例 → epoll_ctl添加监控 → epoll_wait等待事件
                ↑
     内核 → 数据就绪 → 回调加入就绪队列 → 通知应用
     ```

   - **设计思路：**

     - epoll 在 Linux 内核中构建了一个文件系统，它采用红黑树构建，效率超高，其中存储所有监控的文件描述符
     - 使用一个就绪链表存储有事件发生的文件描述符
     - 当监控的文件描述符就绪时，内核通过回调函数将其加入就绪链表
     - 用户空间和内核空间共享就绪列表内存，减少数据拷贝
     - 边缘触发（ET）模式，旨在状态变化时通知

   ```c
   #define MAX_EVENTS 10
   
   int main() {
       struct epoll_event ev, events[MAX_EVENTS];
       int listen_sock, conn_sock, nfds, epollfd;
       
       // 创建epoll实例
       epollfd = epoll_create1(0);
       
       // 添加监听socket
       ev.events = EPOLLIN;
       ev.data.fd = listen_sock;
       epoll_ctl(epollfd, EPOLL_CTL_ADD, listen_sock, &ev);
       
       for(;;) {
           // 等待事件(无限等待)
           nfds = epoll_wait(epollfd, events, MAX_EVENTS, -1);
           
           for(int i = 0; i < nfds; i++) {
               if(events[i].data.fd == listen_sock) {
                   // 处理新连接
                   conn_sock = accept(listen_sock, NULL, NULL);
                   ev.events = EPOLLIN | EPOLLET; // 边缘触发
                   ev.data.fd = conn_sock;
                   epoll_ctl(epollfd, EPOLL_CTL_ADD, conn_sock, &ev);
               } else {
                   // 处理客户端数据
                   handle_client(events[i].data.fd);
               }
           }
       }
   }
   ```

   - **相对其他I/O多路复用的优势？**

   | 特性               | select/poll                | epoll                          |
   | :----------------- | :------------------------- | :----------------------------- |
   | **时间复杂度**     | O(n) 每次线性扫描          | O(1) 只返回就绪描述符          |
   | **描述符数量限制** | 有限制(通常1024)           | 仅受系统内存限制               |
   | **工作模式**       | 水平触发(LT)               | 支持边缘触发(ET)和水平触发(LT) |
   | **内核数据结构**   | 每次调用传递完整描述符集合 | 内核维护红黑树                 |
   | **内存拷贝**       | 每次需要拷贝到内核空间     | 使用mmap共享内存               |
   | **适用场景**       | 少量连接                   | 万级并发连接                   |

   - 应用场景
     - 高并发网络服务器(Nginx, Redis)
     - 实时事件处理系统
     - 高性能代理服务器
     - 大规模连接的游戏服务器

4. **单线程+IO多路复用 vs 多线程**

   | 特性           | 单线程+IO多路复用(epoll)     | 多线程模型                         |
   | :------------- | :--------------------------- | :--------------------------------- |
   | **资源消耗**   | 内存占用少(单进程)           | 每个线程需要独立栈空间(通常2-10MB) |
   | **上下文切换** | 无线程切换开销               | 需要频繁线程上下文切换             |
   | **CPU利用率**  | 适合IO密集型                 | 适合CPU密集型                      |
   | **编程复杂度** | 回调/异步编程较复杂          | 同步编程更直观                     |
   | **扩展性**     | 受限于单核性能               | 可充分利用多核                     |
   | **典型实现**   | select/poll/epoll (Linux)    | pthread/std::thread                |
   | **适用场景**   | 高并发网络服务(Nginx, Redis) | 计算密集型任务                     |

## 虚拟文件系统 VFS

1. **`cat` 读取文件，OS是怎么处理的？**

   - **系统调用入口**：

     ```
     SYSCALL_DEFINE3(read, unsigned int, fd, char __user *, buf, size_t, count)
     ```

   - **关键调用栈**：

     ```
     read() → ksys_read() → vfs_read() → file->f_op->read_iter() → ext4_file_read_iter() → generic_file_read_iter() → filemap_read()
     ```

   - **页缓存交互**：

     - 检查文件页是否已在页缓存（`address_space`）

     - 若不存在，触发缺页异常：

       ```
       do_page_fault() → handle_mm_fault() → __handle_mm_fault() → ...
       ```

   - **磁盘I/O触发**：

     ```
     // fs/ext4/inode.c
     static int ext4_readpage(struct file *file, struct page *page) {
         // 提交bio请求到块设备层
         submit_bio_wait(REQ_OP_READ, bio);
     }
     ```

2. **怎么检测到 `cat` 二进制文件，用什么命令执行？**（不懂）

   1. 解析ELF头部
   2. 建立新的地址空间
   3. 加载程序段（.text, .data）
   4. 设置动态链接器路径
   5. 初始化栈（环境变量、参数）

   用 `exec` 执行

3. **怎么找到文件在磁盘上的位置**

   - **EXT4文件系统示例**：

     - 三步定位：块组 → inode → 数据块

     - 计算公式：

       ```
       块组 = (inode号 - 1) / 每块组inode数
       inode表偏移 = (inode号 - 1) % 每块组inode数
       ```

   - **实际磁盘寻址**：

     ```
     LBA = (块号 * 块大小) / 扇区大小
     ```

     通过`hdparm --fibmap file`可查看文件物理块号

4. **读写系统调用的过程**

   - `read()`

     1. 用户空间：

        ```assembly
        mov eax, 0  ; SYS_read
        mov ebx, fd
        mov ecx, buf
        mov edx, count
        int 0x80
        ```

     2. 内核处理：

        ```
        read() → ksys_read() → vfs_read() → file->f_op->read()
                 ↓
        ext4_file_read_iter() → generic_file_read_iter() → filemap_read()
                 ↓
        submit_bio() → 块设备层 → SCSI/SATA/NVMe驱动
        ```

   - `write()`

     1. **写时复制（COW）**：

        ```c
        // mm/memory.c
        int do_wp_page(struct vm_fault *vmf)
        ```

     2. **延迟写入**：

        ```c
        // fs/ext4/inode.c
        static int ext4_da_write_begin() // 延迟分配块
        ```

     3. **回写线程**：

        ```
        pdflush → writeback_inodes() → do_writepages()
        ```

## 进程间通信 IPC

1. **进程间通信**（IPC）

   - 指在不同进程之间传递数据或信号的机制
   - **管道**
     
     - **半双工**通信：数据只能单向流动。
     - 只能在具有亲缘关系的进程之间使用（如父子进程）
     - 数据以字节流的形式传输。
     
     - 应用场景：
       - Linux命令是管道操作（比如 `ls | grep "txt"`）
       - 父子进程通信（一个进程的输出作为另一个进程的输入）
   - **命名管道**
     
     - 可以**全双工**通信：数据可以双向流动
     - 可以在无关进程之间使用
     - 通过文件系统中的命名管道文件进行通信
     
     - 应用场景：
       - 不同进程间的数据交换（如C/S模型）
       - 长期运行的进程通信（如日志收集）
   - **消息队列**
     
     - 通过消息队列传递结构化数据。
     - 消息可以按类型分类，支持优先级。
     - 消息队列独立于进程存在，进程终止后消息队列仍然存在。
   - **共享内存**
     
     - 多个进程共享同一块内存区域，无需内核介入
     - **通信速度最快**，但需要同步机制（如信号量）避免竞争
     - 和 `mmap` 的区别：数据来源是纯内存还是磁盘文件/是否可以持久化/同步机制是否依赖文件系统等，区别还是挺大的
   - **信号量**
     
     - 用于进程间的同步，控制对共享资源的访问。
     - 可以用于解决生产者-消费者问题。
   - **套接字socket**
     - 支持网络通信，可以在不同主机上的进程之间通信
     - 在UNIX中算是一种双向管道文件
     - 支持多种协议（如 TCP、UDP）

2. **线程同步的方式有哪些**

   | 机制         | 原理           | 适用场景           | 性能开销     |
   | :----------- | :------------- | :----------------- | :----------- |
   | **互斥锁**   | 二进制锁       | 临界区保护         | 中等         |
   | **自旋锁**   | 忙等待         | 短临界区、内核代码 | 高(消耗CPU)  |
   | **读写锁**   | 读共享/写独占  | 读多写少场景       | 中等         |
   | **条件变量** | 事件通知机制   | 生产者-消费者模型  | 低(无忙等待) |
   | **原子操作** | CPU指令级保证  | 计数器等简单操作   | 最低         |
   | **屏障**     | 线程集合同步点 | 并行计算阶段同步   | 高           |

3. **死锁**

   - 多个进程在运行过程中因争夺资源而造成的一种僵局
   - **死锁必要条件**
     - 互斥条件：资源独占使用
     - 占有并等待：持有资源同时请求新资源
     - 非抢占条件：资源只能自愿释放
     - 循环等待：存在请求环形链
   - **死锁预防的方法**
     - 破坏前面四个必要条件
   - **死锁避免的方法**
     - 银行家算法：预判分配是否安全
   - **死锁检测与恢复**
     - 资源分配图算法检测环路
     - 强制剥夺资源(牺牲进程)

4. **一个进程中有两个 thread，一个 thread 是否可以访问另一个 thread 栈上的内容？**

   - 可以，但需满足特定条件，实际要避免这种操作
   - 一个进程下是一个单独的地址空间，如果拿到栈指针就行，拿不到就不可以

   

# 计算机组成原理

1. **磁盘与物理内存发生交换的过程？**

   进程得到的x G虚拟内存在进程看来是一个连续的地址空间，但其实它的数据存储在多个物理内存碎片上，还有一大部分存储在外部磁盘上，在需要时将数据交换进物理内存

   虚拟内存与物理内存的联系：

   ![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/e8c4c5f3ba0ec9dfa521df224d1737e1.png)

2. **虚拟地址到物理地址的映射过程？**

   进程开始要访问一个地址，它可能会经历下面的过程：

   1. 进程每次要访问地址空间上的某一个地址时，都需要把地址翻译为实际物理内存地址
   2. 所有进程共享一整块物理内存，每个进程只把自己目前需要访问的虚拟地址空间映射到物理内存上
   3. 进程需要知道虚拟内存地址空间上的哪些数据在物理内存上，哪些在磁盘上，若在物理内存上，则需要进一步知道数据存储在物理内存上的具体位置，这都通过**页表**来记录
   4. 页表的每一个表项分两部分，第一部分记录此页是否在物理内存上，第二部分记录物理内存页的地址（如果在的话）
   5. 当进程访问某个虚拟地址的时候，就会先去看页表，如果发现对应的数据不在物理内存上，就会发生**缺页异常**
   6. 缺页异常的处理过程，操作系统立即阻塞该进程，**并将硬盘里对应的页换入内存**，然后使该进程就绪。如果内存已满，没有空位，则需找一个页覆盖，至于具体覆盖哪个页是根据OS的页面置换算法

3. **Linux中的匿名页是什么？**

   指的是**没有文件映射的内存页**，即进程直接通过 `malloc()`、`brk()`、`mmap(MAP_ANONYMOUS)` 等方式分配的私有内存，这些内存页不会直接与磁盘上的文件关联，而是仅存在于**物理内存或交换空间**中。

   匿名页的特点：

   - 不与文件系统关联：不像 `mmap()` 映射的文件页，匿名页不会与磁盘文件同步（也不会写回）
   - 通常存放堆、栈、全局变量等数据
   - 可以被 Swap 交换到磁盘，当物理内存不足时，匿名页可能会被写入 交换空间（swap），然后在需要时再加载回来

4. 32位的系统能访问4gb以上的内存吗？

   - 我答的不能 面试官说可以去查一下最新的Linux 【intel新的x86硬件PAE支持36寻址空间，但是多出来的部分是虚拟的地址空间，单个应用程序估计无法使用到超过4GB的空间(32为系统的最大int是4GB)，只能是多个进程合起来能够使用到4G以外的内存】

5. **知道的栈寄存器的名字**

   - eax, ebx, ecx, edx, esi, edi, ebp

# 计算机网络

**计算机网络模型（OSI模型）**

- 物理层：集线器、中继器、调制解调器
- 数据链路层：网桥、交换机
- 网络层：IP、ICMP、ARP、RARP、IPv6、NAT、路由器
- 传输层：TCP、UDP、（TLS/SSL）、网关
- 会话层
- 表示层
- 应用层：HTTP、HTTPS、FTP、SMTP、POP3、IMAP、DNS、SSH、SNMP、Telnet、

**TCP/IP模型和每层的作用**

- 物理层+数据链路层：管理同一局域网内设备间的数据帧传输，确保物理连接可靠
- 网络层：负责数据包的路由和寻址，实现主机间的逻辑通信
- 传输层：提供端到端的数据传输服务
- 应用层：直接位用户应用程序提供网络服务

## 网络层

1. **IP 协议概述**
   - 所有的TCP、UDP、ICMP数据都以IP数据报格式传输
   - IP在传输数据包时，将数据报文分为若干分片进行传输，并在目标系统中进行重组
   - 不同链路类型规定有不同最大长度的链路层数据帧，称为链路层MTU，常见的MTU=1500，若IP报文长度大于转发接口的MTU，则会将数据报文分为若干分片进行传输
   - 对于不同的传输层协议，在IP层上需不需要进行分片也是不同的：
     - **对于TCP，尽量避免分片。**因为当在IP层进行了分片后，如果其中的某片数据丢失，则需对整个数据报进行重传。避免分层的方法是，在3次握手时协商一个MSS值，用来表示本段所能接收的最大长度的报文段
     - **对于UDP而言可以分片。**
2. **IP分片可能出现的问题**

   - **性能消耗**：分片和重组会消耗发送方、接收方一定的CPU等资源，且分片对接收方内存资源的消耗较多
   - **丢包导致重传**：如果某个分片报文在网络传输过程中丢失，那么接收方将无法完成重组，如果应用进程要求重传的话，发送方必须重传所有分片报文而不是仅重传被丢弃的那个分片报文，这种效率低下的重传行为会给端系统和网络资源带来额外的消耗
   - **分片攻击**：黑客构造的分片报文，但是不向接收方发送最后一个分片报文，导致接收方要为所有的分片报文分配内存空间，可由于最后一个分片报文永远不会达到，接收方的内存得不到及时的释放（接收方会启动一个分片重组的定时器，在一定时间内如果无法完成重组，将向发送方发送ICMP重组超时差错报文，，只要这种攻击的分片报文发送的足够多、足够快，很容易占满接收方内存，让接收方无内存资源处理正常的业务，从而达到DOS的攻击效果
3. **NAT网络地址转换**
   - NAT路由器内部会维护一个NAT表，进行 `本地ip：端口`到 `外部网络ip：端口` 的映射

## 传输层

1. TCP报文的组成？

2. TCP的状态位有哪些？什么时候、具体什么事件会触发什么状态位？

3. TCP慢启动过程

4. TCP/IP三次握手

5. 重传机制(超时重传 快重传)

6. TCP拥塞控制算法、流量控制

7. **关于TCP协议和UDP协议**
   - 区别：
     - TCP：
       - 面向连接的、可靠的，确保数据包按顺序且无误地传送到接收方
       - 有流量控制、拥塞控制
     - UDP：
       - 无连接的、不可靠的，低延迟
       - 没有顺序保证或重传机制
       - 将数据分割成独立的数据报，带有一定信息，收到后再组装
       - 有简单的校验和机制
   - 应用场景：
     - TCP：适用于需要高可靠性和数据顺序保证的场景，如文件传输、电子邮件、远程登陆
     - UDP：适用于对传输速度要求较高、容忍一定数据丢失的场景，如视频流媒体、在线游戏、DNS查询
   - 在哪些协议中有用到：
     - TCP：[Telnet](https://zhida.zhihu.com/search?content_id=169112169&content_type=Article&match_order=1&q=Telnet&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDE5MzcwMDEsInEiOiJUZWxuZXQiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoxNjkxMTIxNjksImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.Gml07eGDbxa1jYaVJnEzfJtpRYWKdHsymc3SPDU94xM&zhida_source=entity)(远程登录)、[FTP](https://zhida.zhihu.com/search?content_id=169112169&content_type=Article&match_order=1&q=FTP&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDE5MzcwMDEsInEiOiJGVFAiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoxNjkxMTIxNjksImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.iHZkXQxdmu2OQ4OgzxCbFIqo7lwdSoapeMxibvKo0Xo&zhida_source=entity)(文件传输协议)、[SMTP](https://zhida.zhihu.com/search?content_id=169112169&content_type=Article&match_order=1&q=SMTP&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDE5MzcwMDEsInEiOiJTTVRQIiwiemhpZGFfc291cmNlIjoiZW50aXR5IiwiY29udGVudF9pZCI6MTY5MTEyMTY5LCJjb250ZW50X3R5cGUiOiJBcnRpY2xlIiwibWF0Y2hfb3JkZXIiOjEsInpkX3Rva2VuIjpudWxsfQ.il7Gezua-rDPO1Je3eM1wb_3lArMbaVGLPyPsi6jnEA&zhida_source=entity)(简单邮件传输协议)、HTTP、SSH
     - UDP：[NFS](https://zhida.zhihu.com/search?content_id=169112169&content_type=Article&match_order=1&q=NFS&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDE5MzcwMDEsInEiOiJORlMiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoxNjkxMTIxNjksImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9._c_EheLfLeqLCL7fHxg7bxrYl7FuQnmFpdW2wwzJESw&zhida_source=entity)(网络文件系统)、[SNMP](https://zhida.zhihu.com/search?content_id=169112169&content_type=Article&match_order=1&q=SNMP&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDE5MzcwMDEsInEiOiJTTk1QIiwiemhpZGFfc291cmNlIjoiZW50aXR5IiwiY29udGVudF9pZCI6MTY5MTEyMTY5LCJjb250ZW50X3R5cGUiOiJBcnRpY2xlIiwibWF0Y2hfb3JkZXIiOjEsInpkX3Rva2VuIjpudWxsfQ.rLg3eyWT43bqE6XZSqj5MXMOtt9Xq0Dm6O4pP7GmWcI&zhida_source=entity)(简单网络管理系统)、[DNS](https://zhida.zhihu.com/search?content_id=169112169&content_type=Article&match_order=1&q=DNS&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDE5MzcwMDEsInEiOiJETlMiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoxNjkxMTIxNjksImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9._FLGpV3NGLy7sTSLlD0qopQtufLfCx0RL-sm0rsgjrE&zhida_source=entity)(主域名称系统)、[TFTP](https://zhida.zhihu.com/search?content_id=169112169&content_type=Article&match_order=1&q=TFTP&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDE5MzcwMDEsInEiOiJURlRQIiwiemhpZGFfc291cmNlIjoiZW50aXR5IiwiY29udGVudF9pZCI6MTY5MTEyMTY5LCJjb250ZW50X3R5cGUiOiJBcnRpY2xlIiwibWF0Y2hfb3JkZXIiOjEsInpkX3Rva2VuIjpudWxsfQ.evs753NZcg7-JzU4J9zX8phKst5VHMRazegsuZKdJdY&zhida_source=entity)(通用文件传输协议)、NTP（网络时间协议）

8. **TCP三次握手详细描述，为什么要三次而不是两次**

   - 为了保证客户端和服务器端的可靠连接，TCP建立连接时**必须**要进行三次会话，也叫TCP三次握手，**目的是为了确认双方的接收能力和发送能力是否正常**

     ![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/850de5c566ae60989f45cff4b1aad94c.png)

   - 最开始的时候客户端和服务器都是处于CLOSED关闭状态。主动打开连接的为客户端，被动打开连接的是服务器

   - TCP服务器进程先创建传输控制块TCB，时刻准备接受客户进程的连接请求，此时服务器就进入了 LISTEN 监听状态

   - **第一次握手**TCP客户进程也是先创建传输控制块TCB，然后向服务器发出连接请求报文，这是报文首部中的同部位SYN=1，同时选择一个初始序列号 seq=x ，此时，TCP客户端进程进入了 SYN-SENT 同步已发送状态

   - **第二次握手**TCP服务器收到请求报文后，如果同意连接，则会向客户端发出确认报文。确认报文中应该 ACK=1，SYN=1，确认号是ack=x+1，同时也要为自己初始化一个序列号 seq=y，此时，TCP服务器进程进入了 SYN-RCVD 同步收到状态

   - **第三次握手**TCP客户端收到确认后，还要向服务器给出确认。确认报文的ACK=1，ack=y+1，自己的序列号seq=x+1，此时，TCP连接建立，客户端进入ESTABLISHED已建立连接状态 触发三次握手

   - **为什么要有第三次？**主要原因是，防止已经失效的连接请求报文突然又传送到了服务器，从而产生错误。举例而言：客户端向服务器端发送的请求报文由于网络等原因滞留，未能发送到服务器端，此时连接请求报文失效，客户端会再次向服务器端发送请求报文，之后与服务器端建立连接，当连接释放后，由于网络通畅了，第一次客户端发送的请求报文又突然到达了服务器端，这条请求报文本该失效了，但此时服务器端误认为客户端又发送了一次连接请求，两次握手建立好连接，此时客户端忽略服务器端发来的确认，也不发送数据，造成不必要的错误和网络资源的浪费。如果采用三次握手的话，就算那条失效的报文发送到服务器端，服务器端确认并向客户端发送报文，但此时客户端不会发出确认，由于客户端没有确认，由于服务器端没有接收到确认，就会知道客户端没有请求连接。

9. **TCP四次挥手详细描述**

   - 断开TCP连接需要四次挥手

     ![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/0dc25c2e6ae3de02cc4039553165d8cf.png)

   - 数据传输完毕后，双方都可释放连接。最开始的时候，客户端和服务器都是处于ESTABLISHED状态，然后客户端主动关闭，服务器被动关闭

   - **第一次挥手** 客户端发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态

   - **第二次挥手** 服务器端接收到连接释放报文后，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT 关闭等待状态

   - **第三次挥手** 客户端接收到服务器端的确认请求后，客户端就会进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文，服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认

   - **第四次挥手** 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态，但此时TCP连接还未终止，必须要经过2MSL后（最长报文寿命），当客户端撤销相应的TCB后，客户端才会进入CLOSED关闭状态，服务器端接收到确认报文后，会立即进入CLOSED关闭状态，到这里TCP连接就断开了，四次挥手完成

   - **为什么客户端要等待2MSL？**主要原因是为了保证客户端发送的第一个ACK报文能到服务器，因为这个ACK报文可能丢失，并且2MSL是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃，这样新的连接中不会出现旧连接的请求报文

10. TLS握手过程

11. 一个 TCP server 的进程崩溃后，客户端会怎么反应吗？

    - Linux 内核在进程崩溃前，会向它连接的客户端发送 FIN 报文

## 应用层

1. **http和https**

   - HTTP
     - 用于在web浏览器和服务器之间传递信息的协议
     - 默认工作在TCP80端口
     - 以明文方式发送内容，不提供加密
     - 页面响应更快、资源消耗更低
   - HTTPS
     - 由HTTP进行通信，利用SSL/TLS加密数据包
     - 主要用于身份认证、保护交换数据的隐私与完整性
     - 默认工作在TCP443端口
     - 需要到CA申请证书
     - https如何解决不安全问题、加密方式有哪些？
   - **浏览器进行http请求的时候包含哪些头部**
     - 通用头部：适用于请求和响应，提供与消息本身相关的信息
     - 请求头部：用于传递客户端的详细信息、请求的上下文以及期望的响应格式
     - 实体头部：用于描述请求或响应的主体内容
     - GET请求包含1,2
     - POST请求包含1,2,3
     - PUT请求包含1,2,3
     - DELETE请求包含1,2

2. socket通信过程、客户端需要Bind吗

3. HTTP头、几种请求方式、HTTPS原理、认证过程、HTTP 2.0、QUIC、50x错误意义

4. HTTP/1.1 的 Pipelining 和HTTP/2的多路复用的区别

5. 讲讲为什么用select不用epoll？epoll比select好在哪？

   （答数据结构不同：红黑树加双向链表vs数组；答内核态用户态切换开销不一样）

6. websocket和socket的关系和区别？websocket是七层中的哪一层？（答应用层，不知道对不对），为什么不用socket而用websocket？

7. websocket和http的关系和区别？（答websocket能双向传输信息）又问http不能双向传输信息没？为什么你搭建的服务器不用http？

## 场景题

1. **在浏览器地址栏输入一个URL后回车，背后会进行哪些技术步骤?**
   - 参考该链接：[经典面试题：在浏览器地址栏输入一个 URL 后回车，背后发生了什么-腾讯云开发者社区-腾讯云](https://cloud.tencent.com/developer/article/1793846)

   - DNS解析域名 -> IP地址
     - 搜索**浏览器的DNS缓存**，其中维护着一张域名与IP地址的对应表
     - 若没有命中，则继续搜索**操作系统的DNS缓存**
     - 若没有命中，则操作系统将域名发送至**本地域名服务器**，它查询自己的DNS缓存，成功则返回结果，此处是递归查询
     - 若没有命中，则本地域名服务器向上级域名服务器进行迭代查询，得到IP地址后返回给操作系统，同时将其放在缓存里：
       - 本地域名服务器向**根域名服务器**发起请求，根域名服务器是最高层次的，它并不会直接指明这个域名对应的 IP 地址，而是返回顶级域名服务器的地址，也就是说给本地域名服务器指明一条道路，让他去这里寻找答案
       - 本地域名服务器拿到这个**顶级域名服务器**的地址后，就向其发起请求，获取**权限域名服务器**的地址
       - 本地域名服务器根据权限域名服务器的地址向其发起请求，最终得到该域名对应的 IP 地址
     - 操作系统将IP地址返回给浏览器，同时也将其放在缓存里
     - DNS使用UDP协议，以上所有请求转发过程都是基于UDP
   - 建立TCP连接，发送封装好的HTTP请求报文
     - 先通过三次握手为浏览器和服务器之间建立可靠的连接
     - TCP 会将 HTTP 报文按序号分割成若干报文段并加上 TCP 首部，分别进行传输。接收方在收到这些报文段后，按照序号以原来的顺序重组 HTTP 报文
   - IP封装数据报
     - TCP在各阶段操作时，都是通过IP协议进行传输的，IP将数据添加IP首部封装成IP数据包再进行传输
     - IP数据报首部存有**源IP地址、目标IP地址**
   - ARP查询目的MAC地址
     - ARP协议将IP地址转化为MAC地址，每个主机都有一个ARP高速缓存，里面有本局域网上各主机和路由器的**IP地址到MAC地址的映射表**
   - 物理层在硬件之间传输
   - 服务器响应请求
     - 浏览器的 HTTP 请求报文通过 TCP 三次握手建立的连接通道被切分成若干报文段分别发送给服务器，服务器在收到这些报文段后，按照序号以原来的顺序重组 HTTP 请求报文。然后处理并返回一个 HTTP 响应。当然，HTTP 响应报文也要经过和 HTTP 请求报文一样的过程
   - 断开TCP连接、浏览器显示界面



# C++

## 基本概念

1. **内存数据存储位置**

   | 内存区域        | 存储内容                     | 生命周期         | 特点                      |
   | :-------------- | :--------------------------- | :--------------- | :------------------------ |
   | **栈(Stack)**   | 局部变量、函数参数、返回值等 | 函数执行期间     | 自动分配释放，速度快      |
   | **堆(Heap)**    | 动态分配的内存(`new/malloc`) | 直到手动释放     | 大容量，分配较慢          |
   | **全局/静态区** | 全局变量、静态变量           | 程序整个运行期间 | 初始化为0，线程安全需注意 |
   | **常量区**      | 字符串常量和其他常量         | 程序整个运行期间 | 只读，不可修改            |
   | **代码区**      | 程序执行的机器指令           | 程序整个运行期间 | 只读，存放函数体          |

2. **`virtual` 的意义**

   没有加 `virtual` 的话，创建/销毁子类对象的时候找不到子类的构造函数/析构函数，就会只调用父类的，造成内存泄漏，加了 `virtual` 可以：

   - 通过虚函数机制确保调用正确的析构函数链
   - 基类虚析构函数会使得所有派生类析构函数自动成为虚函数
   - 多态基类必须声明虚析构函数

3. **`new`和 `delete`（C++）， `malloc` 和 `free`（C）**

   这两对搭配是不可以混合使用的，因为:

   - `free` 不会调用析构函数，导致资源泄漏

   - `new` 调用构造函数，可能分配额外内存，而 `free` 不知道这些额外信息，导致堆损坏

   - 关键区别

     | 特性         | new/delete                | malloc/free            |
     | :----------- | :------------------------ | :--------------------- |
     | **语言层面** | C++运算符                 | C库函数                |
     | **内存大小** | 自动计算                  | 需手动计算             |
     | **初始化**   | 调用构造函数              | 只分配内存             |
     | **清理**     | 调用析构函数              | 只释放内存             |
     | **失败处理** | 抛出bad_alloc异常         | 返回NULL               |
     | **重载方式** | 可重载operator new/delete | 不可重载               |
     | **内存对齐** | 遵循类型对齐要求          | 通常按最大基本类型对齐 |
     | **数组支持** | 有new[]/delete[]专用形式  | 需要手动计算数组大小   |
     | **放置形式** | 支持placement new         | 无对应功能             |
     | **类型安全** | 类型安全                  | 返回void*需要转换      |

4. **`new`和 `delete` 的资源消耗原因**

   - 系统调用开销：需要从操作系统申请/释放内存、涉及用户态/内核态切换
   - 构造函数/析构函数调用：
     - `new`：先分配内存，再调用构造函数
     - `delete`：先调用析构函数，再释放内存

5. **下面这段代码有没有问题：**

   ```cpp
   class A { 
   public:
       void func(){
           cout<<"hello"
       }
   }; 
   A* a=nullptr;
   a->func();
   ```

   没有问题。成员函数代码 `func()` 存储在代码段中，静态编译时就已经确定位置，与对象实例无关，所有实例共享同一分函数代码。当调用 `a->func()` 时，编译器生成的代码相当于 `A::func(a)`，这里 `a` 是作为隐式的 `this` 指针参数传递，由于 `func()` 内部没有访问任何成员变量，不需要解引用 `this` 指针。关键点在于 `func()` 没有访问任何成员变量或虚函数，如果函数尝试访问 `this->member`，则会因解引用空指针而崩溃

## 数据结构

1. **`vector` 和 `list` 的区别？**

   | 特性                | vector             | list               |
   | :------------------ | :----------------- | :----------------- |
   | **底层结构**        | 动态数组           | 双向链表           |
   | **内存布局**        | 连续内存           | 非连续内存         |
   | **随机访问**        | O(1)               | O(n)               |
   | **插入/删除(头部)** | O(n)               | O(1)               |
   | **插入/删除(中间)** | O(n)               | O(1)（已知位置）   |
   | **插入/删除(尾部)** | 均摊O(1)           | O(1)               |
   | **内存分配**        | 偶尔需要重新分配   | 每次操作可能分配   |
   | **缓存友好性**      | 高                 | 低                 |
   | **迭代器失效**      | 容量变化时全部失效 | 只有被删除元素失效 |

2. **如果 `vector` 要加入的内容很多应该怎么做？**

   - 预先分配足够空间，避免多次扩容
   - 使用移动而非拷贝

3. **`push_back` 和 `emplace_back` 的区别？**

   | 特性         | push_back                   | emplace_back             |
   | :----------- | :-------------------------- | :----------------------- |
   | **参数**     | 接受对象本身                | 接受构造参数             |
   | **构造方式** | 先构造对象再拷贝/移动到容器 | 直接在容器内存中构造对象 |
   | **效率**     | 可能多一次拷贝/移动         | 通常更高效               |
   | **使用场景** | 已有对象需要放入容器        | 直接构造新对象到容器     |
   | **C++版本**  | C++98                       | C++11引入                |

4. **模板类、模板函数**

   模板是C++泛型编程的基础，允许编写与数据类型无关的代码，编译器根据参数自动确定模板参数类型

   ```cpp
   // 模板函数
   template <typename T>  // 或 template <class T>
   T max(T a, T b) {
       return (a > b) ? a : b;
   }
   ```

   ```cpp
   template <typename T>
   class Stack {
   private:
       std::vector<T> elements;
   public:
       void push(const T& element);
       T pop();
       bool empty() const { return elements.empty(); }
   };
   ```

   - 适用场景
     - 需要编写与数据类型无关的通用代码
     - 需要高性能的泛型实现
     - 实现容器类或算法库
     - 比如把线程池的任务队列中的任务类作为T，之后无论什么具体任务都可以复用代码

5. **STL 容器分类详解**

   - 序列式容器

     - 数组风格容器

       | 容器     | 底层实现     | 特点                              | 时间复杂度                     |
       | :------- | :----------- | :-------------------------------- | :----------------------------- |
       | `array`  | 固定大小数组 | C++11引入，封装原生数组，安全访问 | 随机访问: O(1)                 |
       | `vector` | 动态数组     | 尾部操作高效，支持随机访问        | 插入/删除末尾: O(1) 中间: O(n) |

     - 链表风格容器

       | 容器           | 底层实现 | 特点                                 | 时间复杂度                     |
       | :------------- | :------- | :----------------------------------- | :----------------------------- |
       | `list`         | 双向链表 | 任意位置高效插入删除，不支持随机访问 | 插入/删除: O(1) 访问: O(n)     |
       | `forward_list` | 单向链表 | C++11引入，更省空间，只支持前向遍历  | 插入/删除: O(1) 访问: O(n)     |
       | `deque`        | 分块数组 | 双端队列，头尾操作高效，支持随机访问 | 头尾插入/删除: O(1) 中间: O(n) |

   - 关联式容器

     - 有序关联容器（基于红黑树）

       | 容器       | 特点                         | 时间复杂度               |
       | :--------- | :--------------------------- | :----------------------- |
       | `set`      | 唯一键集合，自动排序         | 插入/删除/查找: O(log n) |
       | `multiset` | 允许重复键的集合，自动排序   | 同上                     |
       | `map`      | 键值对集合，键唯一且排序     | 同上                     |
       | `multimap` | 允许重复键的键值对集合，排序 | 同上                     |

     - 无序关联容器（基于哈希表）

       | 容器                 | 特点                     | 时间复杂度         |
       | :------------------- | :----------------------- | :----------------- |
       | `unordered_set`      | 唯一键集合，哈希存储     | 平均O(1)，最差O(n) |
       | `unordered_multiset` | 允许重复键的哈希集合     | 同上               |
       | `unordered_map`      | 键值对哈希表，键唯一     | 同上               |
       | `unordered_multimap` | 允许重复键的键值对哈希表 | 同上               |

   - 容器适配器

     | 适配器           | 底层容器     | 特点                                           |
     | :--------------- | :----------- | :--------------------------------------------- |
     | `stack`          | `deque/list` | LIFO(后进先出)结构，默认使用deque              |
     | `queue`          | `deque/list` | FIFO(先进先出)结构，默认使用deque              |
     | `priority_queue` | `vector`     | 优先级队列，默认最大堆，使用vector作为底层容器 |

6. **`unordered_map` 和 `map` 的区别？为什么一般都用 `map`？**

   | 特性                    | unordered_map (哈希表) | map (红黑树)                |
   | :---------------------- | :--------------------- | :-------------------------- |
   | **底层实现**            | 哈希表                 | 红黑树                      |
   | **元素顺序**            | 无序                   | 按键值排序                  |
   | **查找时间复杂度**      | 平均O(1)，最差O(n)     | O(log n)                    |
   | **插入/删除时间复杂度** | 平均O(1)，最差O(n)     | O(log n)                    |
   | **内存使用**            | 较高(哈希桶)           | 较低                        |
   | **迭代器稳定性**        | 插入/删除可能导致失效  | 除删除元素外保持稳定        |
   | **自定义键类型要求**    | 需要哈希函数和相等比较 | 只需严格弱序比较(operator<) |

   一般用 `map` 的原因：

   - **确定性**：元素始终有序，便于调试和序列化
   - **稳定性**：迭代器在插入时不会失效
   - **范围查询**：支持lower_bound/upper_bound等有序操作
   - **内存可预测性**：没有哈希表的rehash问题
   - **默认可用**：不需要为键类型定义哈希函数
   - **最差情况性能稳定**：不会因哈希冲突退化

7. **`vector` 扩容机制**

   - **超出容量时**：
     - 分配新的更大的内存块(通常是原大小的1.5或2倍)
     - 将原有元素**移动或拷贝**到新内存
     - 释放旧内存
     - 更新容量和迭代器
   - **扩容基数**：
     - 标准未规定具体值，各实现不同
     - VS通常用1.5倍，gcc通常用2倍
     - 1.5倍在长期多次插入后能更好地复用之前释放的内存块

   

## 新特性

1. **三种智能指针**

   - `std::unique_ptr`

     - 特点
       - **独占所有权**：一个资源只能由一个 `std::unique_ptr` 拥有
       - **不可复制**：不能通过拷贝构造函数或赋值运算符复制 `std::unique_ptr`
       - **可移动**：可以通过 `std::move` 转移所有权
     - 使用场景：适用于需要独占资源所有权的场景，如动态分配的对象
     - 实现原理：

   - `std::shared_ptr`

     - 特点

       - **共享所有权**：多个 `std::shared_ptr` 可以共享同一个资源

       - **引用计数**：内部维护一个引用计数器，当引用计数为 0 时自动释放资源

       - **可复制**：可以通过拷贝构造函数或赋值运算符复制 `std::shared_ptr`

     - 使用场景：适用于需要共享资源所有权的场景，如多个对象共享同一个资源

     - 实现原理：

   - `std::weak_ptr`

     - **特点**
       - **弱引用**：不增加引用计数，不会影响资源的生命周期。
       - **解决循环引用**：用于打破 `std::shared_ptr` 的循环引用问题。
       - **需要转换为 `std::shared_ptr`**：通过 `lock()` 方法获取一个 `std::shared_ptr`
     - 使用场景：适用于需要观察资源但不拥有资源的场景，如缓存、观察者模式、

2. **智能指针的线程安全**

   不是线程安全的，14新加了 `atomic_shared_ptr` 才保证

   解决方案是给智能指针加锁

   | 智能指针类型 | 引用计数线程安全                | 指向对象线程安全 | 典型使用场景               |
   | :----------- | :------------------------------ | :--------------- | :------------------------- |
   | `shared_ptr` | **是** (原子操作)               | **否**           | 多线程共享对象             |
   | `unique_ptr` | 无引用计数                      | **否**           | 独占所有权，线程内使用     |
   | `weak_ptr`   | **是** (与关联的shared_ptr同步) | **否**           | 解决 `shared_ptr` 循环引用 |

3. **`unique_ptr` 怎么赋值给另一个 `unique_ptr`？**

   - 只能通过**移动语义**将所有权转移来赋值

     ```c++
     std::unique_ptr<int> ptr1(new int(42));
     std::cout << "ptr1: " << *ptr1 << std::endl; // 输出 42
     
     // 将 ptr1 的所有权转移给 ptr2
     std::unique_ptr<int> ptr2 = std::move(ptr1);
     
     // ptr1 现在为空
     if (!ptr1) {
         std::cout << "ptr1 is now null" << std::endl;
     }
     
     // ptr2 现在拥有资源
     std::cout << "ptr2: " << *ptr2 << std::endl; // 输出 42
     ```

4. **`move` 的应用场景？**

   - 用于将对象的所有权从一个实例转移到另一个实例。它主要用于实现 **移动语义**，避免不必要的拷贝操作，从而提高性能

   - 应用场景：

     - 转移 `shard_ptr` 的所有权

     - 优化容器操作，避免拷贝构造，直接移动元素

       ```c++
       int main() {
           std::vector<std::string> vec;
           std::string str = "Hello";
       
           // 使用 std::move 将字符串移动到容器中
           vec.push_back(std::move(str));
       
           std::cout << "str after move: " << str << std::endl; // 输出空字符串
           std::cout << "vec[0]: " << vec[0] << std::endl; // 输出 Hello
       
           return 0;
       }
       ```

     - 实现移动构造函数和移动赋值运算符

     - 从函数返回局部对象

       ```c++
       std::string createString() {
           std::string str = "Hello, World!";
           return std::move(str); // 使用 std::move 返回
       }
       
       int main() {
           std::string result = createString();
           std::cout << result << std::endl; // 输出 Hello, World!
       
           return 0;
       }
       ```

     - 在需要传递或返回大型对象时，使用 `std::move` 避免深拷贝

5. **左值和右值、右值引用及其作用？**

   | 特性     | 左值 (lvalue)      | 右值 (rvalue)                  |
   | :------- | :----------------- | :----------------------------- |
   | 定义     | 有持久身份的对象   | 临时对象或字面量               |
   | 示例     | 变量、函数返回引用 | 临时对象、字面量、move后的对象 |
   | 地址     | 有确定地址         | 通常无持久地址                 |
   | 生命周期 | 作用域内持续       | 表达式结束后销毁               |

   右值引用的核心作用：

   - 实现移动语义
   - 完美转发：保持参数原始类型
   - 优化临时对象处理

   **如果没有右值引用，怎么延长右值的生存期**？

   - 使用 `const` 左值引用延长临时对象生命周期

6. 

7. snprintf sprintf 

8. 

9. unordered_map和map的区别？为什么一般都用map？

10. 禁用掉的构造函数或运算符去使用会报什么错？在哪个时期？

11. 几种类型转换的方式有什么区别

12. crtp特性

13. 模板元编程？比如让templae T这个T只能接收某一个基类如何去实现？

14. const用在哪？（常量，常成员函数，底层const）

15. const &amp; 传参为什么效率高？（不需要拷贝）

16. vector超出容量会怎样？（以1.5或者2倍扩容）扩容基数？

17. 虚函数表是类还是对象拥有的？（类）

18. 怎么获取虚函数表？（虚表指针）

19. map查询效率?unordered_map是哈希表，O(1)；map是红黑树，O(logn)

20. map的key是自定义的类，需要注意什么?类要实现<的重载，保证key可以比较（也可以是函数对象）

21. 遇到过内存泄露吗？这里以为问的是项目（傻），说没有，使用了智能指针（应该举小例子）

22. 到过内存越界吗？这里答错了，讲成栈溢出（举例数组下标越界就行）

23. 编程遇到错误怎么解决？用过GDB吗？用vscode断点调试，没用过

24. **抽象类和接口类的区别？**

    - 所有成员函数都是纯虚函数（没有非虚函数或成员变量），即**接口类**。
    - **能否实例化**：
      - **直接实例化** ❌ 不能（所有方法均未实现）。
      - **通过派生类实例化** ❌ 仍然不能（除非派生类实现所有方法）。

    | 特性          | 抽象类 (Abstract Class)  | 接口(Interface)                 |
    | :------------ | :----------------------- | :------------------------------ |
    | **语法实现**  | 包含至少一个纯虚函数     | C++中无原生接口，用纯抽象类模拟 |
    | **成员变量**  | 可以包含成员变量         | 只应包含静态常量(模拟接口时)    |
    | **方法实现**  | 可以提供部分方法的实现   | 所有方法都是纯虚函数(无实现)    |
    | **继承关系**  | 类继承(可多重继承)       | 类继承(推荐用纯抽象类模拟)      |
    | **构造/析构** | 可以有构造函数和析构函数 | 只有虚析构函数                  |
    | **使用场景**  | 提供部分通用实现         | 定义行为契约                    |

25. **内存泄漏是什么？举例子，如何排查内存泄漏？**

    内存泄漏指程序在动态分配内存后，失去对该内存的控制而无法释放，导致该内存区域无法再被程序或操作系统使用的情况

    检测工具：Valgrind、AddressSanitizer

## 程序设计

1. 虚析构函数的必要性

## 语言特性

1. **C++ 怎么保证线程安全？**

   - 保证线程安全是确保多个线程并发访问共享资源时不会导致数据竞争或未定义行为的关键
   - **标准库中的容器不是线程安全的**
   - 使用互斥锁：线程同步，保护共享资源
   - 使用原子操作：简单的共享变量
   - 使用条件变量：用于线程间的通信，通常与互斥锁一起用
   - 使用无锁数据结构：通过原子操作实现线程安全，避免锁的开销

2. **多态底层怎么实现的？**

   - 虚函数表（vtable）机制：

     1. 每个包含虚函数的类都有一个虚函数表
     2. 每个对象包含一个指向vtable的指针(vptr)
     3. 调用虚函数时通过vptr找到vtable再定位具体函数

     ```cpp
     class Base {
     public:
         virtual void func1() {} // 虚函数
         virtual void func2() {}
     };
     
     class Derived : public Base {
     public:
         void func1() override {} // 重写虚函数
     };
     
     // 内存布局实例：
     Derived对象内存布局：
     +-------------------+
     | vptr (指向Derived的vtable) |
     | Base类成员变量      |
     | Derived类成员变量   |
     +-------------------+
     
     Derived的vtable：
     +-------------------+
     | &Derived::func1   | // 重写的函数
     | &Base::func2      | // 继承的函数
     +-------------------+
     ```

   - 动态绑定的运行时行为

     ```cpp
     Base* b = new Derived();
     b->func1(); // 实际调用Derived::func1()
     ```

     1. 通过b找到vptr
     2. 通过vptr找到vtable
     3. 在vtable中找到func1的地址
     4. 调用该地址的函数

3. C++内存泄漏如何判断

# Linux 命令

1. 如何查找一个进程

   - `ps`

     ```shell
     ps aux | grep <进程名>   # 查找进程的PID
     # ps 是查看后台进程
     # ps aux 是输出特定的格式：
     # USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND
     ```

2. 查看端口使用情况

   - `netstat`

     ```shell
     netstat -tulnp    # 查看端口使用情况
     netstat -n		  # 用 "源IP", "源端口号", "目的IP", "目的端口号", "协议号" 这样一个五元组来标识一个通信
     ```

3. 显示系统当前内存的使用情况，包括已用内存、可用内存和交换内存

   - `free`

     ```shell
     free -h       # 以人类可读的方式显示内存使用情况
     ```

4. 如何杀死一个进程

   - `kill`

     ```shell
     kill <PID>      # 终止该进程
     kill -9 <PID>   # 强制终止该进程
     ```

   - `killall`

     ```shell
     killall <进程名>  # 终止所有该进程
     ```

5. 如何查看操作系统日志

   - Linux 系统日志通常位于 `/var/log` 目录下

   - `journalctl`

     ```shell
     journalctl -xe           # 查看系统日志
     journalctl -f            # 实时查看日志
     journalctl -u sshd       # 查看 SSH 服务日志
     ```

   - `cat/tail`

     ```shell
     cat /var/log/syslog      # 读取系统日志
     dmesg | tail             # 查看最近的内核日志
     ```

6. 查看磁盘空间

   - `df`

     ```shell
     df -h    # 查看磁盘空间使用情况
     ```

7. 如何打印文件的绝对路径

   - `realpath`

     ```shell
     realpath <文件名>
     ```

8. 如何读取日志文件的末尾/开头10行

   - `head`

     ```shell
     head -n 10 <文件名>
     ```

   - `tail`

     ```shell
     tail -n 10 <文件名>
     ```

9. sed命令用过吗？有什么作用？如何查看文件的指定行数的内容？

   - 'sed' 是一个流编辑器，可用于文本处理

   - 替换文本

     ```shell
     sed 's/old-text/new-text/' <文件名>
     ```

   - 删除某行

     ```shell
     sed '3d' <文件名>   # 删除第3行
     ```

   - 查看指定行数的内容

     ```shell
     sed -n '10p' <文件名>   # 查看第10行内容
     ```

10. 常用的Linux系统版本

    - Ubuntu22.04

11. linux启动服务的命令

    - `systemctl`

      ```shell
      systemctl start <服务名>   # 启动服务
      systemctl stop <服务名>    # 停止服务
      systemctl restart <服务名> # 重启服务
      systemctl status <服务名>  # 查看服务状态
      ```

12. 将文件移动到别的路径，并解压文件，运行输出

    - `mv`, `tar`

      ```shell
      mv <文件名> <目标路径>        # 移动文件
      cd <目标路径>           
      tar -xzvf <name.tar.gz>     # 解压文件
      ./run.sh
      ```

13. Linux有哪些监控命令

    - `top`：查看所有进程和资源使用情况，CPU
    - `htop`：可以看做是`top`的高级版本
    - `NetHogs`：能够监控到每个进程的网络流量
    - `IPTraf`：网络流量监控，可以基于网卡、IP、协议等监控
    - `iotop`：监控进程磁盘I/O
    - `lsof`：显示打开的文件和进程，包括磁盘文件、网络套接字、管道、设备和进程
    - `iftop`：监控TCP\UDP流的网络流量，显示两台主机之间当前宽带的使用情况
    - `netstat`：监控TCP\UDP网络数据包传入和传出
    - `iostat`：监控每个磁盘分区的读写情况，通常用于查找存储设备性能问题
    - `vmstat`： 监控linux负载，报告关于内核线程、虚拟内存、CPU等活动的统计信息，展示平均负载
    - `tcpdump`：命令行网络数据包分析器，用于捕获和过滤 TCP/IP 包

14. linux环境cpu过高如何排查原因

    - 定位：
      - `top`确认cpu高的应用和进程
      - 定位异常进程对应的线程
    - 分析线程堆栈信息：
      - 获取堆栈信息，结合应用日志等进行分析
    - 方案验证
      - 修改代码，重新部署，观察是否解决

15. cpu使用率过高原因

    - 进程异常：某个进程进入死循环
    - 负载过高：同时运行的任务太多
    - I/O 争用：进程等待磁盘 I/O
    - 网络瓶颈：高网络中断消耗 CPU
    - 内存不足：导致频繁 Swap，CPU 等待数据

16. 进程线程控制操作命令

17. 性能监控与调试

    - **strace 跟踪系统调用**：

      ```bash
      # 只跟踪read,write两类系统调用
      # cat /proc/cpuinfo是被跟踪的目标命令
      strace -e trace=read,write cat /proc/cpuinfo
      # 运行这个命令后 strace 会启动 cat /proc/cpuinfo 进程，然后记录执行过程中的所有 read 和 write 系统调用，输出以下内容：
      read(3, "processor\t: 0\nvendor_id\t: GenuineIntel\n"..., 131072) = 512
      write(1, "processor\t: 0\nvendor_id\t: GenuineIntel\n"..., 512) = 512
      read(3, "cpu family\t: 6\nmodel\t\t: 142\n"..., 131072) = 512
      write(1, "cpu family\t: 6\nmodel\t\t: 142\n"..., 512) = 512
      ```

    - **perf 分析系统调用开销**：

      ```bash
      perf stat -e 'syscalls:sys_enter_*' ls
      ```

    - **内核跟踪点**：

      ```bash
      # 查看所有系统调用跟踪点
      sudo ls /sys/kernel/debug/tracing/events/syscalls/
      ```

## perf

1. 核心组件

   ```
   用户空间工具层
   ├── perf stat    # 统计计数
   ├── perf record  # 采样记录  
   ├── perf report  # 分析报告
   ├── perf top     # 实时监控
   └── perf probe   # 动态探针
   
   内核接口层
   ├── perf_event_open 系统调用
   ├── 硬件PMU (Performance Monitoring Unit)驱动
   ├── 软件事件抽象
   └── 环形缓冲区管理
   
   硬件支持层
   ├── CPU性能计数器
   ├── 缓存事件监控
   └── 分支预测统计
   ```

2. 事件类型

   - **CPU 相关**：
     - cpu-cycles (CPU周期数)
     - instructions (退休指令数)
     - branch-misses (分支预测失败)
     - cache-references (缓存访问)
     - cache-misses (缓存未命中)
   - **内存相关**：
     - mem-loads (内存加载)
     - mem-stores (内存存储)
     - tlb-load-misses (TLB未命中)
   - **内核抽象事件**：
     - context-switches (上下文切换)
     - page-faults (缺页异常)
     - cpu-migrations (CPU迁移)
   - 静态内核探针点：
     - `kmem:mm_page_alloc` (内存分配)
     - `sched:sched_switch` (任务切换)

3. 基本用法

   - 统计命令执行的基本性能指标

     ```bash
     # 统计 ls 命令的 CPU 周期、指令数、缓存命中率等
     perf stat ls
     ```

     ```
      Performance counter stats for 'ls':
     
               1.234567      task-clock (msec)         #    0.789 CPUs utilized          
                     12      context-switches          #    0.009 M/sec                  
                      0      cpu-migrations            #    0.000 K/sec                  
                    123      page-faults               #    0.100 M/sec                  
        <not supported>      cycles                                                      
        <not supported>      instructions                                                
        <not supported>      branches                                                    
        <not supported>      branch-misses                                               
     
            0.001563456 seconds time elapsed
     ```

   - 记录并分析CPU使用情况

     ```bash
     # 记录系统10秒的CPU使用情况
     sudo perf record -a -g -- sleep 10
     
     # 查看记录结果
     perf report
     ```

     在 `perf report` 界面中，你可以看到：

     - 热点函数调用
     - 调用栈信息
     - 各函数占用的CPU比例

   - 分析特定进程

     ```bash
     # 启动一个要分析的进程
     ./my_program &
     
     # 记录该进程的性能数据
     sudo perf record -p $(pidof my_program) -g -- sleep 30
     
     # 生成火焰图
     perf script | stackcollapse-perf.pl | flamegraph.pl > perf.svg
     ```

4. 工作模式

   - 计数模式（适合算子基础分析）

     ```bash
     # 统计矩阵乘法程序的缓存表现
     perf stat -e cache-misses,cache-references,instructions ./matrix_multiply
     ```

   - 采样模式（适合热点分析）

   ```bash
   # 每1000次缓存未命中采样一次调用栈
   perf record -e cache-misses -c 1000 -g -- ./ai_workload
   ```

   - 剖析模式（结合您的可视化经验）

   ```bash
   # 生成火焰图
   perf record -F 99 -g --call-graph dwarf -p $(pidof app)
   perf script | stackcollapse-perf.pl | flamegraph.pl > flame.svg
   ```

5. 实际案例：分析nginx性能

   ```bash
   # 1. 找到 nginx worker 进程
   ps aux | grep nginx
   
   # 2. 记录该进程的性能数据 (假设PID是1234)
   sudo perf record -p 1234 -g -- sleep 30
   
   # 3. 生成报告
   perf report
   
   # 或者生成火焰图
   perf script | stackcollapse-perf.pl | flamegraph.pl > nginx_perf.svg
   ```

## ebpf

eBPF（extended Berkeley Packet Filter）是一种可编程的内核扩展机制，最初由BPF（Berkeley Packet Filter）演化而来，BPF最初是为了在Unix系统上进行网络数据包过滤而设计的。它最早由Steven McCanne和Van Jacobson于1992年在BSD系统中引入，旨在提供一种轻量级的过滤机制，以帮助网络管理员监视和分析网络流量。最初的BPF具有一组预定义的指令集，用于过滤和处理网络数据包。

随着计算机网络和操作系统的发展，对BPF的需求也逐渐增加。在Linux内核中，BPF被广泛应用于网络包过滤、性能监控、安全审计等方面。然而，传统的BPF存在着功能受限、安全性差等问题，限制了其在复杂场景下的应用。为了解决这些问题，在2013年对BPF技术进行了改造升级并命名为eBPF。eBPF最早由Brendan Gregg和其他内核开发者在Linux3.15内核中引入到源码，用于安全有效地扩展内核的功能，而无需通过更改内核源代码或加载内核模块的方式来实现。

eBPF是对传统的BPF的扩展和增强。它引入了许多重要的变化，使得其功能更加强大、灵活和安全：

·可编程性增强：eBPF引入了一种基于LLVM的新的BPF编译器，使得BPF程序可以使用更丰富的指令集和语言特性编写。这使得eBPF程序具有更高的灵活性和表达能力，能够实现更复杂的功能。

·安全性提升：eBPF引入了一套严格的安全验证机制，包括对程序代码进行静态分析和动态验证，以及对程序访问的资源进行严格控制。这使得eBPF程序在内核中执行时更加安全，不会对系统的稳定性和安全性造成影响。

·支持更多的功能和用途：eBPF扩展了BPF的功能和用途，不仅可以用于网络包过滤和转发，还可以用于性能监控、安全审计、动态追踪等领域。这使得eBPF成为一种通用的内核扩展机制，为内核开发人员提供了更多的选择和可能性。

·支持用户态程序：eBPF引入了一种新的用户态BPF虚拟机，使得用户态程序也可以利用eBPF的功能。这使得eBPF不仅可以在内核中执行，还可以在用户态执行，从而扩展了其应用范围和灵活性。

eBPF的灵活强大功能使其不再仅局限于网络包过滤等网络分析场景，其在系统观测和网络安全监控领域也被广泛使用，它允许用户在不修改内核源代码的情况下，通过加载和执行自定义的eBPF程序来扩展内核功能。这些eBPF程序通过Hook机制与内核交互，它们可以对进入和离开内核的事件进行过滤和处理，以实现网络数据包的监控、性能统计和故障追踪等功能。

具体来说，用户根据自己的观测需求编写并编译eBPF程序生成eBPF指令，随后使用bpf()系统调用将生成的指令加载到内核的指定挂载点，当特定事件触发时系统执行这些eBPF指令，从而实现将所需观测信息向用户层的传递，这个过程是完全无侵入，对应用系统来说完全无感知的。

具体的插入eBPF程序实现hook观测点挂载的过程如下图所示：用户编写的eBPF程序（通常是C语言）通过编译器套件编译为eBPF字节码，然后使用 bpf 系统调用将 eBPF 程序加载到 Linux 内核中，当程序被加载到 Linux 内核中时，它在被附加到所请求的钩子上之前需要经过验证和JIT编译两个步骤，前者用来确保 eBPF 程序可以安全运行，后者将程序的通用字节码转换为机器特定的指令集，用以优化程序的执行速度。这样就成功的将机器码hook到用户想要进行挂载观测的点上。

从上面过程可以看出eBPF技术实现挂载与观测的诸多优点：用户可以根据自身需求灵活自定义eBPF程序，将更多观测内容导入到用户空间进行分析；验证过程通过检查程序的特权级以及死循环等指标，避免了eBPF程序对内核运行的安全稳定性造成影响；JIT即时编译使得eBPF程序可以像本地编译的内核代码或作为内核模块加载的代码一样高效地运行，有效减小了代码执行开销，尽可能小的影响系统的执行效率。

 BPF Map 读取
eBPF 程序运行时通常会将收集的数据存放在 BPF map 中，用户态程序可以周期性地查询或拉取这些 map 中的数据，用来统计、聚合和分析监控指标。
例如，可以统计函数调用次数、网络数据包统计、资源使用量等数据，然后通过命令行或程序接口展示。
环形缓冲区 (Ring Buffer)
利用 BPF ring buffer 可以实时传输事件数据，从内核空间向用户空间传递事件消息。这种方式适合处理高频、低延迟的数据流，用户态可以以流的方式接收和处理这些事件。
内核日志输出
通过 bpf_printk 函数输出调试信息，这些信息可以通过查看 /sys/kernel/debug/tracing/trace_pipe 或 dmesg 获取。这种方式适合简单的调试和验证，但一般不用于正式的监控数据采集。
集成至监控系统
将 eBPF 采集到的数据以 Prometheus 格式导出，再利用 Prometheus 进行数据拉取，并结合 Grafana 等工具生成实时的图表、直方图、折线图、热力图等。这样可以将 eBPF 监控数据以可视化面板的形式展示给用户。
高级工具展示
利用像 bcc、bpftrace、bpftool 等工具，用户可以直接在命令行中以动态追踪、实时统计的方式查看 eBPF 的输出，或结合各类专用平台（如 Cilium、SkyWalking、Falco 等）实现更复杂的监控、追踪和安全检测。

eBPF程序的一个核心概念是bpf_map，它是驻留在内核中的以键/值方式存储的数据结构，可以被任何知道它们的BPF程序访问，在用户空间运行的程序也可以通过使用文件描述符来访问bpf_map，所以其经常被用于用户空间和内核空间之间的数据交换和信息传递。eBPF提供了多种类型的maps，例如数组、队列、环形缓冲区等

有一些这个bpf_map_update_elem,bpf_map_lookup_elem之类的函数来更改和读取相关检测数据，然后读取的数据你可以在用户态程序保存，然后你想咋输出都可以滴

## git

1. `git merge` 和 `git rebase` 的区别及用法
   - `git merge` 是安全、保留历史的，适合团队协作； `git rebase` 是整洁、线性历史的，适合本地整理，建议只对未推送的提交使用 `rebase`
   - `git merge` 是保留分支历史的合并，生成一个新的 merge commit
   - `git rebase` 是将分支提交 “重放” 到目标分支上，无额外合并提交

# 中间件/开源软件/框架

## Redis

### 基本概念

1. **简单介绍**

   - 一种高性能的 **内存键值数据库**，核心价值是**用内存换速度**
   - 核心作用：
     - 缓存加速：将热点数据**存入内存**，减少对慢速存储如 MySQL 的访问
     - 高性能读写：支持每秒数十万级操作（读 10W+/s，写 8W+/s），适合高并发场景
   - 典型适用场景：缓存、分布式系统中会话存储、排行榜实时更新、消息队列
   - 不适合大数据量持久化存储、不支持完整ACID事务、不支持关系型查询

2. **redis的两种持久化机制？**

   - RDB（定时生成内存快照二进制文件）：适合数据备份，恢复速度快，对性能影响小，但可能丢失最后一次快照后的数据
   - AOF（记录所有写操作命令）：数据安全性高，支持秒级持久化，但文件较大，恢复速度慢
   - 建议同时使用：RDB做冷备，AOF做热备，利用各自优势

3. **redis的基本数据结构**

   | **数据结构**    | **底层实现**                  | **特点**                                | **常用命令**                   |
   | :-------------- | :---------------------------- | :-------------------------------------- | :----------------------------- |
   | **String**      | 动态字符串（SDS）             | 可存文本、数字、二进制数据（最大512MB） | `SET`, `GET`, `INCR`           |
   | **List**        | 双向链表或压缩列表（ziplist） | 支持双向操作，可作队列或栈              | `LPUSH`, `RPOP`, `LRANGE`      |
   | **Hash**        | 压缩列表或哈希表              | 适合存储对象（如用户信息）              | `HSET`, `HGET`, `HGETALL`      |
   | **Set**         | 哈希表或整数集合              | 无序、去重，支持交并差运算              | `SADD`, `SMEMBERS`, `SINTER`   |
   | **ZSet**        | 跳表（SkipList） + 哈希表     | 有序集合，按分数（score）排序           | `ZADD`, `ZRANGE`, `ZREVRANK`   |
   | **Bitmaps**     | String 的位操作               | 节省空间的布尔统计（如用户签到）        | `SETBIT`, `GETBIT`, `BITCOUNT` |
   | **HyperLogLog** | 概率算法                      | 基数统计（去重计数），误差0.81%         | `PFADD`, `PFCOUNT`             |

4. **redis中 `Hash` 结构的 `rehash` 过程是什么？**

   `Hash` 在扩缩容时触发渐进式 `rehash`

   1. **触发条件**：
      - 扩容：元素数 > 哈希表大小 × 负载因子（默认1）。
      - 缩容：元素数 < 哈希表大小 × 0.1。
   2. **过程**：
      - 分配新哈希表（大小为当前表的2倍或0.5倍）。
      - 逐步将旧表数据迁移到新表（每次增删改查迁移一个桶）。
      - 迁移完成后，用新表替换旧表。
   3. **优点**：
      - 避免一次性迁移导致服务阻塞

5. **LRU 和 LFU 的区别**

   | **策略** | **全称**              | **淘汰规则**                            | **适用场景**                 | 实现细节                                                     |
   | :------- | :-------------------- | :-------------------------------------- | :--------------------------- | ------------------------------------------------------------ |
   | **LRU**  | Least Recently Used   | 淘汰最久未访问的键                      | 访问模式随时间变化均匀       | 近似算法，随机采样部分键，淘汰其中最久未访问的               |
   | **LFU**  | Least Frequently Used | 淘汰访问频率最低的键（Redis 4.0+ 支持） | 存在热点数据，需长期统计频率 | 基于计数器（访问频率衰减 + 概率对数化），避免历史访问影响当前决策 |

### 集群

1. **集群相对于单机来说有什么不同点？**
   - 易于扩展，高性能，高可用性，但是需要额外维护成本
2. **集群如何进行数据同步？**
   - 主从同步，增量同步，全量同步，异步复制
   - 同步的时候有一个replication buffer缓冲区，会写入同步期间新增的数据，同步完rdb之后再同步这个命令，然后重放一次
3. **集群模式是否容易丢失数据？以及如何解决丢失数据的情况？**
   - 集群模式可能丢失数据，主要原因是异步复制
   - 解决方法：开启持久化（RDB/AOF），调整 `min-slaves-to-write` 和 `min-slaves-max-lag` 参数
5. **缓存穿透如果用空值法的话，如何避免大面积的内存被白白占用？**
   - 可以空值设置较短的TTL、使用布隆过滤器、后台任务定期检查和清理空值
6. **redisson相比于setnx灵活在哪？**
   -  同一线程可多次获取锁
   - 自动续期
   - 锁超时
   - 分布式支持
7. 采用延迟双删的情况下，如果MySQL数据库操作失败了怎么办？
8. redis刷新token是如何保证用户无感？

## Nginx

1. nginx的七层和四层
1. 反向代理和正向代理的区别及对应的使用场景
1. 正向代理如何实现负载均衡
1. **多线程好处很多，Nginx 为什么使用多进程而不是多线程?**
   - 因为 Nginx 最核心的目的是要保持**高可用性、高可靠性**，如果使用多线程，线程之间是共享同一个地址空间的，所以当某第三方模块引发地址空间导致段错误时，会导致整个nginx进程挂掉

## gRPC

## webSocket

1. Stream 流的实现原理？
2. 讲讲服务器、
   - 服务器是专门为提供服务、计算、存储或其他服务而设计的计算机，通常具有高性能、高可靠性、高安全性等特点
   - 会有不同的类型，用于托管网站、应用、数据库等
3. 如何进行项目部署，Docker用过吗？
   - 项目部署是指将开发完成的代码放到服务器上运行
   - 部署方式有：
     - 使用 shell 脚本，自动化执行部署步骤
     - 使用Docker容器化技术，打包应用及其依赖环境，实现一键部署
     - 大规模分布式部署使用 K8s，自动管理容器应用
   - Docker部署流程
     - 编写 Dockerfile
     - 构建镜像
     - 运行容器
4. 如何查看服务器的内存使用情况
   - 和在本机上一样
5. 介绍nginx，什么时候反向代理
   - Nginx 是一个高性能的 HTTP 服务器和反向代理服务器，指客户端请求被 Nginx 接收，然后转发到后端服务器
   - 特点：高并发、静态资源托管、负载均衡、反向代理

# 数据库

## 底层原理

1. 数据库采用的引擎？
2. MVCC 底层原理是什么？
3. **MySQL内部如何提高扫描效率？**
   - B+树索引，减少磁盘IO次数
   - 根据成本选择最优执行计划
   - InnoDB buffer pool缓存热数据
   - 提前读取可能需要的数据页
4. 为什么一般使用自增作为主键？（从数据库相关原理、索引方面回答）
5. 事务的隔离级别、索引？
6. 如何优化索引？
7. innodb 如何实现事务？
8. 还知道什么存储数据库引擎？

## 锁

1. 说说 MySQL 的锁机制
2. 乐观锁和悲观锁
3. **如何实现乐观锁？**为什么要用乐观锁？
   - 表中增加 `version` 字段，更新时检查版本
   - 条件更新 `UPDATE table SET data=?, version=version+1 WHERE id=? AND version=?`
4. 什么情况会出现超卖现象？乐观锁解决超卖如何实现？
5. 间隙锁是什么？用来处理什么情况？达到哪一种隔离级别

## SQL语句

1. 多表连接怎么优化
2. 多变连接的情况下，如果要分页查询该怎么改造？
3. 多表连接如何创建索引？联合索引是作用在哪里？
4. `join`, `from`, `groupby`, `order` 的执行顺序？

   - `FROM` > `JOIN` > `WHERE` > `GROUP BY` > `HAVING` > `SELECT` > `DISTINCT` > `ORDER BY` > `LIMIT`
5. 如何进行 SQL 语句优化？
6. 怎么判断加了索引？SQL 语句有没有用到索引？
7. 索引下推是什么？
8. 进行 `set` 语句的时候，undo log ,bin log ,redo log是怎么变化的？
9. MySQL 的 `join` 怎么优化

# 设计模式

## 后端

### 概念

1. **认证和鉴权的区别？**
   - 认证是确认用户是谁的过程，验证用户的身份
   - 鉴权是确认用户能有权限做什么的过程

### 场景

1. 
1. 如果有一个内存敏感性应用，从哪些方面做考虑？（池化，合理管理对象生命周期，避免内存泄漏，单例复用对象）
1. 如果现在一个10WQPS去生成订单号的服务接口，你怎么设计(我以为是下订单，一直说异步)，雪花算法，独立出服务加集群(忘了说etcd和zookeeper了)
1. **主流电商用的是多进程还是多线程**
   - 通常采用多进程和多线程混合架构，前者用于任务隔离和横向扩展，后者用于高并发请求处理和 I/O 密集型任务
   - 多进程架构：
     - 应用场景：任务隔离、高可靠性、横向扩展
     - 优点：隔离性强、资源管理简单、适合CPU密集型任务
     - 缺点：IPC开销大、内存占用高
     - 典型应用：微服务架构、任务队列
   - 多线程架构：
     - 应用场景：高并发请求处理、共享内存频繁数据交换、I/O密集型任务
     - 优点：资源共享、开销低、适合I/O密集型任务
     - 缺点：线程安全问题、调试复杂、一个线程崩溃可能影响整个进程
     - 典型应用：web 服务器、数据库连接池、异步任务处理
1. 贪心和DP在实际应用中的选用
1. 怎么对大型网络进行监测
   - 使用网络监控工具，如 Nagios、Zabbix、Prometheus 等
1. 批处理工具
   - linux中用shell， python脚本
   - windows中使用 `.bat` 脚本
   - 主要用于自动执行重复性任务
1. 两个vLan新加一台设备，问arp协议的工作过程？
   - ARP 协议用于在局域网中解析 IP 地址到 MAC 地址
   - 设备加入 VLAN：
     - 设备连接到交换机，并被配置在某个 VLAN（例如 VLAN 10）
     - 交换机会为该设备分配一个 IP（如果使用 DHCP）。
   - 设备发送 ARP 请求：
     - 设备需要访问同 VLAN 设备时，发送 ARP Request 广播，询问“某个 IP 地址对应的 MAC 地址”。
   - ARP 响应：
     - 目标设备（192.168.10.20）返回 ARP Reply
   - 跨 VLAN 访问（需要路由）：
     - 如果 Host A 需要访问 VLAN 20 的设备，则 VLAN 之间不能直接通信，必须通过三层设备（如路由器或三层交换机）。
     - Host A 发送 ARP 请求，查找 网关（Router/Layer 3 Switch）的 MAC 地址。
     - 通过网关进行路由，VLAN 10 和 VLAN 20 的数据才能互通。
1. 当公司设备出现紧急故障影响业务该如何处理？
   - 迅速通知 运维团队、开发团队、管理人员的相关人员，避免问题扩大
   - 初步排查故障：
     - 硬件问题：服务器是否宕机、磁盘是否满了 (df -h)、CPU 负载 (top)、内存 (free -m)
     - 网络问题：使用 ping、traceroute 检查网络连通性，查看 iptables 或 firewalld 配置
     - 应用问题：查看日志、监控指标，观察 CPU/内存是否异常
   - 采取紧急应对措施
     - 重启服务
     - 回滚版本
     - 切换灾备
   - 事后总结和优化
1. 客户端、服务端传输数据，分别储存数据在哪里？

### 与1、3项目相关可能问题

#### 项目一

1. **如果项目需要升级扩展，会使用什么办法？**
   - 使用微服务架构拆分核心功能
   - 引入K8s进行容器编排，实现弹性伸缩
2. **网络编程怎样实现多用户管理？**
   - 使用 tokio 的异步任务处理每个连接
   - 用 `Arc+Mutex` 保证连接池的线程安全
   - 基于 Session Token 的用户身份验证
   - 连接心跳检测和超时断开机制
3. **项目使用了 Redis，如果要高缓存一致性又要并发应该怎么做？**
   - 一致性策略：
     - 写穿透(Write-through)模式：先更新数据库，再更新缓存
     - 使用Redis事务或Lua脚本保证原子性
     - 采用双删策略防止并发更新问题
   - 并发控制：
     - `tokio`
4. **如何提升服务的可用性？**
   - 用 etcd 实现服务发现和健康检查
   - 引入负载均衡
   - 交易数据多副本存储
   - 定期灾备演练
5. **日志系统设计与线程安全**
   - 分级分段日志（Trace/Debug/Info/Warn/Error）（日志分为多个文件，按日期线程等维度划分，每个日志用一个锁）
   - 暂存日志信息到缓冲区中，缓冲区满的时候线程处理日志（如批量写入减少 I/O 操作），或者使用异步线程后台处理避免阻塞主业务
   - 使用 MPSC 通道实现多生产者单消费者模式

# 岗位理解

1. **知道技术运维是做什么的吗？**
   - 应该有更细致的岗位划分，总体就是确保公司的互联网业务能不间断地为用户提供高质量服务
   - 需要对业务所依赖的基础设施、基础服务、线上业务进行稳定性加强
   - 通过日常巡检、监控、日志分析等技术手段，发现服务可能存在的隐患和安全问题、时发现和响应服务故障，减少服务中断的时间
   - 对整体架构进行优化以屏蔽常见的运行故障，多数据中接入提高业务的容灾能力
2. 对云计算的了解？

