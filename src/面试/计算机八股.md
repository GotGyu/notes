# Rust

## 语言理解

### 与C++的比较

#### Rust 相比 C++ 的好处

1. **内存安全**
   - Rust 通过所有权、借用、生命周期等机制，在编译时保证了内存安全；微软研究表明，70%的C/C++安全漏洞源于内存错误，而Rust可从根本上避免此类问题
   - C++依赖于程序员手动管理内存，容易出现内存泄漏、悬空指针等问题
2. **无畏并发**
   - Rust 编译期静态检查并发代码的安全性，避免数据竞争，`Tokio` 异步运行时凭借此特性支撑高并发网络服务
3. **零成本抽象**
   - Rust 的设计哲学之一是“零成本抽象”，即高级抽象（如迭代器、泛型、模式匹配）在运行时不会引入额外的性能开销，通过编译时严格的所有权和借用检查机制，彻底消除空指针、数据竞争等内存安全问题，无需依赖垃圾回收，使得在系统编程中表现卓越
   - 与 C++ 的模板元编程相比，Rust 的泛型和 trait 系统更加直观和安全，同时保持了高性能
4. 函数式编程风格
   - Rust 支持函数式编程范式，提供了闭包、迭代器、模式匹配等特性，使代码更加简洁、优雅，提高代码可读性，且在不牺牲性能的情况下实现高效抽象
5. 更好的错误处理
   - Rust 提供了 `Result` 和 `Option` 类型，强制程序员显式处理可能的错误和空值
   - 避免了 C++ 中常见的未处理异常或空指针问题
6. 跨平台一致性
   - Rust 的行为在不同平台上是一致的，且 `rustc` 严格遵循语言规范，大大减少了 UB
   - C++可能会因为编译器差异出现不一致，而且UB常见且难以调试
7. 强大的包管理工具
   - 内置 `Cargo`，可以轻松管理项目依赖、构建、测试
   - 与 C++ 的依赖管理（如手动或使用 `Cmake`等工具）相比，更见简单、方便
8. 客观的安全标准
   - Rust 的安全规则提供了一个客观的标准，可以明确区分 API 滥用和 API 本身的错误，编译器会明确指出问题的根源
   - 在 C/C++ 中，错误报告往往需要维护者确认某些行为是bug还是预期行为，沟通成本较高
9. 文档和测试一体化
   - Rust 的文档注释（`///`）和测试代码可以无缝集成到项目中
   - C++ 需要自己编写测试代码

#### Rust的各种特性（指针、数据结构等）在C++里对应什么？

| 特性             | C++                                            | Rust                                |
| :--------------- | :--------------------------------------------- | :---------------------------------- |
| **指针与引用**   | 原始指针 `int* ptr = &x`                       | 引用 `&T``&mut T`                   |
|                  | 独占所有权的智能指针  `std::unique_ptr<T>`     | 独占所有权的智能指针`Box<T>`        |
|                  | 共享所有权的智能指针 `std::shared_ptr<T>`      | 引用计数的智能指针`Rc<T>` `Arc<T>`  |
|                  | 不增加引用计数的弱引用 `std::weak_ptr<T>`      | 弱引用 `Weak<T>`                    |
| **数据结构**     | 动态数组`std::vector<T>`                       | 动态数组 `Vec<T>`                   |
|                  | 基于红黑树的有序映射 `std::map<K, V>`          | 基于B树的有序映射 `BTreeMap<K,V>`   |
|                  | 基于哈希表的无序映射 `std::unordered_map<K,V>` | 基于哈希表的无序映射 `HashMap<K,V>` |
|                  | 基于红黑树的有序集合 `std::set<T>`             | 基于B树的有序集合 `BTreeSet<T>`     |
|                  | 基于哈希表的无序集合 `std::unordered_set<T>`   | 基于哈希表的无序集合 `HashSet<T>`   |
| **并发与多线程** | `std::thread`、`std::mutex`                    | `std::thread`、`Mutex`              |
| **面向对象编程** | 抽象类                                         | `trait` 定义接口                    |
|                  | 多态                                           | `dyn trait` 动态分发                |
| **泛型与模板**   | `template<typename T>` 定义泛型函数或类        | `fn foo<T>(x: T)` 定义泛型函数      |

### Rust 语言本身

#### 用Rust获得安全的同时可能会影响效率，考虑效率优先还是安全优先？

1. Rust 的设计哲学是**零成本抽象**，即在保证安全性的同时，尽量不引入额外的运行时开销。然而，在某些情况下，为了追求更高的效率，可能需要放松一些安全约束
2. 在对性能要求比较高的场景中，可能需要优先考虑效率，如使用 `unsafe` 代码、使用内联汇编（`asm!` 宏）直接编写底层指令
3. 在大多数情况下，安全性仍是首要考虑的因素，尤其是它用来开发一些关键基础设施，如OS、区块链、金融系统等，安全性至关重要，而且项目长期维护，也可以减少潜在的bug

#### Rust 优势

- 内存安全，并发安全，无gc

#### Rust 常用的设计模式

#### Rust 程序有哪些 section，由什么组成？程序启动的过程？

1. 程序在编译后会生成一个二进制文件，该文件包含多个 **section**（段），是程序在内存中的逻辑分区，包括：
   - 代码段 `.txt`
     - 包含程序的机器指令（即编译后的代码）
   - 数据段
     - `.data`：**已初始化**的全局变量和静态变量
     - `.bss`：**未初始化**的全局变量和静态变量
     - `.rodata`：只读数据（如字符串常量）
   - 堆 （Heap）
     - 动态分配的内存区域，用于存储运行时分配的数据（如 `Box`、`Vec` 等）
   - 栈 （Stack）
     - 用于存储函数调用的局部变量、参数和返回地址
     - 栈是 LIFO（后进先出）结构，由编译器自动管理
   - 元数据段
     - **Rust 特有的 section**，包含程序的元信息，如 panic 处理函数、堆栈展开信息等
2. 一个典型的 Rust 程序由以下部分组成：
   - 入口函数 `main`
   - 依赖库 `crate`，通过 `Cargo.toml` 文件管理
   - 模块 `mod`，可以通过 `mod` 组织代码，可以嵌套
   - 全局变量，需要通过 `lazy_static` 或 `OnceCell` 等机制实现延迟初始化
3. 程序启动过程可以分为以下几个阶段：
   - 加载程序
     - 操作系统将程序的二进制文件加载到内存中
     - 解析程序的 section（如 `.text`、`.data`、`.bss` 等）
   - 初始化运行时
     - 设置堆栈、初始化全局变量等
     - Rust 的运行时（runtime）非常轻量，主要负责堆栈展开（unwinding）和 panic 处理
   - 调用 `main` 函数
     - `main` 是代码实际入口
   - 执行用户代码
     - 按逻辑执行
   - 程序结束
     - `main` 返回时，程序结束
     - 释放所有资源（如堆内存、文件句柄等）

#### 为何部分库强调支持 `no_std` 环境？

1. **应用场景**：

   - **嵌入式开发**：无操作系统环境（如ARM Cortex-M）

   - **内核开发**：操作系统内核等特权环境

   - **极致优化**：避免标准库开销（如WASM微服务）


2. **限制与解决方案**：

   - 无堆分配 → 使用`alloc` crate+自定义全局分配器

   - 无线程 → 基于中断的并发模型

   - 无文件系统 → 实现`Read/Write` trait对接硬件

#### **为何不启用 Cargo 依赖的全部功能？Rust 的未用代码清除机制是否足够？**

1. **禁用全特性的原因**：
   - **编译时间**：未用特性仍可能导致额外编译
   - **依赖冲突**：不同特性可能引入不兼容的依赖版本
   - **条件控制**：通过`cfg`精细控制平台特定代码

2. **Rust的未用代码清除**：

   - 虽然会消除未使用的函数（dead code elimination）

   - 但泛型实例化和宏展开仍可能引入冗余代码

## 基本类型

### 数值

### 字符、布尔、单元

### 语句与表达式

### 函数

## 复合类型

### 字符串与切片

#### `&str` 与 `String`

- `&str`：
  - 字符串字面量，在编译期就固定，所以是指向了程序二进制可执行文件中的某一处
  - 是 `str` 的**不可变**引用，快速且高效
  - 使用 UTF-8 编码
- `String`
  - 在堆上分配编译时位置大小的内存，可增长、可改变且具有所有权
  - 在程序运行时需要：
    - 向OS请求内存来存放 `String` 对象
    - 在使用完成后，将内存释放，还给OS
  - 不可以用下标操作，要么用 `.chars()`，要么用 `.bytes()`
  - 使用 UTF-8 编码

#### 为何选择使用 `str` 而非 `String`？

1. **轻量**
   - `str` 不存储容量等额外元数据，作为引用传递时仅涉及指针和长度，零开销传递
   - `String` 需要存储容量、长度、堆指针，完整克隆需要堆内存复制
2. **不可变**
   - 不可变借用，多个线程可同时读取同一 `&str` 无需同步
3. **栈分配 vs 堆分配**
   - `&str` 存在栈上，而 `String` 总是需要堆分配

### 元组

### 结构体

### 枚举

### 数组

### 动态数组 `vector`

### KV存储 `HashMap`

## 深入类型

### 类型转换、类型别名

### `Sized` 和DST

#### `Sized` 的含义

- 用于表示一个类型的大小在编译时已知且固定，即所有在编译时能计算出确切的内存大小的类型，才会实现 `Sized` trait
- 所有在 Rust 中的类型默认都会实现 `Sized`，除非显式地标记为不实现 `Sized`（例如，某些类型如切片、动态大小类型DST等）
- 通常不需要手动实现 `Sized`
- 没有实现 `Sized` trait 的类型无法直接作为普通的值使用，必须通过引用 `&`来处理
- `?Sized` 表示一个泛型类型可以是**动态大小类型**

## 所有权和借用

### 所有权

#### 管理内存的方式

1. **垃圾回收机制**（GC）：在程序运行时不断寻找不再使用的内存，典型代表：Java、Go
2. **手动管理内存的分配和释放**：在程序中，通过函数调用的方式来申请和释放内存，典型代表：C++
3. **所有权管理内存**：编译器在编译时会根据一系列规则进行检查，这种检查只发生在编译期，因此对于程序运行期，不会有任何性能上的损失，典型代表：Rust
   - Rust的所有权规则：
     - 每一个值都被一个变量所拥有，该变量被称为值的所有者
     - 一个值同时只能被一个变量所拥有，或者说一个值只能拥有一个所有者
     - 当所有者（变量）离开作用域范围时，这个值将被丢弃(drop)

#### 堆和栈

- **栈**
  - 内存从高位地址向下增长，栈内存连续分配
  - Rust中 `main` 线程的栈大小是8MB，普通线程是2MB
  - 函数调用时会在栈中创建临时栈空间，调用结束后栈空间中的对象自动进入 `Drop` 流程，最后栈顶指针自动移动到上一个调用栈顶
  - 性能往往更高，但不绝对
- **堆**
  - 内存从低位地址向上增长，堆内存通常只受物理内存限制，通常不连续
  - Rust堆上对象都拥有一个所有者
  - 赋值发生的是所有权的转移（只需浅拷贝栈上的引用或智能指针即可），堆中内容不变
- **性能问题**
  - 小型数据，在栈上的分配性能和读取性能都要比堆上高
  - 中型数据，栈上分配性能高，但是读取性能和堆上并无区别，因为无法利用寄存器或 CPU 高速缓存，最终还是要经过一次内存寻址
  - 大型数据，只建议在堆上分配和使用

#### 怎么判断数据分配在栈上还是分配在堆上?

- Rust 的内存管理模型非常清晰，所以分配在哪里取决于数据的类型和创建方式
- 栈上分配的数据：
  - 基本数据类型：如 `i32`, `f64`, `bool`等
  - **固定大小**的复合类型：元组、数组、结构体等
  - 函数内部局部变量
- 堆上分配的数据：
  - **动态大小**的类型：如 `String`, `Vec<T>`, `Box<T>` 等
  - 智能指针管理的数据：如 `Box<T>`, `Rc<T>`, `Arc<T>`等

#### 深拷贝与浅拷贝

- 深拷贝（克隆）
  - 任何**自动**的复制都不是深拷贝
  - 深度复制**堆**上的数据，而不仅仅是栈上的数据
  - 使用 `clone` 是深拷贝
  - 性能较差
- 浅拷贝（拷贝）
  - 只发生在**栈**上
  - 性能很高
  - `Copy` trait 实现的是浅拷贝
  - =所有权的转移

### 引用与借用

#### 定义

| 概念         | 引用(Reference)                 | 借用(Borrowing)                  |
| :----------- | :------------------------------ | :------------------------------- |
| **表现形式** | 具体的指针类型（`&T`/`&mut T`） | 语言层面的抽象规则               |
| **关注点**   | 内存访问方式                    | 所有权临时转移的约束规则         |
| **语法实体** | 是具体的Rust类型                | 是编译器的静态检查规则           |
| **生命周期** | 显式或隐式携带生命周期标注      | 通过借用检查器验证生命周期有效性 |

#### 为何倾向于使用 `AsRef<T>` 而非 `&[T]`？

1. **接口通用性**：`AsRef<T>` 可以接受任何能转换为 `&T` 的类型，包括 `String`, `Vec<T>`, `&str` 等，而 `&[T]` 只能切片引用
2. **所有权要求**：`AsRef<T>` 无特殊要求，而 `&[T]` 要求调用者必须已有切片引用

```rust
// 例子
fn process_path<P: AsRef<Path>>(path: P) {
    let path = path.as_ref();
    // 统一处理所有路径类型
}

// 可接受多种参数形式
process_path("a.txt");      // &str
process_path(String::from("b.txt")); // String
process_path(PathBuf::from("c.txt")); // PathBuf
```



## 模式匹配

### `match` 和 `if let`

### 解构 `Option`

### 模式适用场景

### 全模式列表

## 泛型和特征

### 泛型

泛型是零成本抽象，获得了巨大的性能，但损失了编译速度和二进制可运行文件的大小。Rust 在编译时进行泛型代码的**单态化**，这正是运行时高效的原因。

#### 为何在泛型函数中优先实现 `From<T>` trait 而非直接接受 `T` 参数？

1. **多源转换支持**：前者更具有扩展性优势，通过实现多个 `From` 变体支持多种输入类型
2. **错误处理统一**：`From` trait天然与 `?` 操作符协同工作
3. **类型推导友好**：编译器能自动推断转换路径



1. 
2. 为何 Default trait 对泛型结构体的 #[derive(Default)] 有特殊要求？（自动派生条件、字段类型约束的传播）
3. 为何 serde 库的 deserialize 函数常返回 Result<T, E> 而非直接 T？（错误处理的必要性、部分解析与回滚机制）

### 特征

特征定义了一组可以被共享的行为，只要实现了特征，就能使用这组行为

#### 孤儿规则

如果想要为类型 `A` 实现特征 `T`，那么 `A` 或者 `T` 至少有一个是在当前作用域中定义的，比如不可以为 `Vector` 类型实现 `Display` 特征，因为它们都定义在标准库中

要绕过孤儿规则，可以使用 `newtype` 模式，从而为外部类型实现外部特征，比如要为 `Vector` 实现 `Display`：

```rust
use std::fmt;

struct Wrapper(Vec<String>);

impl fmt::Display for Wrapper {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "[{}]", self.0.join(", "))
    }
}

fn main() {
    let w = Wrapper(vec![String::from("hello"), String::from("world")]);
    println!("w = {}", w);
}
```

简而言之就是为一个元组结构体创建新类型，该元组结构体封装有一个字段，该字段就是希望实现特征的具体类型

#### 常用 trait 有哪些？

| Trait 名称           | 用途                                                         | 如何使用                                                     |
| -------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| `Copy`               | 允许按位复制类型的值                                         | 添加 `#[derive(Copy)]`                                       |
| `Clone`              | 允许显式复制类型的值                                         | 添加 `#[derive(Clone)]` 或手动实现 `clone` 方法              |
| `Eq`                 | 表示类型可以进行相等性比较                                   | 添加 `#[derive(Eq)]` 或手动实现 `eq` 方法                    |
| `PartialEq`          | 表示类型可以进行部分相等性比较                               | 添加 `#[derive(PartialEq)]` 或手动实现 `partial_eq` 方法     |
| `Ord`                | 表示类型可以进行全序比较                                     | 添加 `#[derive(Ord)]` 或手动实现 `cmp` 方法                  |
| `PartialOrd`         | 表示类型可以进行部分序比较                                   | 添加 `#[derive(PartialOrd)]` 或手动实现 `partial_cmp` 方法   |
| `Debug`              | 允许格式化输出调试信息                                       | 添加 `#[derive(Debug)]` 或手动实现 `fmt` 方法                |
| `Default`            | 允许为类型创建默认值                                         | 在类型定义上添加 `#[derive(Default)]` 或手动实现 `default` 方法 |
| `Hash`               | 允许将类型的值用作哈希表的键                                 | 在类型定义上添加 `#[derive(Hash)]` 或手动实现 `hash` 方法    |
| `Display`            | 允许格式化输出用户面向的信息                                 | 手动实现 `fmt` 方法                                          |
| `FromStr`            | 允许从字符串解析出类型的值                                   | 手动实现 `from_str` 方法                                     |
| `From`/`Into`        | 允许在不同类型之间转换值                                     | 手动实现 `from` 或者 `into` 方法                             |
| `AsRef`/`AsMut`      | 允许将值转换为引用或可变引用                                 | 手动实现 `as_ref` 或者 `as_mut` 方法                         |
| `Borrow`/`BorrowMut` | 允许将值借用为引用或可变引用，通常用于哈希表的键和集合元素的比较和查找 | 手动实现 `borrow` 或者 `borrow_mut` 方法                     |
| `Deref`/`DerefMut`   | 允许重载解引用运算符（*）以便自定义解引用行为。通常用于智能指针 | 手动实现 `deref` 或 `deref_mut` 方法                         |
| `Iterator`           | 表示一个迭代器，可以迭代产生一系列值，通常用于 for 循环和其他迭代操作。 | 手动实现 `next` 方法                                         |
| `Any`                | 允许在运行时进行有限的类型反射和动态类型处理，仅适用于 `'static'` 生命周期 |                                                              |

#### `Copy` 和 `Clone` 的区别？

- 共同点：两者都是用于进行值的复制的trait，`Copy` 是 `Clone` 的一个特例——所有实现了 `Copy` 的类型也会实现 `Clone`，但是反之则不成立。
- 不同点：

| 特征       | `Copy`                                                       | `Clone`                                                      |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 语义       | 简单的按位复制                                               | 深拷贝，通常会**在堆上分配新的内存并复制数据**               |
| 适用类型   | 基本类型，如整数、浮点数、布尔值等，通常**不涉及堆内存**     | 需要进行深度复制的类型，如 `String`、`Vec<T>`                |
| 自动化程度 | **自动复制**，无需显式调用方法                               | 需要**显式调用** `.clone()` 方法                             |
| 性能       | **高效**，**不涉及资源管理**（没有复杂、额外的内存分配、资源释放操作） | **相对较慢**，可能涉及堆内存分配和复制                       |
| 例子       | `i32`, `f64`, `char`, `[i32; 3]` 等，当一个类型实现了 `Copy` 特征时，可以直接对它进行赋值，或者通过传递参数时“复制”值，而不需要显式调用 `clone` 方法 | `String`, `Vec<T>`, `Box<T>`, `Rc<T>` 等，通过 `Clone`，类型的实例会创建一个新的副本 |

- **为何 `#[derive(Clone)]` 对包含引用的结构体可能产生误导？如何手动实现？**

  - 由于Rust严格的所有权系统和内存安全保证，`Clone` trait 的自动派生对于包含引用的结构体会产生一些微妙的语义问题：

    - 当结构体包含引用时，`#[derive(Clone)]` 只会复制引用本身（即指针），不复制引用指向的数据
    - 自动派生的 `Clone` 实现会保留原始生命周期约束，可能导致不必要的限制

  - 手动实现解决方案：

    - 当需要真正的值拷贝而非指针拷贝时，应手动实现：

      ```rust
      #[derive(Clone)]
      struct ProperDeepCopy {
          data: String,  // 直接拥有数据
      }
      
      // 或者使用智能指针
      struct RefDeepCopy<'a> {
          data: Arc<&'a str>,  // 通过Arc共享
      }
      
      impl<'a> Clone for RefDeepCopy<'a> {
          fn clone(&self) -> Self {
              Self {
                  data: self.data.clone(),  // 增加引用计数
              }
          }
      }
      ```

    - 对于包含引用和自有数据的复合结构：

      ```rust
      struct MixedData<'a> {
          owned: Vec<u8>,
          borrowed: &'a [u8],
      }
      
      impl<'a> Clone for MixedData<'a> {
          fn clone(&self) -> Self {
              Self {
                  owned: self.owned.clone(),    // 深拷贝Vec
                  borrowed: self.borrowed,      // 浅拷贝引用
              }
          }
      }
      ```

    - 生命周期处理

      ```rust
      struct Flexible<'a, 'b> {
          a: &'a str,
          b: &'b [u8],
      }
      
      impl<'a, 'b> Clone for Flexible<'a, 'b> {
          fn clone(&self) -> Self {
              Self {
                  a: self.a,
                  b: self.b,
              }
          }
      }
      // 若涉及嵌套引用
      struct Complex<'a, T: 'a> {
          data: &'a T,
          marker: std::marker::PhantomData<&'a T>,
      }
      
      impl<'a, T> Clone for Complex<'a, T> {
          fn clone(&self) -> Self {
              Self {
                  data: self.data,
                  marker: std::marker::PhantomData,
              }
          }
      }
      ```

#### 为何 `Iterator::collect` 依赖 `FromIterator` trait 而非直接构造容器？

```rust
let nums = vec![1, 2, 3];
let set: HashSet<_> = nums.into_iter().collect(); // 依赖FromIterator
```

1. **容器无关性**：同一迭代器可生成`Vec`/`HashSet`等
2. **惰性构造**：迭代过程中逐步构建容器
3. **零成本抽象**：编译后等价于手写构造代码

#### 为何 `impl` Trait 在返回位置与参数位置的行为不同？何时选择泛型？

本质区别：

1. **参数位置**：语法糖，等价于泛型参数

   ```rust
   fn foo(arg: impl Debug) {} 
   // 等价于
   fn foo<D: Debug>(arg: D) {}
   // D:Debug称为特征约束
   ```

2. **返回位置**：存在类型擦除，实际返回具体实现的匿名类型

   在一种场景下非常有用，那就是返回的真是类型非常复杂，不知道该怎么声明，而Rust又要求必须标出所有的类型，此时就可以用 `impl Trait` 的方式简单返回

   但这种返回值方式有限制，只能返回一个具体的类型，如果有两个具体类型都实现了 `Iterator` 特征，也不能在 `if` 中返回A而在 `else` 中返回B，想要返回不同类型的话需要用特征对象

   ```rust
   fn bar() -> impl Iterator { it }
   // 返回一个实现了Iterator特征的类型，也就是迭代器
   ```

选择策略：

| 场景             | 推荐方式           | 原因                     |
| :--------------- | :----------------- | :----------------------- |
| 需要多种输入类型 | 参数位置impl Trait | 保持调用灵活性           |
| 返回闭包或迭代器 | 返回位置impl Trait | 避免暴露复杂的具体类型   |
| 需要静态分发     | 泛型参数           | 允许针对不同类型特化实现 |
| 需要动态分发     | trait对象          | 运行时多态场景           |

性能影响：

- 静态分发（泛型/`impl` Trait参数）：编译时生成特化代码，零运行时开销
- 动态分发（trait对象）：需要虚表查找，但有更好的代码体积控制

### 特征对象

需要在运行时从 `vtable` 动态查找需要调用的方法

#### `dyn` 关键字

- 只用在特征对象的类型声明上，在创建时无需使用 `dyn`
- 不能单独作为特征对象的定义，比如 `fn draw(x: dyn Draw){...}` 会报错，因为特征对象可能是任意实现了某个特征的类型，编译器在编译期不知道该类型的大小，而 `&dyn` 和 `Box<dyn>` 在编译期都是已知大小，所以可以用作特征对象的定义

#### 鸭子类型

- duck typing
- 只关心值长啥样，而不关心它实际是什么。当一个东西走起来像鸭子，叫起来像鸭子，那么它就是一只鸭子，就算它实际上是一个奥特曼，也不重要，我们就当它是鸭子
- 使用特征对象和 Rust 类型系统来进行类似鸭子类型操作的优势是：无需在运行时检查一个值是否实现了特定方法或者担心在调用时因为值没有实现方法而产生错误。如果值没有实现特征对象所需的特征， 那么 Rust 根本就不会编译

#### 什么时候要使用特征对象

- 以下两段代码分别是使用特征对象和使用泛型+特征约束：

  ```rust
  // 使用特征对象
  pub struct Screen {
      pub components: Vec<Box<dyn Draw>>,
  }
  
  
  impl Screen {
      pub fn run(&self) {
          for component in self.components.iter() {
              component.draw();
          }
      }
  }
  // components里面可以存A，B，C...只要它们实现了Draw trait
  ```

  ```rust
  // 使用泛型+特征约束
  pub struct Screen<T: Draw> {
      pub components: Vec<T>,
  }
  
  impl<T> Screen<T>
      where T: Draw {
      pub fn run(&self) {
          for component in self.components.iter() {
              component.draw();
          }
      }
  }
  // 这种写法限制了Screen实例的Vec<T>中的每个元素必须全是A或全是B
  ```

  - 综上，如果只需要相同类型的集合，更倾向于采用泛型+特征约束，因为实现更清晰，而且性能更好，在异构集合处理的时候可以用动态分发
  - 建议混合使用，以静态分发为主尤其是热点路径

#### 动态分发与静态分发

1. **静态分发**

   - 泛型是在**编译期**完成处理的，编译器为每一个泛型参数对应的具体类型生成一份代码
   - 对运行期性能完全没有影响
   - 虽然代码膨胀、但是对优化友好

2. **动态分发**

   - 直到**运行时**才能确定需要调用什么方法，即运行时多态，通过虚表查找实际方法
   - 有固定开销是每次调用需额外指针跳转，还有内存访问可能引起缓存未命中带来的更多开销
   - 类型擦除，运行时丢失具体类型信息
   - 代码体积稳定

   ![](C:/Users/Lenovo/Desktop/JN/找工作/notes/src/utils/dyn.jpg)

   - 虽然特征对象没有固定大小，但它的引用类型如 `&dyn Draw`、`Box<dyn Draw>` 大小是固定为两个指针大小的
     - `ptr` 指向实现了特征 `T` 的具体类型的实例
     - `vptr` 指向一个虚表 `vtable`，其中保存了类型的实力对于可以调用的实现于特征 `Draw` 的方法，当调用方法时，直接从 `vtable` 中找到方法并调用
     - 比如，类型 `A` 实现了特征 `T`，类型 `A` 的实例对象 `a` 可以当作特征 `T` 的特征对象类型来使用，`a` 中保存了作为特征对象的数据指针（指向类型 `A` 的实例数据）和行为指针（指向 `vtable`）。此时的 `a` 是 `T` 的特征对象的实例，而不再是具体类型 `A` 的实例，而且 `a` 的 `vtable` 只包含了实现自特征 `T` 的那些方法（比如 `t`），因此 `a` 只能调用实现于特征 `T` 的 `t` 方法，而不能调用类型 `A` 本身实现的方法和类型 `A` 实现于其他特征的方法。**也就是说，`a` 是哪个特征对象的实例，它的 `vtable` 中就包含了该特征的方法。**

#### `Self` 与 `self`

1. `Self`：指代特征或方法类型的别名   
2. `self`：当前实例对象

#### 特征对象的限制

不是所有特征都能拥有特征对象，只有对象**安全的特征**才行，当一个特征的**所有方法**都有如下属性时，它的对象才是安全的：

1. 方法的返回类型不能是 `Self`
2. 方法没有任何泛型参数

比如 `Clone` 不是一个对象安全的特征，所以如果这样写会报错：

```rust
pub struct Screen {
    pub components: Vec<Box<dyn Clone>>,
}
```

#### 关联类型

1. **什么是关联类型？**

   关联类型是在特征定义的语句块中，声明一个自定义类型，这样就可以在特征的方法签名中使用该类型。比如标准库中的迭代器特征 `Iterator`有一个 `Item` 关联类型，用于替代遍历的值的类型：

   ```rust
   pub trait Iterator {
       type Item;
       fn next(&mut self) -> Option<Self::Item>;
   }
   // Self::Item指代类型实现中定义的Item类型，比如下面的Self::Item就表示u32:
   impl Iterator for Counter {
       type Item = u32;
       fn next(&mut self) -> Option<Self::Item> {
           // --snip--
       }
   }
   ```

2. 举例说明在自定义 trait 中定义并使用关联类型（associated type）的**具体场景及方式**

   - 使用关联类型而不用泛型主要是为了可读性，使用泛型的话需要在trait所有地方（比如函数头部）都写很多 `<T>`，类型定义复杂时更麻烦

     ```rust
     // 用关联类型
     pub trait Iterator {
         type Item;
         fn next(&mut self) -> Option<Self::Item>;
     }
     // 用泛型
     pub trait Iterator<Item> {
         fn next(&mut self) -> Option<Item>;
     }
     ```

     ```rust
     // 用关联类型
     trait Container{
         type A;
         type B;
         fn contains(&self, a: &Self::A, b: &Self::B) -> bool;
     }
     fn difference<C: Container>(container: &C) {}
     // 用泛型
     trait Container<A,B> {
         fn contains(&self,a: A,b: B) -> bool;
     }
     fn difference<A,B,C>(container: &C) -> i32
       where
         C : Container<A,B> {...}
     ```

   - 特别适合构建灵活且类型安全的**泛型容器**，用作类型抽象

     ```rust
     // 迭代器
     trait Container {
         type Item;  // 关联类型声明
         
         fn get(&self, index: usize) -> Option<&Self::Item>;
         fn push(&mut self, item: Self::Item);
         fn iter(&self) -> Iter<'_, Self::Item>;  // 使用关联类型
     }
     
     struct MyVec<T> {
         data: Vec<T>,
     }
     
     impl<T> Container for MyVec<T> {
         type Item = T;  // 关联类型具体化
         
         fn get(&self, index: usize) -> Option<&T> {
             self.data.get(index)
         }
         
         fn push(&mut self, item: T) {
             self.data.push(item);
         }
         
         fn iter(&self) -> std::slice::Iter<'_, T> {
             self.data.iter()
         }
     }
     ```

     ```rust
     // 图结构
     trait Graph {
         type Node: Hash + Eq;  // 带trait约束的关联类型
         type Edge;
         type NodeIter: Iterator<Item = Self::Node>;
         type EdgeIter: Iterator<Item = Self::Edge>;
         
         fn nodes(&self) -> Self::NodeIter;
         fn edges(&self, node: &Self::Node) -> Self::EdgeIter;
     }
     ```

3. **默认类型参数**

   - 主要作用：
     1. 减少实现的样板代码
     2. 扩展类型但是无需大幅修改现有的代码

   - 用的比较少



## 生命周期

### 简介

1. 概念：简单理解就是引用的有效作用域
2. 主要作用：避免悬垂引用
3. rust使用**借用检查器**来检查借用正确性，不允许借用生命周期更短的变量 
4. 存在多个引用时，编译器有时会无法自动推导生命周期，于是需要手动标注，不过标注并不会改变任何引用的实际作用域

### 生命周期消除

实际上对于编译器来说，每一个引用类型都有一个生命周期，但是有消除规则，所以不用每个引用都标注生命周期，比如：

```rust
fn first_word(s: &str) -> &str {
    let bytes = s.as_bytes();

    for (i, &item) in bytes.iter().enumerate() {
        if item == b' ' {
            return &s[0..i];
        }
    }

    &s[..]
}
```

因为函数的返回值是一个引用类型，对于引用只有两种情况：

1. 从参数获取
2. 从函数体内部新创建的变量获取（悬垂引用）

只能是情况1，而且也只有一个传入参数，编译器自动判定输入生命周期==输出生命周期，所以自然可以编译通过

三条消除规则：

- **每一个引用参数都会获得独自的生命周期**

  例如一个引用参数的函数就有一个生命周期标注: `fn foo<'a>(x: &'a i32)`，两个引用参数的有两个生命周期标注:`fn foo<'a, 'b>(x: &'a i32, y: &'b i32)`, 依此类推

- **若只有一个输入生命周期（函数参数中只有一个引用类型），那么该生命周期会被赋给所有的输出生命周期**，也就是所有返回值的生命周期都等于该输入生命周期

  例如函数 `fn foo(x: &i32) -> &i32`，`x` 参数的生命周期会被自动赋给返回值 `&i32`，因此该函数等同于 `fn foo<'a>(x: &'a i32) -> &'a i32`

- **若存在多个输入生命周期，且其中一个是 `&self` 或 `&mut self`，则 `&self` 的生命周期被赋给所有的输出生命周期**

  拥有 `&self` 形式的参数，说明该函数是一个 `方法`，该规则让方法的使用便利度大幅提升

### 静态生命周期

`'static` 表示引用可以和整个程序获得一样久，比如字符串字面量和特征对象

- `&'static`

  - 一个**引用**必须要活得跟剩下的程序一样久，才能被标注为 `&'static`，注意针对的仅仅是引用，而不是持有该引用的变量，对于变量来说，还是要遵循相应的作用域规则：

    ```rust
    n get_memory_location() -> (usize, usize) {
      // “Hello World” 是字符串字面量，因此它的生命周期是 `'static`.
      // 但持有它的变量 `string` 的生命周期就不一样了，它完全取决于变量作用域，对于该例子来说，也就是当前的函数范围
      let string = "Hello World!";
      let pointer = string.as_ptr() as usize;
      let length = string.len();
      (pointer, length)
      // `string` 在这里被 drop 释放
      // 虽然变量被释放，无法再被访问，但是数据依然还会继续存活
    }
    
    fn get_str_at_location(pointer: usize, length: usize) -> &'static str {
      // 使用裸指针需要 `unsafe{}` 语句块
      // 引用确实活得和程序一样久，因为这里可以直接取到对应字符串
      unsafe { from_utf8_unchecked(from_raw_parts(pointer as *const u8, length)) }
    }
    
    fn main() {
      let (pointer, length) = get_memory_location();
      let message = get_str_at_location(pointer, length);
      println!(
        "The {} bytes at 0x{:X} stored: {}",
        length, pointer, message
      );
      // 如果大家想知道为何处理裸指针需要 `unsafe`，可以试着反注释以下代码
      // let message = get_str_at_location(1000, 10);
    }
    ```

- `T:'static`

  - 在函数中，可能会约束 `T:'static`，即 `T` 必须活得和程序一样久，那么使用 `T` 的时候就必须要满足 `'static` 约束，但是使用 `&T` 的话只要确保 `&T` 的生命周期符合规则即可，不用非要 `'static`
  - **`<T: 'static>`意味着`T`是全局变量/常量吗？**
    - 不是，它的含义仅仅是 `T` 的生命周期是 `'static`，即生命周期足够长，可以持续到程序的整个运行期间

### 生命周期约束

通过形如 `'a:'b` 的语法，说明两个生命周期的长短关系，这个是表示 `'a` 活得至少和 `'b` 一样久。

`T:'a` 表示类型 `T` 必须比 `'a` 获得要久

### 为何需显式定义接收两个引用并返回值的作用域函数模板，即使编译能通过？

```rust
// 显式标注版（推荐）
fn longest<'a>(s1: &'a str, s2: &'a str) -> &'a str {
    if s1.len() > s2.len() { s1 } else { s2 }
}

// 隐式推断版（不推荐）
fn longest(s1: &str, s2: &str) -> &str { /* ... */ }
```

- **类型安全**：明确约束输入输出的生命周期关系
- **可读性**：作为API契约的一部分，帮助调用者理解约束
- **未来兼容**：避免编译器推断策略变化导致代码break

### 如何利用生命周期为引用切片（涉及两个不同生命周期）定义迭代器？

```rust
struct SliceIter<'a, 'b: 'a, T> {
    first: &'a [T],
    second: &'b [T],
    index: usize,
}

impl<'a, 'b, T> Iterator for SliceIter<'a, 'b, T> {
    type Item = &'a T;  // 统一到更短的生命周期

    fn next(&mut self) -> Option<Self::Item> {
        if self.index < self.first.len() {
            let item = &self.first[self.index];
            self.index += 1;
            Some(item)
        } else {
            let adj_index = self.index - self.first.len();
            self.second.get(adj_index).map(|x| unsafe {
                // 安全条件：'b outlives 'a
                std::mem::transmute::<&'b T, &'a T>(x)
            })
        }
    }
}
```

**关键点**：

1. `'b: 'a` 约束确保第二个切片生命周期覆盖第一个
2. 使用`transmute`需要`unsafe`并确保安全条件

## 返回值和错误处理

为何 Rust 的 panic! 不推荐用于常规错误处理？如何设计可恢复的错误策略？（崩溃安全哲学、catch_unwind 的适用边界）

## 函数式编程

对Rust函数式编程的理解？C是函数式编程吗？

### 闭包

### 迭代器

Rust使用迭代器的好处

- 惰性

## 智能指针

### 简介

#### 智能指针和引用的区别在于

1. 引用是最常见的指针，智能指针提供比引用更多的功能特性
2. 智能指针允许拥有同一个数据的多个所有权，跟踪每一个所有者并进行计数，所有都归还后智能指针和指向数据会被自动清理释放
3. 引用仅仅借用了数据，而智能指针可以拥有它们指向的数据、为其他人提供服务

#### 智能指针和结构体

智能指针往往基于结构体实现，它与普通结构体最大的区别为实现了 `Deref` 和 `Drop` 特征：

- `Deref` 可以让智能指针像引用那样工作，这样你就可以写出同时支持智能指针和引用的代码，例如 `*T`
- `Drop` 允许你指定智能指针超出作用域后自动执行的代码，例如做一些数据清除等收尾工作

#### 了解哪些智能指针？

- `String`，`Vec`
- `Mutex<T>`
- `Box<T>` 可以将值分配到堆上
- `Rc<T>`, `Arc<T>` 引用计数类型，允许多所有权存在；配套`Weak<T>` 不具有所有权， 只用来跟踪该指针指向的资源是否已被销毁
- `Ref<T>` 和 `RefMut<T>`，允许将借用规则检查从编译期移动到运行期进行



1. 

2. 举例说明 Cell 与 RefCell 的适用场景及用法区别。（例如内部可变性的编译时与运行时检查）

3. `Cell` 和 `RefCell`

   - 内部可变性

   - `Cell<T>`提供了一种内部可变的机制。可以通过`&self`修改内部的值，而无需通过`&mut self`。它是零开销的，但它的修改只能整体地修改，不能通过`&self`拿到内部的`&mut T`。

     另一种`RefCell<T>`则可以用`borrow`或`borrow_mut`通过`&self`拿到内部的 `&mut T`。但它是有运行时开销的，内部会记录当前的借用状态，是未被借用，还是被可变借用，还是被不可变借用，以及被不可变借用了多少次。

4. `BTreeMap` 的实现

   - B-Tree 是动态数目子节点，有分裂-合并操作的，对有 Cache 的现代 CPU 而言性能更好，比传统二叉树性能更好，因为它一次性拿比较多的数据出来可以填到一个 Cache Line 里

5. `RefCell` 大量使用时是正常现象吗？使用`RefCell` 有什么问题？

   - trait设计不合理，在需要 `&self`的方法上要改变内部状态。使用 `RefCell` 要遵循借用的使用规则，不然会导致运行时Panic

6. 为何 Cow<str> 优于直接使用 String 或 &str 处理混合场景？（借用/拷贝的智能选择、减少不必要的内存分配）

7. 为何 Rc<RefCell<T>> 可能导致运行时死锁？如何用类型系统规避？（内部可变性设计、编译期与运行期检查的权衡）

8. 为何 Box<dyn Error> 作为错误类型时需谨慎？如何设计可追踪的错误链？（trait 对象类型擦除、std::error::Error 的向下兼容性）

### `Deref` 与 `Drop`

智能指针的名称来源，主要就在于它实现了 `Deref` 和 `Drop` 特征，这两个特征可以智能地帮助我们节省使用上的负担：

- `Deref` 可以让智能指针像引用那样工作，就可以写出同时支持智能指针和引用的代码，如 `*T`
- `Drop` 允许你指定智能指针超出作用域后自动执行的代码，例如做一些数据清除等收尾工作

#### `Deref` 实现原理

当对某一持有智能指针的变量 `x` 进行解引用时，实际上Rust为我们调用了 `*(x.deref())`，先调用 `deref` 方法返回值的常规引用，然后通过 `*` 对常规引用进行解引用，最终获取到目标值

同时，还支持连续的 `Deref` 隐式转换，直到找到适合的形式为止：

```rust
fn main() {
    let s = Box::new(String::from("hello world"));
    display(&s)
}

fn display(s: &str) {
    println!("{}",s);
}
```

这里从 `Box` 通过连续的隐式转换变成 `&str`，首先 `Box` 被 `Deref` 成 `String`，然后再 `Deref` 成 `&str`，最终成功的匹配了函数参数，**以上所有都在编译期完成**，对运行时没有性能损耗

原则上说，只应该为自定义的智能指针实现 `Deref`，不要为自定义的其他类型变量实现

#### `Deref` 规则总结

一个类型为 `T` 的对象 `foo`，

1. 如果 `T: Deref<Target=U>`，那么，相关 `foo` 的引用 `&foo` 在应用的时候会自动转换为 `&U`
2. 当 `T: DerefMut<Target=U>`，可以将 `&mut T` 转换成 `&mut U`
3. 当 `T: Deref<Target=U>`，可以将 `&mut T` 转换成 `&U`

#### `Drop` 的顺序

- **变量级别，按照逆序的方式**，`A` 在 `B` 之前创建，因此 `A` 在 `B` 之后被 `drop`
- **结构体内部，按照顺序的方式**，结构体 `A` 中的字段按照定义中的顺序依次 `drop`

#### `Drop` 使用场景

- 回收内存资源
- 执行一些收尾工作
- 不能为一个类型同时实现 `Copy` 和 `Drop`

在绝大多数情况下，我们都无需手动去 `drop` 以回收内存资源，因为 Rust 会自动帮我们完成这些工作，它甚至会对复杂类型的每个字段都单独的调用 `drop` 进行回收！但是确实有极少数情况，需要你自己来回收资源的，例如文件描述符、网络 socket 等，当这些值超出作用域不再使用时，就需要进行关闭以释放相关的资源，在这些情况下，就需要使用者自己来解决 `Drop` 的问题

### `Box` 堆对象分配

#### `Box<T>` 简介

- 是什么：

  - 最常见的智能指针，将一个值分配到堆上，然后在栈上保留一个智能指针指向堆上的数据

- 使用场景：

  - 特意的将数据分配在堆上
  - 数据较大时，又不想在转移所有权时进行数据拷贝
  - 类型的大小在编译期无法确定，但是我们又需要固定大小的类型时
  - 特征对象，用于说明对象实现了一个特征，而不是某个特定的类型

- 如何使用：

  - 以下代码将一个长度为1000的数组放在堆上，然后使用一个智能指针指向它，`arr`持有了该指针，转移所有权给 `arr1` 时会复制栈中的指针给 `arr1`，然后让 `arr` 失效

    ```rust
    let arr = Box::new([0;1000]);
    let arr1 = arr;
    ```

- 实现原理：

  - 调用 `jemalloc` 做内存管理

### `Rc` 与 `Arc`

#### 简介

`Rc` （单线程）与 `Arc` （多线程）通过引用计数的方式，允许一个数据资源在同一时刻拥有多个所有者

1. `Rc<T>`

- 引用计数，通过记录一个数据被引用的次数来确定该数据是否正在被使用。当引用次数归零时，就代表该数据不再被使用，因此可以被清理释放
- 当我们**希望在堆上分配一个对象供程序的多个部分使用且无法确定哪个部分最后一个结束时，就可以使用 `Rc` 成为数据值的所有者**
- `Rc::clone(&a)` 不是深拷贝，只是**复制了智能指针并增加了引用计数，没有克隆底层数据**，克隆后新变量和 `a` 共享堆上变量
- 是指向底层数据的**不可变引用**，如果需要改变内部值需要和 `RefCell` 一起使用，具体见下一节

2.`Arc<T>`

- 原子化的 `Rc<T>` 智能指针
- 原子化虽然可以带来线程安全，但是会有性能损耗，所以不需要线程安全的时候可以用 `Rc<T>`
- 和 `Rc<T>` API 完全一样，模块不一样
- 是指向底层数据的**不可变引用**，如果需要改变内部值需要和 `Mutex` 一起使用，具体见下一节

#### 为何 `Arc` 不直接实现 `DerefMut`？如何安全地修改其内部数据？

- （原子引用计数的线程安全限制、Arc<Mutex<T>> 模式）

#### KDTree中父亲孩子相互引用，问 `Rc<T>` 和 `Weak<T>`



### `Cell` 与 `RefCell` 内部可变性

可以在拥有不可变引用的同时修改目标数据，which正常代码做不到，实现用了unsafe，但被安全封装。两者在功能上没有区别

#### `Cell`

-  `Cell<T>` **适用于 `T` 实现 `Copy` 的情况**，没有实现 `Copy` 的不能使用
-  实际开发中使用的不多

#### `RefCell`

- **用于引用**，实现编译期可变、不可变引用共存，但只是将报错从编译期推迟到运行时，从编译器错误变成了 `panic` 异常
- 适用于编译期误报或者一个引用被在多处代码使用、修改以至于难于管理借用关系时

#### 内部可变性

- 内部可变性：即使某个值是不可变的，你仍然可以在该值内部修改它的内容
- 需要用：
  - `Rc<T>` 和 `RefCell<T>` 结合：用于**单线程**中的内部可变性
  - `Arc<T>` 和 `Mutex<T>` 结合：用于**多线程**中的内部可变性

1. **`Rc`+`RefCell` 组合使用**

   - **单线程**的内部可变性

   - 前者可以实现一个数据拥有多个所有者，后者可以实现数据的可变性：

     ```rust
     use std::cell::RefCell;
     use std::rc::Rc;
     fn main() {
         let s = Rc::new(RefCell::new("我很善变，还拥有多个主人".to_string()));
     
         let s1 = s.clone();
         let s2 = s.clone();
         // let mut s2 = s.borrow_mut();
         s2.borrow_mut().push_str(", oh yeah!");
     
         println!("{:?}\n{:?}\n{:?}", s, s1, s2);
     }
     // 输出：
     // RefCell { value: "我很善变，还拥有多个主人, oh yeah!" }
     // RefCell { value: "我很善变，还拥有多个主人, oh yeah!" }
     // RefCell { value: "我很善变，还拥有多个主人, oh yeah!" }
     ```

     这份代码中，使用 `RefCell<String>` 包裹一个字符串，同时通过 `Rc` 创建了它的三个所有者：`s`、`s1`和`s2`，并且通过其中一个所有者 `s2` 对字符串内容进行了修改。由于 `Rc` 的所有者们共享同一个底层的数据，因此当一个所有者修改了数据时，会导致全部所有者持有的数据都发生了变化

   - **性能**方面，大致相当于没有线程安全版本的 C++ `shared_ptr` 指针，所以性能非常高

   - **内存**方面，比裸数据只多了三个 `usize/isize`，没有其他额外的负担

   - CPU损耗也非常低，但可能会导致缓存Miss，对热点代码使用时需要做好 `benchmark`

2. **`Arc`+`Mutex` 组合使用**

   - **多线程**的内部可变性

## 循环引用与自引用

### `Weak`

### 结构体

#### 如何创建一个自引用结构体？

- Rust 中的一个关键约束是**结构体中的字段不能直接引用结构体中的其他字段**，因为它们的生命周期通常是相互依赖的，这会导致生命周期不一致的问题

- 为了实现，需要借助 `Pin, UnsafeCell, RefCell` 等

  ```rust
  use std::cell::RefCell;
  use std::pin::Pin;
  
  struct SelfRef<'a> {
      data: String,
      data_ref: RefCell<Option<&'a str>>, // 通过 RefCell 包装引用，使其可以在运行时修改
  }
  
  impl<'a> SelfRef<'a> {
      // 构造函数，初始化 `SelfRef` 实例
      // 为了确保函数返回时数据的所有权不会被转移，将它放在堆上，唯一的访问方式就是通过指针
      fn new(data: String) -> Pin<Box<SelfRef<'a>>> {
          let mut self_ref = Box::pin(SelfRef {
              data: data,
              data_ref: RefCell::new(None), // 初始化引用为 None
          });
  
          // 设置数据引用为 `data` 的字符串切片
          let data_ref = &self_ref.data;
          *self_ref.data_ref.borrow_mut() = Some(data_ref);
  
          self_ref
      }
  
      // 获取引用，返回一个 `Option<&str>`，此时是借用数据
      fn get_data_ref(&self) -> Option<&str> {
          self.data_ref.borrow().clone()
      }
  }
  
  fn main() {
      let data = String::from("Hello, World!");
      let self_ref = SelfRef::new(data);
  
      // 访问自引用字段
      if let Some(data_ref) = self_ref.get_data_ref() {
          println!("{}", data_ref);
      }
  }
  ```



## 多线程并发编程

### 并发和并行

- 如果某个系统支持两个或者多个动作的**同时存在**，那么这个系统就是一个并发系统
- 如果某个系统支持两个或者多个动作**同时执行**，那么这个系统就是一个并行系统
- 现代计算机的**多核心并发**，即核心数为N，但所有任务是放在M个线程队列中，交给N个CPU核心去执行，实现了 `M:N` 的处理模型。在这种情况下，并发与并行是同时在发生的，所有用户任务从表面来看都在并发的运行，但实际上，同一时刻只有 `N` 个任务能被同时并行的处理
- Rust 标准库提供了**1:1 线程模型**（因为 Rust 要保持尽量小的运行时），即直接调用操作系统提供的创建线程的 API 来创建线程，最终程序内的线程数和该程序占用的操作系统线程数相等
- 第三方库如 `tokio` 使用 **M:N 线程模型**，牺牲性能来换取更精确的线程控制以及更小的线程上下文切换成本

### 多线程

#### 多线程编程的风险

由于多线程的代码是同时运行的，无法保证线程间的执行顺序，这会导致一些问题：

- 竞态条件(race conditions)，多个线程以非一致性的顺序同时访问数据资源
- 死锁(deadlocks)，两个线程都想使用某个资源，但是又都在等待对方释放资源后才能使用，结果最终都无法继续执行
- 一些因为多线程导致的很隐晦的 BUG，难以复现和解决

虽然 Rust 已经通过各种机制减少了上述情况的发生，但是依然无法完全避免上述情况（即**Rust不保证多线程行为正确**）

#### 线程是如何结束的

 `main` 线程是程序的主线程，一旦结束，则程序随之结束，同时各个子线程也将被强行终止。父线程结束后，子线程仍在持续运行，直到子线程的代码运行完成或者 `main` 线程的结束，但有两种情况线程中的代码不会执行完：

- 线程的任务是一个循环 IO 读取，任务流程类似：IO 阻塞，等待读取新的数据 -> 读到数据，处理完成 -> 继续阻塞等待 ··· -> 收到 socket 关闭的信号 -> 结束线程，在此过程中，绝大部分时间线程都处于阻塞的状态，因此虽然看上去是循环，CPU 占用其实很小，也是网络服务中最最常见的模型
- 线程的任务是一个循环，里面没有任何阻塞，包括休眠这种操作也没有，此时 CPU 很不幸的会被跑满，而且你如果没有设置终止条件，该线程将持续跑满一个 CPU 核心，并且不会被终止，直到 `main` 线程的结束

#### 多线程的性能

- 据不精确估算，创建一个线程大概需要 0.24 毫秒，随着线程的变多，这个值会变得更大，因此**线程的创建耗时是不可忽略的**，只有当真的需要处理一个值得用线程去处理的任务时，才使用线程，一些鸡毛蒜皮的任务，就无需创建线程了
- 创建合适的线程数量：当任务大部分时间处于阻塞态时，可以考虑增多线程数量，否则让线程数等于CPU核心数才是最好的
- 多线程的**开销往往是在锁、数据竞争、缓存失效**上，这些限制了现代化软件系统随着 CPU 核心的增多性能也线性增加的野心

### 线程同步：消息传递

#### 几种模型

1. 标准库提供了通道 `std::sync::mpsc` ：
   - 多发送者单接收者模型，也可以用作单发送者单接收者
   - 提供异步通道：无论接收者是否正在接收消息，消息发送者在发送消息时都不会阻塞
   - 提供同步通道：发送消息是阻塞的，只有在消息被接收后才解除阻塞
     - 异步通道的缓冲上限取决于内存大小，不要撑爆就行。因此，使用异步消息虽然能非常高效且不会造成发送线程的阻塞，但是存在消息未及时消费、最终内存过大的问题。在实际项目中，可以考虑使用一个带缓冲值的同步通道来避免这种风险。
2. 第三方库提供了 mpmc（多发送者多接收者） 或更高性能：
   - [**crossbeam-channel**](https://github.com/crossbeam-rs/crossbeam/tree/master/crossbeam-channel), 老牌强库，功能较全，性能较强，之前是独立的库，但是后面合并到了`crossbeam`主仓库中
   - [**flume**](https://github.com/zesterer/flume), 官方给出的性能数据某些场景要比 crossbeam 更好些

#### 使用通道的注意事项

1. 使用通道来传输数据，满足 FIFO 原则，同时也要**遵循 Rust 的所有权规则**：

   - 若值的类型实现了`Copy`特征，则直接复制一份该值，然后传输过去，例如之前的`i32`类型

   - 若值没有实现`Copy`，则它的所有权会被转移给接收端，在发送端继续使用该值将报错

2. 当通道关闭后，发送消息或接收消息将会报错。那么如何关闭通道呢？ 很简单：**所有发送者被`drop`或者所有接收者被`drop`后，通道会自动关闭**。这件事是在编译期实现的，完全没有运行期性能损耗！

3. 一个消息通道只能传输一种类型的数据，如果你想要传输多种类型的数据，可以为每个类型创建一个通道，也可以使用枚举类型来实现

#### 消息传递vs共享内存

共享内存可以说是同步的灵魂，因为消息传递的底层实际上也是通过共享内存来实现，两者的区别如下：

- 共享内存相对消息传递能节省多次内存拷贝的成本
- 共享内存的实现简洁的多
- 共享内存的锁竞争更多
- 消息传递类似一个单所有权的系统：一个值同时只能有一个所有者，如果另一个线程需要该值的所有权，需要将所有权通过消息传递进行转移。而共享内存类似于一个多所有权的系统：多个线程可以同时访问同一个值

**消息传递的主要适用场景：**

- 需要可靠和简单的(简单不等于简洁)实现时
- 需要模拟现实世界，例如用消息去通知某个目标执行相应的操作时
- 需要一个任务处理流水线(管道)时，等等

**共享内存的主要适用场景：**

- 需要简洁的实现以及更高的性能时

#### 何种场景下选择作用域线程参数而非消息传递？

一句话回答：当子线程需要访问父线程作用域内的变量时，优先选择**作用域线程**；当线程间仅需要传递数据，且数据可被转移所有权，使用**消息传递**

- **作用域线程**（如 `rayon`/`crossbeam`）

  - 定义：**受作用域控制的线程生命周期管理方式**，目的是让线程能安全地引用当前作用域中的局部变量，而不会引起悬垂引用的问题

  - 特点：在 Rust 中，像标准库的 `std::thread::spawn` 是**非作用域线程**，它要求传入 `'static` 生命周期的数据（即线程内部不能引用外部栈上的局部变量）。而 `crossbeam` 和 `rayon` 提供了**作用域线程（scoped threads）**，使得线程可以临时安全地借用当前作用域的局部变量

  - 场景：

    1. **子线程需要借用主线程的局部变量**：使用作用域线程可以安全借用父线程栈上的变量，这在标准线程模型中是不允许的（因为不能保证变量活多久）

       ```rust
       use crossbeam::thread;
       fn main() {
           let v = vec![1, 2, 3];
           thread::scope(|s| {
               s.spawn(|_| {
                   // 可以借用 v
                   println!("{:?}", v);
               });
           }).unwrap();
       }
       ```

    2. **在并行算法中，多个任务要并行处理同一数据结构的不同部分**：使用作用域线程可以避免复杂的同步、`clone` 或 `channel` 传递

       ```rust
       use crossbeam::thread;
       fn main() {
           let mut data = vec![1, 2, 3, 4, 5, 6];
           thread::scope(|s| {
               let (left, right) = data.split_at_mut(3);
               s.spawn(|_| left.iter_mut().for_each(|x| *x *= 2));
               s.spawn(|_| right.iter_mut().for_each(|x| *x *= 2));
           }).unwrap();
           println!("{:?}", data);
       }
       ```

- **消息传递**（如 `std::sync::mpsc` 或 `tokio::sync::mpsc`）

  - 特点：通过 `channel` 在线程间传递数据，具有隔离性、灵活性、安全性

  - 场景：

    1. **子线程和主线程之间传递数据，不需要共享变量**：如果只是为了在线程间传值，不需要访问共享变量，`channel`是更通用、解耦的方式

       ```rust
       use std::thread;
       use std::sync::mpsc;
       
       fn main() {
           let (tx, rx) = mpsc::channel();
           thread::spawn(move || {
               tx.send("hello").unwrap();
           });
           println!("{}", rx.recv().unwrap());
       }
       ```

    2. 线程是**长期运行**的，而不是临时任务：作用域线程必须在作用域内结束，但有些后台线程是“守护线程”或运行整个程序生命周期的，这种用 `channel` 更合适

### 线程同步：锁、信号量、condvar

#### Rust中的几种锁

- `Mutex<T>` 互斥锁
- `RwLock<T>` 读写锁
- `Condvar` 条件变量
- `Semaphore` 信号量
- `Once` 一次性初始化锁
- `Barrier` 屏障

#### 锁中毒

- 定义：线程在持有锁时发生 panic，锁会进入“中毒”状态，中毒的锁会记录 panic 信息，其他线程在尝试获取锁时会收到 `PoisonError`
- 必要性：一种保护机制，用于防止数据处于不一致状态。如果线程在持有锁时 panic，可能会导致共享数据被破坏，锁中毒提醒其他线程数据可能已损坏
- 处理方案：恢复数据并继续使用锁/丢弃锁并重新初始化数据

#### `Mutex<T>` 和 `RwLock<T>`

- **对 T 的要求有什么区别？**
  - `Mutex<T>` 要求 `T` 实现 `Send` 和 `Sync`
  - `Rwlock<T>` 要求 `T` 实现 `Send`，通常不要求 `Sync`
- **`RwLock` 的使用场景？**
  -  最适合用在**并发读多于写的情况**。它允许多个线程同时持有**读锁**，从而实现多个线程可以同时读取数据而不会发生竞争。如果有线程需要写数据，它会**请求写锁并阻塞所有其他的读和写操作**
  -  理想使用场景：共享数据的并发读取、频繁读取，少量写入（如缓存、配置读取、状态监控等场景，读取远远超过写入）
- **`Mutex` 的使用场景？**
  - 最适合用在**数据写操作比较频繁的情况**。`Mutex` 通过互斥锁确保同一时刻只有一个线程能够访问数据，适用于对数据进行单线程化访问的场景。
  - 理想使用场景：需要频繁修改数据，需要排他锁来保证数据一致性（比如状态更新、批量处理、缓存写入等场景）
  - 不知道哪个合适，统一使用`Mutex`，因为性能比 `RwLock` 好一点，同时还更简单

#### 条件变量 Condvar

配合 `Mutex` 一起使用，解决资源访问顺序的问题，可以让线程挂起，直到某个条件发生后再继续执行。使用 `std::sync::Condvar`

#### 信号量 Semaphore

在多线程中，另一个重要的概念就是信号量，使用它可以让我们精准的控制当前正在运行的任务最大数量。推荐使用 `tokio::sync::Semaphore`

### 线程同步：`Atomic` 原子操作

由于原子操作是通过指令提供的支持，因此它的**性能相比锁和消息传递会好很多**。虽然原子类型是无锁类型，但是无锁不代表无需等待，因为原子类型内部使用了`CAS`循环，当大量的冲突发生时，该等待还是得等待

p.s.：CAS：Compare and swap，过一条指令读取指定的内存地址，然后判断其中的值是否等于给定的前置值，如果相等，则将其修改为新的值

#### `Atomic` 使用场景

1. 并发原语的基石，对于高性能库的开发者、标准库开发者都非常常用
   - 无锁(lock free)数据结构
   - 全局变量，例如全局自增 ID
   - 跨线程计数器，例如可以用于统计指标
2. **和`Mutex`一样，`Atomic`的值具有内部可变性**，无需将其声明为`mut`

#### 内存顺序

内存顺序是指 CPU 在访问内存时的顺序，该顺序可能受以下因素的影响：

- 代码中的先后顺序
- 编译器优化导致在编译阶段发生改变(内存重排序 reordering)
- 运行阶段因 CPU 的缓存机制导致顺序被打乱

使用 `Atomic` 时，部分方法中可以通过参数限定内存顺序，该枚举有5个成员：

- **Relaxed**， 这是最宽松的规则，它对编译器和 CPU 不做任何限制，可以乱序
- **Release 释放**，设定内存屏障(Memory barrier)，保证它之前的操作永远在它之前，但是它后面的操作可能被重排到它前面
- **Acquire 获取**, 设定内存屏障，保证在它之后的访问永远在它之后，但是它之前的操作却有可能被重排到它后面，往往和`Release`在不同线程中联合使用
- **AcqRel**, 是 *Acquire* 和 *Release* 的结合，同时拥有它们俩提供的保证。比如你要对一个 `atomic` 自增 1，同时希望该操作之前和之后的读取或写入操作不会被重新排序
- **SeqCst 顺序一致性**， `SeqCst`就像是`AcqRel`的加强版，它不管原子操作是属于读取还是写入的操作，只要某个线程有用到`SeqCst`的原子操作，线程中该`SeqCst`操作前的数据操作绝对不会被重新排在该`SeqCst`操作之后，且该`SeqCst`操作后的数据操作也绝对不会被重新排在`SeqCst`操作前。

原则上，`Acquire` 用于读取， `Release` 用于写入，不知道怎么选择时优先选择 `SeqCst`

#### `Atomic` 能替代锁吗

不行

- 对于复杂的场景下，锁的使用简单粗暴，不容易有坑
- `std::sync::atomic`包中仅提供了数值类型的原子操作：`AtomicBool`, `AtomicIsize`, `AtomicUsize`, `AtomicI8`, `AtomicU16`等，而锁可以应用于各种类型
- 在有些情况下，必须使用锁来配合，例如使用`Mutex`配合`Condvar`

### `Send`, `Sync` 线程安全

#### 讲一下 `Send` 和 `Sync`

   - 两个标记特征（marker trait），用于保证**多线程并发编程的安全性**，主要作用是定义类型在多线程环境中的行为约束

   - 多线程编程的时候需要加上，编译器会自己推断一个结构是否 `Send`，是否 `Sync`

   - `Send`：

     - 表示类型的**所有权**可以安全地跨线程**传递**
     - 类型里的所有子类型需要实现 `Send`，成立的话该类型会自动派生 `Send`

   - `Sync`：

     - 表示类型的**不可变引用**可以安全地跨线程**共享**
     - 类型里的所有子类型需要实现 `Sync`，成立的话该类型会自动派生 `Sync`

   - 一个类型要在线程间安全的共享的前提是，指向它的引用必须能在线程间传递。因为如果引用都不能被传递，我们就无法在多个线程间使用引用去访问同一个数据了。所以，**若类型 T 的引用 `&T` 是 `Send`，则 `T` 是 `Sync`**

     比如 `RwLock<T>` 和 `Mutex<T>`，由于前者可以并发读，所以前者的 `T` 必定可以在线程间共享，`Mutex` 则相反，看源码可以得到印证：

     ```rust
     unsafe impl<T: ?Sized + Send + Sync> Sync for RwLock<T> {}
     
     unsafe impl<T: ?Sized + Send> Sync for Mutex<T> {}
     ```

   - **手动实现 `Send` 和 `Sync` 是unsafe的**，通常并不需要手动实现 Send 和 Sync trait，实现者需要使用`unsafe`小心维护并发安全保证

   - 绝大部分类型都实现了`Send`和`Sync`，常见的未实现的有：裸指针、`Cell`、`RefCell`、`Rc` 等

## 异步编程

异步编程是一个并发编程模型

### `async`

#### `async` vs 其他并发模型

- **OS 线程**， 最简单，也无需改变任何编程模型(业务/代码逻辑)，因此非常适合作为语言的原生并发模型，Rust 就选择了原生支持线程级的并发编程。但也有缺点，例如线程间的同步更加困难，线程间的上下文切换损耗较大。使用线程池在一定程度上可以提升性能，但是对于 IO 密集的场景来说，线程池还是不够。
- **事件驱动**， 常常跟回调( Callback )一起使用，性能相当好，最大的问题就是存在回调地狱的风险：非线性的控制流和结果处理导致了数据流向和错误传播变得难以掌控，还会导致代码可维护性和可读性的大幅降低，大名鼎鼎的 `JavaScript` 曾经就存在回调地狱。
- **协程(Coroutines)** 可能是目前最火的并发模型，`Go` 语言的协程设计就非常优秀，协程跟线程类似，无需改变编程模型，同时可以支持大量的任务并发运行。但协程抽象层次过高，导致用户无法接触到底层的细节，这对于系统编程语言和自定义异步运行时是难以接受的
- **actor 模型**是 erlang 的杀手锏之一，它将所有并发计算分割成一个一个单元，这些单元被称为 `actor` ，单元之间通过消息传递的方式进行通信和数据传递，跟分布式系统的设计理念非常相像。由于 `actor` 模型跟现实很贴近，因此它相对来说更容易实现，但是一旦遇到流控制、失败重试等场景时，就不太好用
- **async/await**，性能高，支持底层编程，同时又像线程和协程那样无需过多的改变编程模型，但有得必有失，`async` 模型的问题就是内部实现机制过于复杂，对于用户来说，理解和使用起来也没有线程和协程简单

Rust经过权衡取舍后最终选择**同时提供多线程编程和 `async` 编程**：

- 前者通过标准库实现，当无需那么高的并发时，例如需要并行计算时，可以选择它，优点是线程内的代码执行效率更高、实现更直观更简单
- 后者通过语言特性 + 标准库 + 三方库的方式实现，在你需要高并发、异步 `I/O` 时，选择它就对了

Rust 的异步编程实现的很好：

- **Future 在 Rust 中是惰性的**，只有在被轮询(`poll`)时才会运行， 因此丢弃一个 `Future` 会阻止它未来再被运行，可以将`Future`理解为一个在未来某个时间点被调度执行的任务。
- **Async 在 Rust 中使用开销是零**， 意味着只有你能看到的代码(自己的代码)才有性能损耗，看不到的(`async` 内部实现)都没有性能损耗，例如，你可以无需分配任何堆内存、也无需任何动态分发来使用 `async` ，这对于热点路径的性能有非常大的好处，正是得益于此，Rust 的异步编程性能才会这么高。
- **Rust 没有内置异步调用所必需的运行时**，但是无需担心，Rust 社区生态中已经提供了非常优异的运行时实现，例如大明星 [`tokio`](https://tokio.rs/)
- **运行时同时支持单线程和多线程**

#### `Tokio` vs `Async-std`？

- 这两个是主流的异步运行时库，都提供了异步 I/O、任务调度、并发工具

- `Tokio` ：
  - 目标：**高性能**、灵活性、可扩展性
  - 基于 Rust 的异步 I/O 库 `futures  实现的，提供一种高效的异步任务调度机制，从而编写高性能异步应用程序
  - 其核心是一个事件循环，负责监控 I/O 事件，并在事件发生时调度相应的异步任务
  - 最常见的应用场景是处理 I/O 密集型任务，如网络请求、文件读写等，**适合复杂、大规模应用**
  - 拥有丰富的生态，支持多种协议如 HTTP，gRPC，WebSocket
- `async-std` ：
  - 目标: **提供与 Rust 标准库一致的 API**，降低学习成本
  - 性能略微逊色，调度器使用全局线程池，**适合中小型应用**
  - 提供了很多异步版本的 stdlib 容器，如 `async-std::net`,`async-std::io` 等，更方便地编写异步应用程序，无需手动处理异步任务的调度
  - 最常见的应用场景是与标准库容器（`Vec`, `HashMap`）一起使用
  - 生态较少

#### 多线程编程 `thread` vs 异步编程 `Async`

- 这是两种主要的并发模型，各有优缺点，适用于不同的场景
- **`thread`：**
  - 特点：
    - 每个任务运行在独立的操作系统线程中
    - 充分利用多核CPU，**适合计算密集型任务**
    - 使用同步原语如 `Mutex`, `Condvar`, `Arc` 等管理共享状态
  - 缺点：
    - 线程的创建和销毁开销较大，**适合长时间运行的任务**，如并行计算
    - 线程间同步复杂，容易引入死锁或竞争条件
- **`Async`：**
  - 特点：
    - **基于任务进行调度**，使用异步运行时调度
    - 非阻塞I/O，**适合I/O密集型任务**，如web 服务器、数据库连接等等网络服务
    - 更轻量级，可以创建大量并发任务
    - 协作式调度，任务需要主动让出控制权，**适合高并发场景**
    - 任务切换的性能开销远低于使用多线程时的线程上下文切换
  - 缺点：
    - 调试和错误处理更加复杂
    - 需要深入理解异步编程模型
    - 编译器会为`async`函数生成状态机，然后将整个运行时打包进来，会造成编译出的二进制可执行文件体积显著增大
  - 底层实现
    - 基于线程封装了一个运行时，可以将多个任务映射到少量线程上，然后将线程切换变成了任务切换，后者仅仅是内存中的访问，因此高效很多
- **选取原则：**
  - 有大量 `IO` 任务需要并发运行时，选 `async` 模型
  - 有部分 `IO` 任务需要并发运行时，选多线程，如果想要降低线程创建和销毁的开销，可以使用线程池
  - 有大量 `CPU` 密集任务需要并行运行时，例如并行计算，选多线程模型，且让线程数等于或者稍大于 `CPU` 核心数
  - 无所谓时，统一选多线程
  - 也可以根据情况两者一起使用

#### `async/.await` 简单用法

使用 `async/.await` 可以让我们用同步的方式去编写异步的代码，**通过 `async` 标记的语法块会被转换成实现了`Future`特征的状态机。**与同步调用阻塞当前线程不同，当`Future`执行并遇到阻塞时，它会让出当前线程的控制权，这样其它的`Future`就可以在该线程中运行，这种方式完全不会导致当前线程的阻塞。

```rust
use futures::executor::block_on;

async fn hello_world() {
    hello_cat().await;
    println!("hello, world!");
}

async fn hello_cat() {
    println!("hello, kitty!");
}
fn main() {
    let future = hello_world();
    block_on(future);
}
```

上面代码中，`block_on` 是一个执行器，它会阻塞当前线程直到指定的 `Future` 完成。在`async fn`函数中使用`.await`可以等待另一个异步调用的完成，`.await` 不会阻塞当前线程，而是异步等待 `Future A` 的完成，在等待过程中，线程还可以继续执行其它的 `Future B`，实现并发处理的效果。

上面的代码并没有实现并发，只是用 `block_on` 顺序地推进主 `Future` 状态机，要实现并发可以这么写，需要使用 `join!` 或 `spawn` 等并发调度机制：

```rust
use futures::join;
use futures::executor::block_on;

async fn hello_cat() {
    println!("hello, kitty!");
}

async fn hello_dog() {
    println!("hello, doggy!");
}

async fn hello_world() {
    let ((), ()) = join!(hello_cat(), hello_dog());
    println!("hello, world!");
}

fn main() {
    block_on(hello_world());
}

```

#### `async/await` 是不是语法糖？

是，本质上是编译器帮助构造一个 `Future` 状态机，开发者能够少写很多代码，但它的实现不止表面上的语法简化

而它同时还有超越语法糖的本质创新，因为它实现了真正的**零成本抽象**：

- **无运行时开销**：不依赖垃圾回收或虚拟机
- **无动态分配**：小 `Future` 可完全栈分配
- **无类型擦除**：编译器静态知晓所有类型

还有**和语言系统的深度集成**：

- **生命周期系统**：正确处理跨 `await` 点的引用
- **所有权系统**：确保资源安全释放
- **Pin系统**：安全处理自引用结构

还有**执行模型的创新**：

- **协作式调度**：精确控制挂起点
- **唤醒机制**：通过`Waker`实现高效通知
- **取消语义**：通过`Drop`自动清理资源

#### 什么是 `async` 的优雅关闭？

- 指在程序退出时，确保所有异步任务都能正常完成，而不是强制终止。这对于释放资源、保存状态或完成未完成的操作非常重要
- 如何实现：
  - 监听关闭信号：使用 `tokio::signal` 或 `async-std::signal` 监听系统信号（如 `SIGINT` 或 `SIGTERM`）
  - 通知任务退出：通过通道（channel）或取消标志（`CancellationToken`）通知所有异步任务退出
  - 等待任务完成：使用 `JoinHandle` 或类似机制等待所有任务完成

#### `async` 的生命周期

`async fn` 函数如果拥有引用类型的参数，那它返回的 `Future` 的生命周期就会被这些参数的生命周期所限制，**参数必须比 `Future` 活得更久**。在一般情况下，在函数调用后就立即 `.await` 不会存在任何问题，但若 `Future` 被先存起来或发送到另一个任务或者线程，就可能存在问题了。

其中一个常用的解决方法就是将具有引用参数的 `async fn` 函数转变成一个具有 `'static` 生命周期的 `Future`（没看懂）

#### `async move`

`async` 允许我们使用 `move` 关键字来将环境中变量的所有权转移到语句块内，就像闭包那样，**好处**是你不再发愁该如何解决借用生命周期的问题，**坏处**就是无法跟其它代码实现对变量的共享

#### 多线程执行器下的注意事项

1. `Future` 可能会在线程间被移动，因此 `async` 语句块中的变量必须要能在线程间传递。 至于 `Future` 会在线程间移动的原因是：它内部的任何`.await`都可能导致它被切换到一个新线程上去执行。由于需要在多线程环境使用，意味着 `Rc`、 `RefCell` 、没有实现 `Send` 的所有权类型、没有实现 `Sync` 的引用类型，它们都是不安全的，因此无法被使用
2. 在 `.await` 时使用普通的锁不安全，例如 `Mutex` 。原因是，它可能会导致线程池被锁：当一个任务获取锁 `A` 后，若它将线程的控制权还给执行器，然后执行器又调度运行另一个任务，该任务也去尝试获取了锁 `A` ，结果当前线程会直接卡死，最终陷入死锁中。因此，为了避免这种情况的发生，需要使用 `futures` 包下的锁 `futures::lock` 来替代 `Mutex` 完成任务

### `Future` 与任务调度

#### 简单介绍 `Future`

`Future` trait 是 Rust 异步编程的核心，因为异步函数是异步编程的核心，而 `Future` 是异步函数的返回值和被执行的关键

`Future` trait 的定义用一句话就是：是一个能产出值的异步计算(虽然该值可能为空，例如 `()` )。将其源码简化就是：

```rust
trait SimpleFuture {
    type Output;
    fn poll(&mut self, wake: fn()) -> Poll<Self::Output>;
}

enum Poll<T> {
    Ready(T),
    Pending,
}
```

`Future` 需要被**执行器 `poll` (轮询)**后才能运行，通过调用该方法，可以推进 `Future` 的进一步执行，直到被切走为止（因为 `Future` 并不能保证在一次 `poll` 中就被执行完）。若在当前 `poll` 中， `Future` 可以被完成，则会返回 `Poll::Ready(result)` ，反之则返回 `Poll::Pending`， 并且安排一个 **`wake` 函数**：当未来 `Future` 准备好进一步执行时， 该函数会被调用，然后管理该 `Future` 的执行器(例如 `block_on`)会再次调用 `poll` 方法，此时 `Future` 就可以继续执行了。如果没有 `wake` 方法，那执行器无法知道某个 `Future` 是否可以继续被执行，除非执行器定期的轮询每一个 `Future`，确认它是否能被执行，但这种作法效率较低。而有了 `wake`，`Future` 就可以主动通知执行器，然后执行器就可以精确的执行该 `Future`。 这种“**事件通知 -> 执行**”的方式要远比定期对所有 `Future` 进行一次全遍历来的高效

这种 `Future` 模型允许将**多个异步操作**组合在一起，同时还**无需任何内存分配**。不仅仅如此，如果你需要同时运行多个 `Future`或链式调用多个 `Future` ，也可以通过无内存分配的状态机实现，例如：

```rust
trait SimpleFuture {
    type Output;
    fn poll(&mut self, wake: fn()) -> Poll<Self::Output>;
}
enum Poll<T> {
    Ready(T),
    Pending,
}

/// 一个SimpleFuture，它会并发地运行两个Future直到它们完成
/// 之所以可以并发，是因为两个Future的轮询可以交替进行，一个阻塞，另一个就可以立刻执行，反之亦然
pub struct Join<FutureA, FutureB> {
    // 结构体的每个字段都包含一个Future，可以运行直到完成.
    // 等到Future完成后，字段会被设置为 `None`. 这样Future完成后，就不会再被轮询
    a: Option<FutureA>,
    b: Option<FutureB>,
}

impl<FutureA, FutureB> SimpleFuture for Join<FutureA, FutureB>
where
    FutureA: SimpleFuture<Output = ()>,
    FutureB: SimpleFuture<Output = ()>,
{
    type Output = ();
    fn poll(&mut self, wake: fn()) -> Poll<Self::Output> {
        // 尝试去完成一个 Future `a`
        if let Some(a) = &mut self.a {
            if let Poll::Ready(()) = a.poll(wake) {
                self.a.take();
            }
        }
        // 尝试去完成一个 Future `b`
        if let Some(b) = &mut self.b {
            if let Poll::Ready(()) = b.poll(wake) {
                self.b.take();
            }
        }
        if self.a.is_none() && self.b.is_none() {
            // 两个 Future都已完成 - 我们可以成功地返回了
            Poll::Ready(())
        } else {
            // 至少还有一个 Future 没有完成任务，因此返回 `Poll::Pending`.
            // 当该 Future 再次准备好时，通过调用`wake()`函数来继续执行
            Poll::Pending
        }
    }
}
```

**真实的 `Future` trait**：

```rust
trait Future {
    type Output;
    fn poll(
        // 首先值得注意的地方是，`self`的类型从`&mut self`变成了`Pin<&mut Self>`:
        self: Pin<&mut Self>,
        // 其次将`wake: fn()` 修改为 `cx: &mut Context<'_>`，以为wake函数可以携带数据了
        cx: &mut Context<'_>,
    ) -> Poll<Self::Output>;
}
```

#### `Waker` 唤醒任务

`Waker` 提供了一个 `wake()` 方法，用于告诉执行器：相关的任务可以被唤醒了，此时执行器就可以对相应的 `Future` 再次进行 `poll` 操作

#### executor 执行器

`Future` 是惰性的，需要驱动它才会动，其中一个推动它的方式就是在 `async` 函数中使用 `.await` 来调用另一个 `async` 函数，但是这个只能解决 `async` 内部的问题，最外层的 `async` 函数则要**用执行器推动其运行**

执行器会管理一批 `Future` (最外层的 `async` 函数)，然后通过不停地 `poll` 推动它们直到完成。 最开始，执行器会先 `poll` 一次 `Future` ，后面就不会主动去 `poll` 了，而是等待 `Future` 通过调用 `wake` 函数来通知它可以继续，它才会继续去 `poll` 。这种 **wake 通知然后 poll** 的方式会不断重复，直到 `Future` 完成

#### 执行器和系统IO

怎么样检查 `Future` 有没有完成？一个简单粗暴的方法就是开一个新线程不停的检查是否完成，如果是就调用 `wake()`，虽然该方法可行但是性能太低，需要为每个阻塞的 `Future` 都创建单独的线程。实际上，该问题往往是通过OS提供的**IO多路复用机制**来完成的，例如Linux中的 `epoll`，从而实现一个线程同时阻塞地去等待多个异步IO事件，一旦某个事件完成就立即退出阻塞并返回数据。利用它，**只需要一个执行器线程**，就会接收 IO 事件并将其分发到对应的 `Waker` 中，接着后者会唤醒相关的任务，最终通过执行器 `poll` 后，任务可以顺利地继续执行, 这种 IO 读取流程可以不停的循环，直到所有任务完成

#### 为何 `async fn` 返回的 `Future` 默认不实现 `Send`？如何强制标记？

- 原因：主要是出于安全性和灵活性的考虑

  - **跨线程安全性**：生成的 `Future` 可能包含非 `Send` 类型（如 `Rc`、裸指针、非 `Send` 的结构体等），如果隐式标记为 `Send`，可能会导致数据竞争或未定义行为（UB），因为非 `Send` 类型可能被多个线程同时访问
  - **灵活性**：默认不实现 `Send` 可以让编译器更灵活地处理 `async fn` 的生成代码。

- 如果确定 `Future` 是线程安全的，可以这样强制标记：

  - 将 `Future` 装箱并标记为 `Send`

  ```rust
  use std::future::Future;
  use std::pin::Pin;
  
  async fn my_async_fn() -> i32 {
      // 异步代码
      42
  }
  
  fn spawn_send_future() {
      let future: Pin<Box<dyn Future<Output = i32> + Send>> = Box::pin(my_async_fn());
      // 可以将 future 跨线程传递
  }
  ```

  - 约束 `async` 块，显示标记为 `Send`

  ```rust
  use std::future::Future;
  
  fn spawn_send_future() {
      let future: Box<dyn Future<Output = i32> + Send> = Box::pin(async {
          // 异步代码
          42
      });
      // 可以将 future 跨线程传递
  }
  ```

### `Pin` 和 `Unpin` 

#### 关于 `Pin<T>`

- **作用是什么？**
  - 一个**结构体**，防止某个数据的内存位置移动
  - 在接口上体现为不让用户拿到 `&mut T`，确保指向数据的指针不能随意改变
  - 可以将值固定到栈上，也可以固定到堆上
- **为什么需要它？**
  - 核心目的：**允许安全地创建拥有自引用字段的结构体或 `future`**
  - 通常用于与异步编程和 `Future` 相关的场景
  - 因为异步任务会在运行时暂停和恢复，如果数据在这种暂停恢复过程中被移动了，可能会导致不可预期的行为，具体来说：
  - `Future` 的方法签名是 `Pin<&mut self>`，而 `Future` 本质上是一个通过状态机实现的无状态 generator，即运行时并不会为每个 generator 维护上下文的状态，这些状态都是通过编译器变成 `Future` 里的数据，而 `Future` 有可能会被传递、移动，`Future` 里面的数据存在自引用的情况，那么 `Future` 被移动的话，这些自引用的指针就会变成野指针，从而导致异常

#### 关于 `Unpin`

- 一个标记特征，表明一个类型可以随意被移动，可以被 `Pin` 住的值实现的特征是 `!Unpin`
- 如果类型实现了 `Unpin` 特征，就不能再 `Pin` 了（可以，但是无用）
- 绝大多数情况都是自动实现, 无需我们的操心

#### **为什么 `async/await` 需要 `Pin`**

**一句话总结**：因为异步状态机 `Future` 会捕获局部变量并可能引用自己。如果这些引用指向的是状态机自身的字段，而状态机又可能被移动，那引用就会悬空。为了解决这一“自引用 + 移动”冲突，要用 `Pin` 把 `Future` 固定在内存中，确保这些引用始终有效

`Future` trait 的 `poll` 方法的签名中有一个 `self: Pin<&mut Self>`，`async` 的底层会创建一个实现了 `Future` 的匿名类型，并提供一个 `poll` 方法，当  `poll` 第一次被调用时，它会去查询任务状态，若任务无法完成，则 `poll` 方法会返回，未来对 `poll` 的调用将从上一次调用结束的地方开始。该过程会一直持续，直到 `Future` 完成为止。然而，如果 `async` 语句块中**使用了引用类型**，比如：

```rust
async {
    let mut x = [0; 128];
    let read_into_buf_fut = read_into_buf(&mut x);
    read_into_buf_fut.await;
    println!("{:?}", x);
}
```

这段代码会被编译成：

```rust
struct ReadIntoBuf<'a> {
    buf: &'a mut [u8], // 指向下面的`x`字段
}

struct AsyncFuture {
    x: [u8; 128],
    read_into_buf_fut: ReadIntoBuf<'what_lifetime?>,  // 内部保存了一个&mmut x，导致构造自引用结构体
}
```

这里，`ReadIntoBuf` 拥有一个引用字段，指向了结构体的另一个字段 `x` ，一旦 `AsyncFuture` 被移动，那 `x` 的地址也将随之变化，而对 `x` 的引用却不会变，导致出现未定义行为，也就是 `read_into_buf_fut.buf` 会变为不合法的。若能将 `Future` 在内存中固定到一个位置，就可以避免这种问题的发生，也就可以安全的创建上面这种引用类型。

当编写 `async` 的时候，**Rust编译器会自动**：

- 分析 `async` 块中是否存在 **引用局部变量的 `future`**
- 如果存在，它会要求这个 `future` 必须是 **`!Unpin`** 的
- 如果你尝试把它 `.await` 前移动，Rust 会拒绝编译，除非你明确地把它 `pin`

#### 具体哪些情况需要 `Pin`

| 情况                                       | 是否安全           | 是否需要 Pin    |
| ------------------------------------------ | ------------------ | --------------- |
| `Future` 中只包含值（非引用）              | ✅ 安全             | ❌ 不需要 Pin    |
| `Future` 中保存了引用（如 `&mut x`）       | ❌ 不安全，可能悬空 | ✅ 需要 Pin 固定 |
| `Future` 立即 `.await` 不保存引用          | ✅ 安全             | ❌ 不需要 Pin    |
| `Future` 被保存到变量再 `.await`，且带引用 | ❌ 不安全           | ✅ 必须 Pin      |

#### 为什么 `Future` 默认是 `Unpin` 的？

Rust 出于 ergonomics（易用性）考虑，默认假设 `Future` 是可以安全移动的（`Unpin`），但是：

- **一旦包含引用或自引用结构**
- 或者需要嵌套多个 Future

就必须使用 `Pin` 显式表示这个 Future 不能再移动

**`async` 函数返回的 `Future` 默认是 `!Unpin` 的**

## 宏

1. **`#[inline(never)]` 的递归优化**

   ```rust
   // 递归函数
   #[inline(never)]
   fn factorial(n: u64) -> u64 {
       if n <= 1 { 1 } else { n * factorial(n-1) }
   }
   ```

   | 策略               | 优点         | 缺点           |
   | :----------------- | :----------- | :------------- |
   | 默认内联           | 减少调用开销 | 栈空间爆炸风险 |
   | `#[inline(never)]` | 控制栈深度   | 增加调用开销   |

2. **`#[repr(C)]` 的FFI必要性**

   ```rust
   #[repr(Rust)] // 默认（编译器可重排字段）
   struct RustStyle {
       a: u8,
       b: u32,
   } // 可能优化为4字节大小
   
   #[repr(C)] // C兼容布局
   struct CStyle {
       a: u8,
       b: u32,
   } // 固定为8字节（含padding）
   ```

   - **字段顺序保证**：C代码依赖固定偏移量
   - **大小和对齐**：跨语言传递时需精确匹配
   - **ABI兼容**：函数调用时的参数传递规则

3. 过程宏

## Unsafe

### 使用 `unsafe` 的5种操作

1. 解引用裸指针
   - **裸指针**（原生指针），如 `*const T`, `*mut T`，在功能上和引用类似，它可以：
     - 可以绕过Rust的借用规则，可以同时拥有一个数据的可变、不可变指针
     - 不能保证指向合法的内存
     - 可以是 `null`
     - 没有实现任何自动的回收
   - 创建裸指针是安全的行为，而解引用裸指针才需要 `unsafe`
2. 调用 `unsafe` 或其他语言的函数或方法
3. 实现 `unsafe` 特征
4. 访问或修改可变的静态变量
5. 访问 `union` 的字段
   - `union` 主要用于与C进行交互

### `unsafe` 意味着不安全吗？

- 不是，虽然是 `unsafe` 区域，但 Rust 仍然提供了强大的安全支撑，`unsafe` 并不能绕过 Rust 的借用检查，也不能关闭任何 Rust 的安全检查规则，例如在 `unsafe` 中使用**引用**时，该有的检查一样都不会少
- 仅仅是在上述5种操作中，编译器才不会进行内存安全方面的检查
- `unsafe` 的存在主要是因为 Rust 的静态检查强大且保守，导致当编译器在分析代码时，一些正确代码会因为编译器无法分析出它的所有正确性，结果将这段代码拒绝，导致编译错误
- 用了 `unsafe` 后需要人工替代编译器的部分职责来对其正确性和安全性负责任
- 系统编程必须要操作内存，`unsafe` 的存在是有其必要性的



1. 为何 unsafe 代码块中修改全局变量需使用 UnsafeCell 或原子操作？（未定义行为的触发条件、编译器优化的干扰）

### 控制 `unsafe` 的边界

- `unsafe` 语句块代表：即使出现了内存错误，也能立刻意识到错误是在 `unsafe` 代码块中而不是别的地方
- 写代码时要让 `unsafe` 边界尽量小，同时在外面包裹 `safe` 的 API

### 如何禁止模块内使用 `unsafe` 代码？

```rust
#![forbid(unsafe_code)]
// 或针对特定模块
mod safe_module {
    #![deny(unsafe_code)]
    
    // 任何unsafe代码将触发编译错误
}
```

**应用场景**：

- 安全关键代码库（如加密算法）
- 团队协作时强制安全约束
- 审计需求（如通过`cargo-geiger`检查）

## 包和模块

### 包

### 模块

#### 为何 `#[cfg(test)]` 模块外的单元测试可能引发问题？如何正确组织测试代码？

- `#[cfg(test)]` 是 **条件编译**，表示“仅在测试模式下编译这段代码”。它常用于定义内部测试模块，如果在 **`#[cfg(test)]` 模块外** 定义了测试逻辑（比如测试数据、辅助函数等），那么它在 **非测试编译**（即正常 `cargo build`、`cargo run`）时也会被编译，甚至被暴露

- 正确做法：

  - 把所有测试逻辑、mock、测试数据放在 `#[cfg(test)] mod tests` 内部或 `tests/` 集成测试目录中

  - 如果需要复用测试辅助函数，使用：

    ```rust
    #[cfg(test)]
    pub mod test_utils {
        pub fn generate_sample_data() -> MyStruct { ... }
    }
    ```

#### 将多模块置于同一文件而非分拆的考量？

在 Rust 中，每个模块默认可映射为一个文件，但你也可以在一个 `.rs` 文件中定义多个子模块，将模块放在同一个文件有以下考量：

- **模块规模非常小**（仅几百行），拆文件反而造成冗余。
- **逻辑强关联的子模块**（例如一个 `parser.rs` 文件里同时写 `tokenizer`、`ast`、`parser`）。
- **项目原型期 / demo 阶段**，快速验证不需要复杂结构。
- **减少目录层级**，提高可读性（特别是在多人协作时避免“点进去都是几行”的模块碎片化）。

#### 为何 Rust 不支持与其他 Rust 模块的共享/动态链接？

Rust 默认是**静态链接语言**，不鼓励/不支持像 C/C++ 那样的 **动态链接共享库（.so/.dll）** 机制用于多个 Rust crate 之间，原因包括：

1. **没有稳定 ABI（应用二进制接口）**

   - Rust 编译器每次升级都会可能改变函数/struct 的内存布局和调用方式。

   - 没有稳定 ABI 意味着两个版本的 Rust crate **无法以动态库方式共享代码**。

2. **静态链接更符合 Rust 的零成本抽象理念**

   - 每个 crate 会被单独编译，进行函数内联、去除未使用代码等优化（LTO）。

   - 静态链接能让 Rust 保证 **最终可执行文件行为可控、安全、可预测**。

3. **动态链接破坏类型安全**
   - 动态链接会绕过 Rust 的类型系统（无法在运行时验证 Trait、泛型等匹配），会引入 C/C++ 类似的 “link-time undefined symbol”、“运行时崩溃” 问题。

4. **动态链接也影响安全和封装**

   - Rust 的很多封装是靠编译时类型系统实现的。

   - 动态链接可能暴露内部实现、绕过封装边界。

## 学习时的难点

1. Rust代码虽然简洁，但可读性会弱一点，给我带来了一些困扰

   比如，`Deref` 特征让变量可以自动隐式转换，省去了编写代码的复杂度。但如果你不知道某个类型是否实现了 `Deref` 特征，那么在看到某段代码时，并不能在第一时间反应过来该代码发生了隐式的 `Deref` 转换。事实上，不仅仅是 `Deref`，在 Rust 中还有各种 `From/Into` 等等会给阅读代码带来一定负担的特征

2. 不知道智能指针为什么智能

   智能指它们自动管理资源的生命周期，而且可以自动解引用，封装了复杂的生命周期和所有权管理逻辑，让写代码时更简单

3. 搞不清 `String` 和 `&str` 的关系

   最开始写代码总在 `String` 和 `&str` 之间反复出错，直到我学习了底层结构才明白：

   - `String` 是一个拥有所有权的堆分配字符串，底层结构是 `Vec<u8>`。
   - `&str` 是对一段 UTF-8 字节切片的引用，通常是 `String` 的一部分。

   这个时候我才真正理解所有权和借用模型在 Rust 字符串中的体现。

4. `async/await` 和多线程不是一回事

   一开始我以为 Rust 的 async/await = 多线程，结果发现单线程 runtime 一样能跑很多任务。

   例如用 `async-std` 或 `tokio` 时：

   ```rust
   async fn do_work() { ... }
   
   #[tokio::main]
   async fn main() {
       let f1 = do_work();
       let f2 = do_work();
       futures::join!(f1, f2);
   }
   ```

   发现并发了好几个任务，但根本没开线程，甚至 CPU 一直只有一个核在跑。

   **原来 async 是协程，是协作式并发！**

   - **多线程** 是抢占式并发（由操作系统调度）。
   - **异步** 是用户态任务切换（由 runtime 调度），本质是一个 `state machine`。

   明白这一点后，我开始理解 `Future` 是啥、`.await` 是切点、为什么要用 `Pin` 和 `poll`

## 未分类问题

1. 为何为自定义 trait/结构体设计 into_inner() 方法？（例如释放内部资源所有权）

2. **`{struct A;std::mem::size_of::<A>()}`的值是多少？**

   - `std::mem::size_of::<A>` 返回的是类型 `A` 在内存中占用的字节数
   - 对于一个没有任何字段的结构体，会分配至少 1 字节的内存空间，**以便可以正确地实例化它并放置在栈上**

3. **什么时候会用到 `PhantomData`？**如何通过 PhantomData 标记未使用的生命周期或类型参数？需注意哪些陷阱？（零开销抽象、类型系统欺骗的合法性）

   - **所有权标记**：当希望一个类型“拥有”某个泛型参数，但实际上并不存储该类型的值时
   - **生命周期标记**：当需要表达一个类型与某个生命周期相关，但实际数据并不直接包含该生命周期时
   - **未使用的类型参数**：泛型类型中，如果某些类型参数未被直接使用，编译器可能会报错，用了这个类型就不会报错

4. **`fn`, `Fn`, `FnMut`, `FnOnce` 的区别**

   - `fn` 是定义函数的关键字，而另外三个是用于表示闭包类型的 trait
   - `Fn` 是最基本的闭包 trait，它表示闭包可以捕获其环境变量的**不可变引用**
   - `FnMut` 表示闭包可以捕获其环境变量的**可变引用**
   - `FnOnce` 表示闭包只能调用一次，即闭包可以**捕获其环境变量的所有权**
   - 所有的闭包都自动实现了 `FnOnce` trait，因此任何一个闭包都至少可以被调用一次
   - 没有移出所捕获变量的所有权的闭包自动实现了 `FnMut` 特征
   - 不需要对捕获变量进行改变的闭包自动实现了 `Fn` 特征

5. **调用 `.into_iter()` 而非 `.iter()` 的动机？**

   | 方法           | 所有权     | 适用场景         | 示例                     |
   | :------------- | :--------- | :--------------- | :----------------------- |
   | `.iter()`      | 借用       | 只读访问集合元素 | `for x in v.iter()`      |
   | `.into_iter()` | 转移所有权 | 需要消费集合     | `for x in v.into_iter()` |

6. 为何 std::mem::forget 不被标记为 unsafe？它如何绕过析构器？（资源泄漏的合法性、与 ManuallyDrop 的对比）

7. **为何 `mem::replace` 或 `take` 方法在结构体更新中至关重要？**

   ```rust
   // 更新结构体字段时的所有权问题
   struct Processor {
       buffer: String,
   }
   
   impl Processor {
       fn update(&mut self, new_data: String) -> String {
           // 必须取出旧buffer，同时放入新buffer
           std::mem::replace(&mut self.buffer, new_data)
       }
   }
   ```

   **技术原理**：

   - **所有权转移**：通过`&mut`引用实现"偷取"数据
   - **避免无效状态**：保证`Option`取值的原子性操作
   - **性能优势**：比`clone+replace`更高效（仅指针交换）

   **`take` 的特殊价值**：

   ```rust
   let mut opt = Some(42);
   let taken = opt.take(); // opt变为None，taken为Some(42)
   ```

   专为`Option`设计，语义比 `replace(&mut opt, None)`更清晰

   1. 为何优先使用 `Vec` 的 `pop`（顶部弹出）而非 `remove`（索引删除）？

      - 例如删除末尾元素更高效

   2. 为何在公开模块中直接扩展 Vec 的自定义实现，而非封装隐藏内部 Vec 的结构体？（反之的优缺点？）

   3. 若 BinaryHeap 性能弱于 BTreeSet（可能因场景而异），为何仍选择 BinaryHeap？（例如需优先级队列而非有序集合）

   4. 为何标准库的 HashMap 默认使用 SipHash 而非更快哈希算法？何时需替换？（DDoS 防护与性能的取舍、BuildHasher 定制场景）

   5. hashmap 和 concurrenthashmap

   6. **何时应避免使用 `BufReader`？**
      - 小文件读取
        - 此时直接读取更高效，否则缓冲区的管理开销可能超过收益
      - 需逐行处理的场景
        - 需要精确控制行边界时，直接处理字符串更可靠


## 简单编程题

1. **类型转换，`i32`是否可以传给`i64`形参？写一个泛型函数，同时支持`i64`和`i32`形参**

   - 是的，`i32` 可以转换为 `i64`，因为 `i64` 的范围更大，这是一种安全转换只要用 `as i64` （显式转换）或者 `.into()` （隐式转换）即可
   - `Into<i64>` 是一个 trait，表示可以将类型转换为 `i64`，约束泛型参数为 `Into<i64>`，可以同时支持 `i32` 和 `i64`
   - 注册自定义内存分配器（GlobalAlloc）。（例如在特定硬件环境下的内存管理）

   ```rust
   fn function<T: Into<i64>>(value: T) {
       let value_i64: i64 = value.into();
       println!("{}", value_i64);
   }
   
   fn main() {
       let x: i32 = 1;
       let y: i64 = 1;
       function(x);
       function(y);
   }
   ```

2. **写一个结构体，设置默认值并打印它**

   ```rust
   #[derive(Debug)]
   struct A {
       key: i64,
       value: i64,
   }
   
   // 为 A 实现 Default trait
   impl Default for A {
       fn default() -> Self {
           A {
               key: 1,
               value: 2,
           }
       }
   }
   
   fn main() {
       let a = A::default();
       println!("{:?}", a);
   }
   ```

3. 为任意可显示类型（Display）的迭代器定义扩展 trait，实现自定义格式化输出。（例如统一拼接为特定分隔符的字符串）

4. 使用引用计数智能指针（Rc/Arc）建模多对多关系，并使其满足 Sync 约束，最后封装到 Mutex 中。（例如图结构中的节点互引用）

5. 实现自定义哈希器（Hasher）与非默认哈希构建器（BuildHasher），并用于 HashMap 和 HashSet。（仅需展示类型关联，无需关注哈希质量）

6. 为自定义类型实现 FromStr，要求返回自定义错误类型。（例如解析字符串时的结构化错误处理）

7. 编写单元测试用例。（例如对函数边界条件的验证）

8. #### 为何 `rayon` 的快速排序（`quicksort`）优于归并排序（`mergesort`）？反之适用条件？（好像没好）

   - `rayon`：用于并行计算的库，通过**工作窃取调度器**实现高效的并行任务分配，在 `rayon` 中，快排通常由于归并排序，因为快排具有更好的并行化潜力、缓存友好性和更低的空间复杂度
   - 适用场景：
     - 快排：不稳定，**计算密集型任务、通用排序**
     - 归并：需要稳定性、链表排序或外部排序

# 数据结构

### 树

#### 红黑树

1. 简述：自平衡的二叉搜索树，为了解决有序数据退化成链表的问题

2. 特性：

   - 根节点为黑色
   - 所有节点都是黑色或红色
   - 所有叶子节点（Null）都是黑色
   - 红色节点的子节点一定是黑色的
   - 任意一个节点到其叶子节点的所有路径上的黑色节点数量相同（黑色完美平衡二叉树）

3. 性能：

   - 查找的时间复杂度为 O(logn)，查找性能优秀
   - 插入的时间复杂度是 O(1)
   - 删除的时间复杂度是 O(logn)

4. 什么是左旋、右旋、变色？

   - 左旋、右旋、变色都是对节点所在子树的操作，以节点为基进行变化保持树的平衡的操作
   - 插入删除会涉及到左旋右旋

5. 相比AVL树：

   - 插入/删除需要的旋转操作更少

   - 查询稍慢但仍在O(log n)

   - **更适合频繁修改的场景**

#### B+树 vs 跳表

- B+树：
  - 多叉树数据结构，每个节点都可以存储16kb的数据，三层的数据结构可以存储2kw的数据量，即2kw的数据量最大是三次磁盘IO（假设数据也都在磁盘中），B+树还是一种平衡树，在插入数据时需要平衡树的结构，会有额外的开销，因此频繁的写入和删除会带来较大的性能开销。
  - 适合IO读取，即落盘存储
  - 频繁的写入和删除会造成额外的性能开销，性能降低，适合读多写少的场景
  - 典型用例：MySQL数据库使用B+树，因为其读多写少的场景多
- 跳表
  - 链表数据结构且实现简单，存储2kw=2^24的数据需要24层。插入数据时是否出现在层上取决于随机函数，无需平衡数据结构等额外的开销
  - 跳表实现简单，无需平衡数据结构
  - 存储量大的时候跳表的深度也随之大
  - 典型用例：Redis数据库的zset使用跳表，因为redis是内存存储，不存在io的瓶颈，所以跳表的层数的耗时可以忽略不计，而且插入数据时不需要开销以平衡数据结构，写多

# 操作系统

## 整体理解

### 操作系统都有哪些结构

- 内核、shell、文件系统，形成了基本的操作系统结构
- 结构种类：
  - 微内核：最基本的功能由中央内核（微内核）实现。所有其他的功能都委托给一些独立进程，这些进程通过明确定义的通信接口与中心内核通信。代表：Google的Fuchsia、鸿蒙
  - 宏内核：内核的所有代码，包括子系统（如内存管理、文件管理、设备驱动程序）都打包到一个文件中。内核中的每一个函数都可以访问到内核中所有其他部分。代表：Linux、Windows
  - 混合内核：macOS

### 用户态与内核态

| 特性           | 用户态             | 内核态               |
| :------------- | :----------------- | :------------------- |
| **权限级别**   | Ring 3(受限)       | Ring 0(完全权限)     |
| **内存访问**   | 只能访问用户空间   | 可访问全部内存空间   |
| **指令集**     | 受限指令集         | 可执行特权指令       |
| **稳定性影响** | 崩溃只影响当前进程 | 崩溃导致整个系统崩溃 |

**用户态→内核态** 触发场景：

1. 系统调用(如 `read`/`write`)
2. 硬件中断(如时钟中断)
3. 异常(如缺页异常)

**内核态→用户态** 触发场景：

1. 系统调用返回
2. 中断处理完成
3. 任务调度切换回用户进程

```assembly
; 示例汇编代码
; 系统调用进入内核态
mov eax, 1    ; 系统调用号
mov ebx, arg1 ; 参数
int 0x80      ; 软中断触发切换

; 内核返回用户态
iret          ; 中断返回指令
```

### 关键系统调用

进程管理

| 系统调用 | 作用       | 内核函数                   |
| :------- | :--------- | :------------------------- |
| fork     | 创建子进程 | kernel/fork.c:_do_fork()   |
| clone    | 创建线程   | kernel/fork.c:sys_clone () |
| execve   | 执行程序   | fs/exec.c:do_execve ()     |
| exit     | 终止进程   | kernel/exit.c:do_exit ()   |

文件操作

| 系统调用 | 作用     | 内核路径                    |
| :------- | :------- | :-------------------------- |
| openat   | 打开文件 | fs/open.c:do_sys_openat2 () |
| close    | 关闭文件 | fs/file.c:__close_fd()      |
| mmap     | 内存映射 | mm/mmap.c:do_mmap ()        |
| fsync    | 强制刷盘 | fs/sync.c:do_fsync ()       |

内存管理

| 系统调用 | 作用         | 内核路径                      |
| :------- | :----------- | :---------------------------- |
| brk      | 调整堆大小   | mm/mmap.c:sys_brk ()          |
| madvise  | 内存使用建议 | mm/madvise.c:sys_madvise ()   |
| mprotect | 修改内存保护 | mm/mprotect.c:sys_mprotect () |

网络通信

| 系统调用 | 作用       | 内核路径                    |
| :------- | :--------- | :-------------------------- |
| socket   | 创建套接字 | net/socket.c:sys_socket ()  |
| connect  | 建立连接   | net/socket.c:sys_connect () |
| sendmsg  | 发送数据   | net/socket.c:sys_sendmsg () |

特殊机制

| 系统调用 | 作用           | 内核路径                      |
| :------- | :------------- | :---------------------------- |
| ioctl    | 设备控制       | fs/ioctl.c:sys_ioctl ()       |
| ptrace   | 进程调试       | kernel/ptrace.c:sys_ptrace () |
| futex    | 快速用户态互斥 | kernel/futex.c:sys_futex ()   |

### **对OS整体理解**

关键设计思想：

- **抽象**：进程、文件、socket 等抽象屏蔽硬件细节
- **隔离**：通过虚拟化（CPU/内存/设备）实现多任务安全
- **并发控制**：锁、RCU、无锁数据结构等
- **性能优化**：缓存（页缓存、inode 缓存）、预读、异步 I/O

### 发生系统调用时，内核发生了什么？

1. 用户态要向内核请求服务，执行 `syscall n` 指令
2. **系统调用是陷阱类型的异常**，`syscall n` 会导致一个到处理异常的陷阱trap，触发软中断，程序的执行流从用户空间切换到内核空间
3. 进入内核态：
   - CPU切换到内核栈并保存用户态寄存器，根据中断号查找系统调用入口
   - 系统调用号在x86通过 `eax` 寄存器传递
4. 系统调用分发
5. 内核处理，将内核态的数据复制到进程空间
6. 数据拷贝
   - 检查用户缓冲区可写（`access_ok()`）
   - 内核通过 `copy_to_user()`/`copy_from_user()` 与用户空间交换数据
7. 返回用户态
   - 恢复保存的寄存器
   - 执行 `iret` 指令
   - CPU 切换回用户栈，继续执行下条指令

## 进程管理 SCHED

### 概念

#### 进程、线程、协程的区别

| **特性**     | **进程**                                      | **线程**                                         | **协程**                                     |
| :----------- | :-------------------------------------------- | :----------------------------------------------- | :------------------------------------------- |
| **定义**     | OS资源分配的基本单位，独立内存空间            | 程序执行的最小单位，共享进程内存                 | 用户态轻量级线程，由程序控制调度             |
| **资源占用** | 高（独立内存、文件句柄等）                    | 中（共享进程内存，但需内核调度）                 | 极低（通常KB级栈内存，无内核切换）           |
| **切换开销** | 高（需切换虚拟地址空间、内核态介入）          | 中（需内核调度，但共享内存）                     | 极低（用户态切换，无内核介入）               |
| **并发性**   | 多进程并行（依赖多核）                        | 多线程并行（依赖多核）                           | 单线程内高并发（适合I/O密集型）              |
| **通信方式** | 管道、消息队列、共享内存、信号等（借助OS）    | 直接读写进程数据段（需同步机制）                 | 直接共享变量（无需同步）                     |
| **调度者**   | 操作系统内核                                  | 操作系统内核                                     | 用户程序（如事件循环）                       |
| **独立性**   | 完全独立（崩溃不影响其他进程）                | 共享进程资源（一个线程崩溃可能导致整个进程退出） | 完全共享（协程崩溃可能影响同线程内其他协程） |
| **适用场景** | CPU密集型、需要隔离的任务（如浏览器多标签页） | CPU密集型、需要并行的任务（如计算任务拆分）      | I/O密集型、高并发任务（如网络爬虫、微服务）  |
| **创销开销** | 高                                            | 中                                               | 极低                                         |
| **典型实现** | `fork()`                                      | POSIX的`pthread`、C++的`std::thread`             | C++20的`coroutine`, Rust 的 `tokio`          |

#### Linux 时间片分配机制 CFS

- CFS完全公平调度器，能在真实硬件上模拟出一种“**公平的、精确的任务多处理CPU**”

- **特点**：

  - 不固定时间片长度：尽可能 1/n，但随着优先级不同有增减
  - 目标：**公平性**(而非均等时间)，尽量公平的同时也保证了交互式进程的响应速度
  - 采用**红黑树**作为调度的任务队列的数据结构
    - 每个节点代表了一个要调度的任务，节点的key即为虚拟时间vruntime，虚拟时间由这个任务的运行时间运算而来
    - key越小，也就是vruntime越小的话，红黑树对应的节点就越靠左
    - 每次挑选最左边的节点作为下一个要运行的任务，这个节点由一个特殊的指针指向，所以**CFS搜索的时间是 O(1)**

- **原则**

  - 随着任务的执行，它的运行时间增加，vruntime也会变大，它会在红黑树中向右移动；
  - 计算密集型作业将运行很长时间，因此它将移到最右侧；
  - I/O密集型作业会运行很短的时间，因此它只会稍微向右移动；
  - 对于更重要的任务，也就是nice值较小的（一般是小于0），他们的移动速度相对慢很多

- **计算公式**：

  ```
  时间片 = (调度周期 * 任务权重) / 所有运行队列任务权重总和   # 调度周期通常20ms
  ```

- **特殊场景**：

  - 实时进程(RT)优先于普通进程
  - CPU绑定任务有独立队列

#### 进程切换方式

分为两个步骤：

1. 进程调度
   - 调度算法：Linux 中实现了多种不同的进程调度算法，如 CFS（Completely Fair Scheduler）、O(1) 调度算法、实时调度算法等，并且各个算法之间可以配置和切换，由用户指定默认调度器。
   - 调度队列：调度算法的实现需要用到调度队列，它通过双向链表的数据结构来管理所有进程。Linux 中有就绪队列、休眠队列、实时队列等不同类型的队列，它们存储着不同状态的进程。
   - 进程状态：Linux 中的进程状态有很多种，如 TASK_RUNNING（运行中）、TASK_INTERRUPTIBLE（可中断的）、TASK_UNINTERRUPTIBLE（不可中断的）、TASK_STOPPED（已停止的）等。进程在不同状态下会被放置到不同类型的调度队列中，以便进行合适的调度。
2. 上下文切换
   - 进程控制块（Process Control Block, PCB）：PCB 是 Linux 内核用来存储和管理进程信息的重要数据结构。在进程切换时，需要将当前进程的 PCB 中保存的上下文信息保存到内存中。
   - 内核栈：内核栈用来保存进程的运行状态，进程切换时需要把当前进程的内核栈保存到当前进程的 PCB 中，并从新进程的 PCB 中恢复对应的内核栈信息。
   - 寄存器状态：CPU 中包含了多个寄存器，进程切换时需要将当前进程的寄存器状态保存到当前进程的 PCB 中，并从新进程的 PCB 中恢复寄存器状态。
   - 进程上下文切换：在 Linux 中，进程上下文切换是通过 switch_to 宏实现的。该宏会将当前进程的上下文信息保存到 PCB 中，并从新进程的 PCB 中读取上下文信息，完成进程切换的操作。

### 场景

#### 操作系统进程切换过程

- 触发切换：
  - 时间片用完 -> 系统调用阻塞 ->更高优先级进程就绪 -> 硬件中断
- 切换流程：
  - 保存当前进程上下文（用户寄存器、栈指针、程序计数器、状态寄存器、MMU）
  - 更新内核数据结构（将当前进程状态保存到PCB，将进程移入适当队列）
  - 选择新进程（调度算法选择下一个进程）
  - 恢复新进程上下文（加载新进程的寄存器、更新MMU、恢复栈指针、设置程序计数器）
  - 刷新TLB和CPU缓存



## 内存管理 MM

### 概念

#### 内存地址

每个进程都有完全属于自己的、独立的、不被干扰的内存空间，用户态的程序不能随意操作内核地址空间，内核态线程共享内核地址空间，如下图所示：

![mem](../utils/mem.png)

**MMU地址转换**

- MMU 是一种硬件电路，它包含两个部件，一个是分段部件，一个是分页部件
- 分段机制把一个逻辑地址转换为线性地址
- 分页机制把一个线性地址转换为物理地址

![](../utils/mmu.png)

**分段机制**

1. 段选择符

   - 为了方便快速检索段选择符，处理器提供了 6 个分段寄存器来缓存**段选择符**： cs,ss,ds,es,fs 和 gs
   - 段的**基地址**(Base Address)：在线性地址空间中段的起始地址
   - 段的**界限**(Limit)：在虚拟地址空间中，段内可以使用的最大偏移量

2. 分段实现

   - 逻辑地址的段寄存器中的值提供段描述符，然后从段描述符中得到段基址和段界限，然后加上逻辑地址的偏移量，就得到了线性地址

     ![mem](../utils/parse_duan.png)

**分页机制（32位）**

- 分页机制是在分段机制之后进行的，它进一步将线性地址转换为物理地址

- 10 位页目录，10 位页表项， 12 位页偏移地址

- 单页的大小为 4KB

  ![](../utils/parse_page.png)

#### 用户态地址空间

![mem](../utils/user_as.png)

- TEXT：代码段可执行代码、字符串字面值、只读变量
- DATA：数据段，映射程序中已经初始化的全局变量
- BSS 段：存放程序中未初始化的全局变量
- HEAP：运行时的堆，在程序运行中使用 malloc 申请的内存区域
- MMAP：共享库及匿名文件的映射区域
- STACK：用户进程栈

#### 内核态地址空间

![mem](../utils/kernel_as.png)

- 直接映射区：线性空间中从 3G 开始最大 896M 的区间，为直接内存映射区
- 动态内存映射区：该区域由内核函数 vmalloc 来分配
- 永久内存映射区：该区域可访问高端内存
- 固定映射区：该区域和 4G 的顶端只有 4k 的隔离带，其每个地址项都服务于特定的用途，如： ACPI_BASE 等

#### 进程内存空间

- 用户进程通常只能访问用户空间的虚拟地址，不能访问内核空间虚拟地址
- 内核空间是由内核负责映射，不会跟着进程变化；内核空间地址有自己对应的页表，用户进程各自有不同的页表

![process_as](../utils/process_as.jpeg)

#### **虚拟内存**

- **是什么？**
  - OS 提供的抽象层，使得每个进程拥有独立的地址空间，与物理内存分离，核心机制：
    - **地址转换**：通过MMU将虚拟地址转为物理地址
    - **分页管理**：内存被划分为固定大小的页（通常4KB）
    - **按需加载**：只有实际使用的页才会占用物理内存
- **为什么要用？**
  - 解决物理内存不足的问题，为多个进程提供足够的内存空间
  - 隔离不同进程的访问权限，提高系统的安全性
  - 可以为进程提供独立的内存空间并引入多层的页表结构将虚拟内存翻译成物理内存，进程之间可以共享物理内存减少开销，也能简化程序的链接装载以及内存分配过程
- **优缺点？**
  - **优点**：
    - 进程隔离（一个进程崩溃不影响其他进程）
    - 更大的地址空间（超过物理内存限制）
    - 内存共享（动态库、进程间通信）
    - 高效的物理内存管理（按需分页、页面置换）
  - **缺点**：
    - 地址转换开销（需要TLB加速）
    - 页面置换可能引起抖动（thrashing）
    - 实现复杂度高
- **怎么实现？**

#### **虚拟内存、分页、页表的组织形式**

- **地址转换**：CPU 的 MMU 通过页表将虚拟地址 → 物理地址
- **分页**：内存被划分为固定大小的页（通常 4KB）
- **页表层级**（以 x86-64 四级页表为例）
- 缺页异常处理流程
  - CPU 触发缺页异常（Page Fault）
  - 内核调用 `do_page_fault()`
  - 检查地址合法性（是否在 vma 区域内）
  - 若合法：
    - 文件映射：从磁盘读取数据到内存页（`filemap_fault()`）
    - 匿名页：分配新物理页并清零
  - 更新页表项，重新执行指令

#### Linux 内存分配算法

1. **伙伴系统算法**

   - 为内核提供了一种用于分配一组连续的页而建立的一种高效的分配策略，并有效的解决了**外碎片**问题

     - 外部碎片指的是还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域
     - 把所有的空闲页分组为 11 个块链表，每个块链表分别包含大小为 1，2，4，8，16，32，64，128，256，512 和 1024 个连续页框的页块。最大可以申请 1024 个连续页，对应 4MB 大小的连续内存

     ![](../utils/friend.png)

   - 分配的内存区是以页框为基本单位的

   - 申请算法：申请 2^i 个页块存储空间，如果 2^i 对应的块链表有空闲页块，则分配给应用，否则查找 2^(i+1) 对应的块链表是否有空闲页块，如果有，则分配 2^i 块链表节点给应用，另外 2^i 块链表节点插入到 2^i 对应的块链表中，如果 2^(i+1) 块链表中没有空闲页块，则继续反复，直到找到有空闲页块的块链表，如果仍然没有，就返回内存分配失败

   - 回收算法：释放 2^i 个页块存储空间，查找 2^i 个页块对应的块链表，是否有与其物理地址是连续的页块，如果没有，则无需合并，如果有，则合并成 2^（i+1）的页块，以此类推，继续查找下一级块链接，直到不能合并为止

2. **slab算法**

   - Linux 所使用的 slab 分配器的基础是 Jeff Bonwick 为 SunOS 操作系统首次引入的一种算法，**基本思想是将内核中经常使用的对象放到高速缓存中**，并且由系统保持为初始的可利用状态。比如进程描述符，内核中会频繁对此数据进行申请和释放
   - 目标是减少伙伴算法在分配小块连续内存时所产生的**内部碎片**
   - 将频繁使用的对象缓存起来，减少分配、初始化和释放对象的时间开销

#### **介绍 `mmap` 和 `munmap` **

这两个是用于**内存映射**的系统调用，用于将文件或设备映射到进程的地址空间，或者申请匿名内存

- `mmap`

  - 用于将 **文件、设备** 或 **匿名内存** 映射到进程的虚拟地址空间，使其可以像操作内存一样访问文件内容，提高 I/O 性能。此外，也可用于 **分配大块内存**，替代 `malloc`

  - `mmap` 映射成功，返回映射的 **虚拟地址指针**；失败则返回 `MAP_FAILED` 并设置 `errno`

  - 参数中的 `flags` 可以控制映射方式，如共享映射、私有映射、匿名映射等

  - 应用场景：

    - 大文件高效访问（避免 `read()` 和 `write()` 的拷贝开销）
    - 匿名共享内存（IPC）
    - 动态库加载（如 `ld.so` 使用 `mmap` 加载 `.so` 文件）

  - 和 `malloc` 的比较

    | 特性     | `mmap`                                        | `malloc`                  |
    | -------- | --------------------------------------------- | ------------------------- |
    | 内存来源 | 直接从 **虚拟内存（内核管理）** 分配          | 由 **堆（heap）** 管理    |
    | 内存大小 | 适用于 **大块内存**                           | 适用于 **小块内存**       |
    | 释放方式 | 需要手动 `munmap`                             | `free()` 自动释放         |
    | 性能     | **减少 `malloc`/`free` 开销**，大数据量下更快 | 适用于 **小对象频繁分配** |

- `munmap`

  - 用于解除 `mmap` 创建的映射，释放映射的虚拟内存区域。若不 `munmap`，映射区域会 **持续占用虚拟地址空间**，直到进程终止

1. `brk()` 系统调用

   - 被 glibc 进一步封装为 `malloc` 接口，申请的用户空间属于堆空间
   - 在申请的空间较小时会用这个函数

### 场景题

#### C++ `new`了一块100B的内存，操作系统此时会发生什么来分配这100B的内存空间？

1. **用户态**：

   - `new` 调用 `operator new(size_t)`，可能使用 `malloc(100)`。
   - `malloc()` 查找自由链表（Free List），看是否有已释放的、大小合适的块可复用。
   - 如果堆内存不足，调用 `sbrk()` 或 `mmap()` 请求新内存。

2. **内核态**（如果 `mmap()` 或 `sbrk()` 触发系统调用）：

   - 当为进程分配内存时，如 `mmap` 和 `malloc`，OS首先为其分配虚拟内存，在进程真正访问相应内存时通过缺页中断机制为其分配真正的物理内存，并通过页表建立虚拟内存到物理内存的映射

   - **虚拟地址空间分配**：修改进程地址空间，分配 100B（可能在堆上）。
   - **更新页表**，但不会立即分配物理内存。

3. **用户首次访问该内存时**：

   - 触发**缺页异常**（Page Fault）。
   - OS **分配物理页**，映射到虚拟地址。
   - 进程可以正常读写这块内存。

## 网络管理 net

### 概念

### **NIO（同步非阻塞IO）和BIO（同步阻塞IO）**

- BIO
  - 当进程调用 `read()`/`write()` 等系统调用时，如果数据未就绪，进程被放入等待队列，进入 **TASK_INTERRUPTIBLE** 状态
  - 当数据到达或缓冲区可写时，内核通过中断处理程序**唤醒**等待队列中的进程
  - **优点**：实现简单，CPU 利用率高（进程睡眠时不占用 CPU）
  - **缺点**：每个连接需要一个线程/进程，高并发时资源消耗大
- NIO
  - 系统调用不阻塞，调用立即返回，需轮询检查状态
  - **优点**：单线程可处理多个连接
  - **缺点**：需要轮询检查状态，CPU 利用率低（忙等待问题）

#### **I/O多路复用**

- 核心特点
  - **事件驱动**：内核通知就绪事件，避免轮询，在事件检测时会阻塞
  - **多路分离**：单线程监控多个文件描述符
  - **高性能**：支撑高并发连接的关键技术
- 主要实现有 select, poll, epoll

#### **关于 epoll**

- **是什么：**

  - Linux 特有的 I/O 事件通知机制，为解决Linux内核处理大量文件描述符而提出的方案
  - 属于Linux下多路I/O复用接口中 select/poll 的增强，用于监控多个fd上的I/O事件
  - 属于边缘触发(ET)或水平触发(LT)的就绪通知系统

- 工作流程：

  ```
  应用线程 → epoll_create创建实例 → epoll_ctl添加监控 → epoll_wait等待事件
             ↑
  内核 → 数据就绪 → 回调加入就绪队列 → 通知应用
  ```

- **设计思路：**

  - epoll 在 Linux 内核中构建了一个文件系统，它采用红黑树构建，效率超高，其中存储所有监控的文件描述符
  - 使用一个就绪链表存储有事件发生的文件描述符
  - 当监控的文件描述符就绪时，内核通过回调函数将其加入就绪链表
  - 用户空间和内核空间共享就绪列表内存，减少数据拷贝
  - 边缘触发（ET）模式，旨在状态变化时通知

```c
#define MAX_EVENTS 10

int main() {
    struct epoll_event ev, events[MAX_EVENTS];
    int listen_sock, conn_sock, nfds, epollfd;
    
    // 创建epoll实例
    epollfd = epoll_create1(0);
    
    // 添加监听socket
    ev.events = EPOLLIN;
    ev.data.fd = listen_sock;
    epoll_ctl(epollfd, EPOLL_CTL_ADD, listen_sock, &ev);
    
    for(;;) {
        // 等待事件(无限等待)
        nfds = epoll_wait(epollfd, events, MAX_EVENTS, -1);
        
        for(int i = 0; i < nfds; i++) {
            if(events[i].data.fd == listen_sock) {
                // 处理新连接
                conn_sock = accept(listen_sock, NULL, NULL);
                ev.events = EPOLLIN | EPOLLET; // 边缘触发
                ev.data.fd = conn_sock;
                epoll_ctl(epollfd, EPOLL_CTL_ADD, conn_sock, &ev);
            } else {
                // 处理客户端数据
                handle_client(events[i].data.fd);
            }
        }
    }
}
```

- **相对其他I/O多路复用的优势？**

| 特性               | select/poll                | epoll                          |
| :----------------- | :------------------------- | :----------------------------- |
| **时间复杂度**     | O(n) 每次线性扫描          | O(1) 只返回就绪描述符          |
| **描述符数量限制** | 有限制(通常1024)           | 仅受系统内存限制               |
| **工作模式**       | 水平触发(LT)               | 支持边缘触发(ET)和水平触发(LT) |
| **内核数据结构**   | 每次调用传递完整描述符集合 | 内核维护红黑树                 |
| **内存拷贝**       | 每次需要拷贝到内核空间     | 使用mmap共享内存               |
| **适用场景**       | 少量连接                   | 万级并发连接                   |

- 应用场景
  - 高并发网络服务器(Nginx, Redis)
  - 实时事件处理系统
  - 高性能代理服务器
  - 大规模连接的游戏服务器

### 场景

#### 单线程+IO多路复用 vs 多线程

| 特性           | 单线程+IO多路复用(epoll)     | 多线程模型                         |
| :------------- | :--------------------------- | :--------------------------------- |
| **资源消耗**   | 内存占用少(单进程)           | 每个线程需要独立栈空间(通常2-10MB) |
| **上下文切换** | 无线程切换开销               | 需要频繁线程上下文切换             |
| **CPU利用率**  | 适合IO密集型                 | 适合CPU密集型                      |
| **编程复杂度** | 回调/异步编程较复杂          | 同步编程更直观                     |
| **扩展性**     | 受限于单核性能               | 可充分利用多核                     |
| **典型实现**   | select/poll/epoll (Linux)    | pthread/std::thread                |
| **适用场景**   | 高并发网络服务(Nginx, Redis) | 计算密集型任务                     |

## 虚拟文件系统 VFS

### 概念

#### 零拷贝

出现的目的是为了提高读写性能，数据拷贝的基础过程是从磁盘读取数据到内存、再通过网卡传输给用户，这个过程中具体的模式：

![](../utils/data_copy.jpg)

1. 仅CPU方式

   - 当应用程序需要读取磁盘数据时，调用 `read()` 从用户态陷入内核态，`read()` 这个系统调用最终由CPU来完成；
   - CPU向磁盘发起I/O请求，磁盘收到之后开始准备数据；
   - 磁盘将数据放到磁盘缓冲区之后，向CPU发起I/O中断，报告CPU数据已经Ready了；
   - CPU收到磁盘控制器的I/O中断之后，开始拷贝数据，完成之后 `read()` 返回，再从内核态切换到用户态；

   ![](../utils/cpu_copy.jpg)

2. **CPU&DMA方式**

   - DMA是一种硬件设备绕开CPU独立直接访问内存的机制，帮CPU做一些杂活。目前支持DMA的硬件包括：网卡、声卡、显卡、磁盘控制器
   - CPU不再和磁盘直接交互，而是DMA和磁盘交互并且将数据从磁盘缓冲区拷贝到内核缓冲区，之后的过程类似

   ![](../utils/cpu_dma.jpg)

​	以上两种方式，都存在多次冗余数据拷贝和内核态&用户态的切换，零拷贝技术降低冗余数据拷贝、解放CPU，目前有四个手段：

1. `mmap`+`write`

   `mmap` 是 Linux 提供的一种内存映射文件的机制，它实现了将内核中读缓冲区地址与用户空间缓冲区地址进行映射，从而实现内核缓冲区与用户缓冲区的共享。这样就减少了一次用户态和内核态的CPU拷贝，但是在内核空间内仍然有一次CPU拷贝。

   虽然有改进，但是由系统调用引起的状态切换并没有减少

   ![](../utils/mmap+write.jpg)

   

2. `sendfile`

   `sendfile` 建立了两个文件之间的传输通道，只用一个函数就完成之前 `read`+`write` 和 `mmap`+`write`的功能，少了两次状态切换，由于数据不经过用户缓冲区，因此该数据无法被修改

   从图中可以看到，应用程序只需要调用 `sendfile` 函数即可完成，只有2次状态切换、1次CPU拷贝、2次DMA拷贝。但是 `sendfile` 在内核缓冲区和socket缓冲区仍然存在一次CPU拷贝，或许这个还可以优化。

   ![](../utils/sendfile.jpg)

3. `sendfile`+DMA收集

   Linux 2.4 内核对 `sendfile` 系统调用进行优化，但是需要硬件DMA控制器的配合。升级后的 `sendfile` 将内核空间缓冲区中对应的数据描述信息（文件描述符、地址偏移量等信息）记录到socket缓冲区中。DMA控制器根据socket缓冲区中的地址和偏移量将数据从内核缓冲区拷贝到网卡中，从而省去了内核空间中仅剩1次CPU拷贝。

   ![](../utils/sendfile+dma.jpg)

4. `splice`

   `splice` 系统调用是Linux 在 2.6 版本引入的，其不需要硬件支持，并且不再限定于socket上，实现两个普通文件之间的数据零拷贝

   `splice` 系统调用可以在内核缓冲区和socket缓冲区之间建立管道来传输数据，避免了两者之间的 CPU 拷贝操作

   ![](../utils/splice.jpg)

### 场景

#### `cat` 读取文件，OS是怎么处理的？

- **系统调用入口**：

  ```
  SYSCALL_DEFINE3(read, unsigned int, fd, char __user *, buf, size_t, count)
  ```

- **关键调用栈**：

  ```
  read() → ksys_read() → vfs_read() → file->f_op->read_iter() → ext4_file_read_iter() → generic_file_read_iter() → filemap_read()
  ```

- **页缓存交互**：

  - 检查文件页是否已在页缓存（`address_space`）

  - 若不存在，触发缺页异常：

    ```
    do_page_fault() → handle_mm_fault() → __handle_mm_fault() → ...
    ```

- **磁盘I/O触发**：

  ```
  // fs/ext4/inode.c
  static int ext4_readpage(struct file *file, struct page *page) {
      // 提交bio请求到块设备层
      submit_bio_wait(REQ_OP_READ, bio);
  }
  ```

#### **怎么检测到 `cat` 二进制文件，用什么命令执行？**（不懂）

1. 解析ELF头部
2. 建立新的地址空间
3. 加载程序段（.text, .data）
4. 设置动态链接器路径
5. 初始化栈（环境变量、参数）

用 `exec` 执行

#### **怎么找到文件在磁盘上的位置**

- **EXT4文件系统示例**：

  - 三步定位：块组 → inode → 数据块

  - 计算公式：

    ```
    块组 = (inode号 - 1) / 每块组inode数
    inode表偏移 = (inode号 - 1) % 每块组inode数
    ```

- **实际磁盘寻址**：

  ```
  LBA = (块号 * 块大小) / 扇区大小
  ```

  通过`hdparm --fibmap file`可查看文件物理块号

#### **读写系统调用的过程**

- `read()`

  1. 用户空间：

     ```assembly
     mov eax, 0  ; SYS_read
     mov ebx, fd
     mov ecx, buf
     mov edx, count
     int 0x80
     ```

  2. 内核处理：

     ```
     read() → ksys_read() → vfs_read() → file->f_op->read()
              ↓
     ext4_file_read_iter() → generic_file_read_iter() → filemap_read()
              ↓
     submit_bio() → 块设备层 → SCSI/SATA/NVMe驱动
     ```

- `write()`

  1. **写时复制（COW）**：

     ```c
     // mm/memory.c
     int do_wp_page(struct vm_fault *vmf)
     ```

  2. **延迟写入**：

     ```c
     // fs/ext4/inode.c
     static int ext4_da_write_begin() // 延迟分配块
     ```

  3. **回写线程**：

     ```
     pdflush → writeback_inodes() → do_writepages()
     ```

## 进程间通信 IPC

### 概念

#### **进程间通信**（IPC）

- 指在不同进程之间传递数据或信号的机制
- **管道**
  
  - **半双工**通信：数据只能单向流动。
  - 只能在具有亲缘关系的进程之间使用（如父子进程）
  - 数据以字节流的形式传输。
  
  - 应用场景：
    - Linux命令是管道操作（比如 `ls | grep "txt"`）
    - 父子进程通信（一个进程的输出作为另一个进程的输入）
- **命名管道**
  
  - 可以**全双工**通信：数据可以双向流动
  - 可以在无关进程之间使用
  - 通过文件系统中的命名管道文件进行通信
  
  - 应用场景：
    - 不同进程间的数据交换（如C/S模型）
    - 长期运行的进程通信（如日志收集）
- **消息队列**
  
  - 通过消息队列传递结构化数据。
  - 消息可以按类型分类，支持优先级。
  - 消息队列独立于进程存在，进程终止后消息队列仍然存在。
- **共享内存**
  
  - 多个进程共享同一块内存区域，无需内核介入
  - **通信速度最快**，但需要同步机制（如信号量）避免竞争
  - 和 `mmap` 的区别：数据来源是纯内存还是磁盘文件/是否可以持久化/同步机制是否依赖文件系统等，区别还是挺大的
- **信号量**
  
  - 用于进程间的同步，控制对共享资源的访问。
  - 可以用于解决生产者-消费者问题。
- **套接字socket**
  - 支持网络通信，可以在不同主机上的进程之间通信
  - 在UNIX中算是一种双向管道文件
  - 支持多种协议（如 TCP、UDP）

#### 线程同步的方式有哪些

| 机制         | 原理           | 适用场景           | 性能开销     |
| :----------- | :------------- | :----------------- | :----------- |
| **互斥锁**   | 二进制锁       | 临界区保护         | 中等         |
| **自旋锁**   | 忙等待         | 短临界区、内核代码 | 高(消耗CPU)  |
| **读写锁**   | 读共享/写独占  | 读多写少场景       | 中等         |
| **条件变量** | 事件通知机制   | 生产者-消费者模型  | 低(无忙等待) |
| **原子操作** | CPU指令级保证  | 计数器等简单操作   | 最低         |
| **屏障**     | 线程集合同步点 | 并行计算阶段同步   | 高           |

#### 死锁

- 多个进程在运行过程中因争夺资源而造成的一种僵局
- **死锁必要条件**
  - 互斥条件：资源独占使用
  - 占有并等待：持有资源同时请求新资源
  - 非抢占条件：资源只能自愿释放
  - 循环等待：存在请求环形链
- **死锁预防的方法**
  - 破坏前面四个必要条件
- **死锁避免的方法**
  - 银行家算法：预判分配是否安全
- **死锁检测与恢复**
  - 资源分配图算法检测环路
  - 强制剥夺资源(牺牲进程)

### 场景

#### 一个进程中有两个 thread，一个 thread 是否可以访问另一个 thread 栈上的内容？

- 可以，但需满足特定条件，实际要避免这种操作
- 一个进程下是一个单独的地址空间，如果拿到栈指针就行，拿不到就不可以

#### 什么场景适合读写锁？写多的场景怎么办？

- 读写锁适用于读操作远多于写操作的场景，可以显著提高程序的并发性能
- 互斥锁、无锁数据结构

# 计算机组成原理

1. **磁盘与物理内存发生交换的过程？**

   进程得到的x G虚拟内存在进程看来是一个连续的地址空间，但其实它的数据存储在多个物理内存碎片上，还有一大部分存储在外部磁盘上，在需要时将数据交换进物理内存

   虚拟内存与物理内存的联系：

   ![在这里插入图片描述](../utils/vmem.png)

2. **虚拟地址到物理地址的映射过程？**

   进程开始要访问一个地址，它可能会经历下面的过程：

   1. 进程每次要访问地址空间上的某一个地址时，都需要把地址翻译为实际物理内存地址
   2. 所有进程共享一整块物理内存，每个进程只把自己目前需要访问的虚拟地址空间映射到物理内存上
   3. 进程需要知道虚拟内存地址空间上的哪些数据在物理内存上，哪些在磁盘上，若在物理内存上，则需要进一步知道数据存储在物理内存上的具体位置，这都通过**页表**来记录
   4. 页表的每一个表项分两部分，第一部分记录此页是否在物理内存上，第二部分记录物理内存页的地址（如果在的话）
   5. 当进程访问某个虚拟地址的时候，就会先去看页表，如果发现对应的数据不在物理内存上，就会发生**缺页异常**
   6. 缺页异常的处理过程，操作系统立即阻塞该进程，**并将硬盘里对应的页换入内存**，然后使该进程就绪。如果内存已满，没有空位，则需找一个页覆盖，至于具体覆盖哪个页是根据OS的页面置换算法

3. **Linux中的匿名页是什么？**

   指的是**没有文件映射的内存页**，即进程直接通过 `malloc()`、`brk()`、`mmap(MAP_ANONYMOUS)` 等方式分配的私有内存，这些内存页不会直接与磁盘上的文件关联，而是仅存在于**物理内存或交换空间**中。

   匿名页的特点：

   - 不与文件系统关联：不像 `mmap()` 映射的文件页，匿名页不会与磁盘文件同步（也不会写回）
   - 通常存放堆、栈、全局变量等数据
   - 可以被 Swap 交换到磁盘，当物理内存不足时，匿名页可能会被写入 交换空间（swap），然后在需要时再加载回来

4. 32位的系统能访问4gb以上的内存吗？

   - 我答的不能 面试官说可以去查一下最新的Linux 【intel新的x86硬件PAE支持36寻址空间，但是多出来的部分是虚拟的地址空间，单个应用程序估计无法使用到超过4GB的空间(32为系统的最大int是4GB)，只能是多个进程合起来能够使用到4G以外的内存】

5. **知道的栈寄存器的名字**

   - eax, ebx, ecx, edx, esi, edi, ebp

6. **程序编译过程**

   GCC编译器驱动程序读取源程序文件 `hello.c`，并把它翻译成一个可执行目标文件hello。这个翻译过程分为四个阶段：**[预处理](https://zhida.zhihu.com/search?content_id=194063567&content_type=Article&match_order=1&q=预处理&zhida_source=entity)（Preprocessing）、编译（Compilation）、[汇编](https://zhida.zhihu.com/search?content_id=194063567&content_type=Article&match_order=1&q=汇编&zhida_source=entity)（Assembly）、[链接](https://zhida.zhihu.com/search?content_id=194063567&content_type=Article&match_order=1&q=链接&zhida_source=entity)（Linking）**。执行这四个阶段的程序（**预处理器、编译器、汇编器、和链接器**）一起构成了编译系统。

# 计算机网络

**计算机网络模型（OSI模型）**

- 物理层：集线器、中继器、调制解调器
- 数据链路层：网桥、交换机
- 网络层：IP、ICMP、ARP、RARP、IPv6、NAT、路由器
- 传输层：TCP、UDP、（TLS/SSL）、网关
- 会话层
- 表示层
- 应用层：HTTP、HTTPS、FTP、SMTP、POP3、IMAP、DNS、SSH、SNMP、Telnet、

**TCP/IP模型和每层的作用**

- 物理层+数据链路层：管理同一局域网内设备间的数据帧传输，确保物理连接可靠
- 网络层：负责数据包的路由和寻址，实现主机间的逻辑通信
- 传输层：提供端到端的数据传输服务
- 应用层：直接位用户应用程序提供网络服务

## 网络层

### **IP 协议概述**

- 所有的TCP、UDP、ICMP数据都以IP数据报格式传输
- IP在传输数据包时，将数据报文分为若干分片进行传输，并在目标系统中进行重组
- 不同链路类型规定有不同最大长度的链路层数据帧，称为链路层MTU，常见的MTU=1500，若IP报文长度大于转发接口的MTU，则会将数据报文分为若干分片进行传输
- 对于不同的传输层协议，在IP层上需不需要进行分片也是不同的：
  - **对于TCP，尽量避免分片。**因为当在IP层进行了分片后，如果其中的某片数据丢失，则需对整个数据报进行重传。避免分层的方法是，在3次握手时协商一个MSS值，用来表示本段所能接收的最大长度的报文段
  - **对于UDP而言可以分片。**

### **IP分片可能出现的问题**

- **性能消耗**：分片和重组会消耗发送方、接收方一定的CPU等资源，且分片对接收方内存资源的消耗较多
- **丢包导致重传**：如果某个分片报文在网络传输过程中丢失，那么接收方将无法完成重组，如果应用进程要求重传的话，发送方必须重传所有分片报文而不是仅重传被丢弃的那个分片报文，这种效率低下的重传行为会给端系统和网络资源带来额外的消耗
- **分片攻击**：黑客构造的分片报文，但是不向接收方发送最后一个分片报文，导致接收方要为所有的分片报文分配内存空间，可由于最后一个分片报文永远不会达到，接收方的内存得不到及时的释放（接收方会启动一个分片重组的定时器，在一定时间内如果无法完成重组，将向发送方发送ICMP重组超时差错报文，，只要这种攻击的分片报文发送的足够多、足够快，很容易占满接收方内存，让接收方无内存资源处理正常的业务，从而达到DOS的攻击效果

### **NAT网络地址转换**

- NAT路由器内部会维护一个NAT表，进行 `本地ip：端口`到 `外部网络ip：端口` 的映射

## 传输层

1. TCP报文的组成？字段有哪些

2. TCP的状态位有哪些？什么时候、具体什么事件会触发什么状态位？

3. TCP慢启动过程

4. TCP/IP三次握手

5. 重传机制(超时重传 快重传)

6. **TCP拥塞控制算法**

   - 慢开始
   - 拥塞避免
   - 快重传
   - 快恢复

7. TCP粘包什么意思

8. **关于TCP协议和UDP协议**
   - 区别：
     - TCP：
       - 面向连接的、可靠的，确保数据包按顺序且无误地传送到接收方
       - 有流量控制、拥塞控制
     - UDP：
       - 无连接的、不可靠的，低延迟
       - 没有顺序保证或重传机制
       - 将数据分割成独立的数据报，带有一定信息，收到后再组装
       - 有简单的校验和机制
   - 应用场景：
     - TCP：适用于需要高可靠性和数据顺序保证的场景，如文件传输、电子邮件、远程登陆
     - UDP：适用于对传输速度要求较高、容忍一定数据丢失的场景，如视频流媒体、在线游戏、DNS查询
   - 在哪些协议中有用到：
     - TCP：[Telnet](https://zhida.zhihu.com/search?content_id=169112169&content_type=Article&match_order=1&q=Telnet&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDE5MzcwMDEsInEiOiJUZWxuZXQiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoxNjkxMTIxNjksImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.Gml07eGDbxa1jYaVJnEzfJtpRYWKdHsymc3SPDU94xM&zhida_source=entity)(远程登录)、[FTP](https://zhida.zhihu.com/search?content_id=169112169&content_type=Article&match_order=1&q=FTP&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDE5MzcwMDEsInEiOiJGVFAiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoxNjkxMTIxNjksImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.iHZkXQxdmu2OQ4OgzxCbFIqo7lwdSoapeMxibvKo0Xo&zhida_source=entity)(文件传输协议)、[SMTP](https://zhida.zhihu.com/search?content_id=169112169&content_type=Article&match_order=1&q=SMTP&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDE5MzcwMDEsInEiOiJTTVRQIiwiemhpZGFfc291cmNlIjoiZW50aXR5IiwiY29udGVudF9pZCI6MTY5MTEyMTY5LCJjb250ZW50X3R5cGUiOiJBcnRpY2xlIiwibWF0Y2hfb3JkZXIiOjEsInpkX3Rva2VuIjpudWxsfQ.il7Gezua-rDPO1Je3eM1wb_3lArMbaVGLPyPsi6jnEA&zhida_source=entity)(简单邮件传输协议)、HTTP、SSH
     - UDP：[NFS](https://zhida.zhihu.com/search?content_id=169112169&content_type=Article&match_order=1&q=NFS&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDE5MzcwMDEsInEiOiJORlMiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoxNjkxMTIxNjksImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9._c_EheLfLeqLCL7fHxg7bxrYl7FuQnmFpdW2wwzJESw&zhida_source=entity)(网络文件系统)、[SNMP](https://zhida.zhihu.com/search?content_id=169112169&content_type=Article&match_order=1&q=SNMP&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDE5MzcwMDEsInEiOiJTTk1QIiwiemhpZGFfc291cmNlIjoiZW50aXR5IiwiY29udGVudF9pZCI6MTY5MTEyMTY5LCJjb250ZW50X3R5cGUiOiJBcnRpY2xlIiwibWF0Y2hfb3JkZXIiOjEsInpkX3Rva2VuIjpudWxsfQ.rLg3eyWT43bqE6XZSqj5MXMOtt9Xq0Dm6O4pP7GmWcI&zhida_source=entity)(简单网络管理系统)、[DNS](https://zhida.zhihu.com/search?content_id=169112169&content_type=Article&match_order=1&q=DNS&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDE5MzcwMDEsInEiOiJETlMiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoxNjkxMTIxNjksImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9._FLGpV3NGLy7sTSLlD0qopQtufLfCx0RL-sm0rsgjrE&zhida_source=entity)(主域名称系统)、[TFTP](https://zhida.zhihu.com/search?content_id=169112169&content_type=Article&match_order=1&q=TFTP&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDE5MzcwMDEsInEiOiJURlRQIiwiemhpZGFfc291cmNlIjoiZW50aXR5IiwiY29udGVudF9pZCI6MTY5MTEyMTY5LCJjb250ZW50X3R5cGUiOiJBcnRpY2xlIiwibWF0Y2hfb3JkZXIiOjEsInpkX3Rva2VuIjpudWxsfQ.evs753NZcg7-JzU4J9zX8phKst5VHMRazegsuZKdJdY&zhida_source=entity)(通用文件传输协议)、NTP（网络时间协议）

9. **UDP怎么实现可靠性**

   UDP 是一种**无连接、不可靠、但低开销**的协议。想要在基于 UDP 的通信中实现可靠性，通常要在 **应用层自己实现以下机制**：

   - **确认应答机制（ACK）**：
     - 每个数据包都带一个序号，接收方收到后立即发回 ACK 确认。
     - 如果一定时间内没收到 ACK，发送方会重发。
   - **重传机制（Retransmission）**：
     - 发送端维护一个重传计时器，超时没收到 ACK 就重传。
   - **序号机制（Sequence Number）**：
     - 用于检测乱序、重传、丢包等，常用于语音/视频流恢复顺序。
   - **滑动窗口（Sliding Window）**：
     - 类似 TCP 的流量控制，可以在应用层实现滑动窗口来提高效率。
   - **拥塞控制**：
     - 根据 ACK 的反馈情况调节发送速率，避免网络拥堵。
   - **校验机制**：
     - 应用层可以增加 CRC、哈希等校验，增强数据完整性校验。

10. **TCP为什么能够保证可靠性**

   TCP 是一个**面向连接、可靠传输、全双工、字节流协议**，它的可靠性依赖于以下几个机制：

   1. **三次握手建立连接**：
      - 确保通信双方都能收发数据，防止旧连接数据干扰。
   2. **序列号 + 确认号（SEQ/ACK）**：
      - 每个字节都有编号，接收方通过 ACK 告诉发送方哪些数据已收到。
   3. **重传机制（RTO + 快速重传）**：
      - 发送方若未收到 ACK，会在超时时重发数据。
      - 快速重传可在收到 3 个重复 ACK 时立即重发，降低等待时间。
   4. **接收方应答机制（ACK）**：
      - 所有收到的数据都要 ACK，防止丢包。
   5. **流量控制（滑动窗口）**：
      - 防止接收方处理不过来，窗口控制了双方发送速率。
   6. **拥塞控制**：
      - 包括慢启动、拥塞避免、快重传、快恢复，防止网络崩溃。
   7. **校验和（Checksum）**：
      - 每个 TCP 报文段都包含校验和，确保数据传输完整。

11. **TCP三次握手详细描述，为什么要三次而不是两次**

    - 为了保证客户端和服务器端的可靠连接，TCP建立连接时**必须**要进行三次会话，也叫TCP三次握手，**目的是为了确认双方的接收能力和发送能力是否正常**

      ![在这里插入图片描述](../utils/tcp3.png)

    - 最开始的时候客户端和服务器都是处于CLOSED关闭状态。主动打开连接的为客户端，被动打开连接的是服务器

    - TCP服务器进程先创建传输控制块TCB，时刻准备接受客户进程的连接请求，此时服务器就进入了 LISTEN 监听状态

    - **第一次握手**TCP客户进程也是先创建传输控制块TCB，然后向服务器发出连接请求报文，这是报文首部中的同部位SYN=1，同时选择一个初始序列号 seq=x ，此时，TCP客户端进程进入了 SYN-SENT 同步已发送状态

    - **第二次握手**TCP服务器收到请求报文后，如果同意连接，则会向客户端发出确认报文。确认报文中应该 ACK=1，SYN=1，确认号是ack=x+1，同时也要为自己初始化一个序列号 seq=y，此时，TCP服务器进程进入了 SYN-RCVD 同步收到状态

    - **第三次握手**TCP客户端收到确认后，还要向服务器给出确认。确认报文的ACK=1，ack=y+1，自己的序列号seq=x+1，此时，TCP连接建立，客户端进入ESTABLISHED已建立连接状态 触发三次握手

    - **为什么要有第三次？**主要原因是，防止已经失效的连接请求报文突然又传送到了服务器，从而产生错误。举例而言：客户端向服务器端发送的请求报文由于网络等原因滞留，未能发送到服务器端，此时连接请求报文失效，客户端会再次向服务器端发送请求报文，之后与服务器端建立连接，当连接释放后，由于网络通畅了，第一次客户端发送的请求报文又突然到达了服务器端，这条请求报文本该失效了，但此时服务器端误认为客户端又发送了一次连接请求，两次握手建立好连接，此时客户端忽略服务器端发来的确认，也不发送数据，造成不必要的错误和网络资源的浪费。如果采用三次握手的话，就算那条失效的报文发送到服务器端，服务器端确认并向客户端发送报文，但此时客户端不会发出确认，由于客户端没有确认，由于服务器端没有接收到确认，就会知道客户端没有请求连接。

12. **TCP四次挥手详细描述**

    - 断开TCP连接需要四次挥手

      ![在这里插入图片描述](../utils/tcp4.png)

    - 数据传输完毕后，双方都可释放连接。最开始的时候，客户端和服务器都是处于ESTABLISHED状态，然后客户端主动关闭，服务器被动关闭

    - **第一次挥手** 客户端发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态

    - **第二次挥手** 服务器端接收到连接释放报文后，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT 关闭等待状态

    - **第三次挥手** 客户端接收到服务器端的确认请求后，客户端就会进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文，服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认

    - **第四次挥手** 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态，但此时TCP连接还未终止，必须要经过2MSL后（最长报文寿命），当客户端撤销相应的TCB后，客户端才会进入CLOSED关闭状态，服务器端接收到确认报文后，会立即进入CLOSED关闭状态，到这里TCP连接就断开了，四次挥手完成

    - **为什么客户端要等待2MSL？**主要原因是为了保证客户端发送的第一个ACK报文能到服务器，因为这个ACK报文可能丢失，并且2MSL是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃，这样新的连接中不会出现旧连接的请求报文

13. TLS握手过程

14. 一个 TCP server 的进程崩溃后，客户端会怎么反应吗？

    - Linux 内核在进程崩溃前，会向它连接的客户端发送 FIN 报文

## 应用层

### **http和https**

- HTTP
  - 用于在web浏览器和服务器之间传递信息的协议
  - 默认工作在TCP80端口
  - 以明文方式发送内容，不提供加密
  - 页面响应更快、资源消耗更低
- HTTPS
  - 由HTTP进行通信，利用SSL/TLS加密数据包
  - 主要用于身份认证、保护交换数据的隐私与完整性
  - 默认工作在TCP443端口
  - 需要到CA申请证书
  - https如何解决不安全问题、加密方式有哪些？
- **浏览器进行http请求的时候包含哪些头部**
  - 通用头部：适用于请求和响应，提供与消息本身相关的信息
  - 请求头部：用于传递客户端的详细信息、请求的上下文以及期望的响应格式
  - 实体头部：用于描述请求或响应的主体内容
  - GET请求包含1,2
  - POST请求包含1,2,3
  - PUT请求包含1,2,3
  - DELETE请求包含1,2

1. socket通信过程、客户端需要Bind吗

2. HTTP头、几种请求方式、HTTPS原理、认证过程、HTTP 2.0、QUIC、50x错误意义

3. HTTP/1.1 的 Pipelining 和HTTP/2的多路复用的区别

4. 讲讲为什么用select不用epoll？epoll比select好在哪？

   （答数据结构不同：红黑树加双向链表vs数组；答内核态用户态切换开销不一样）

5. websocket和socket的关系和区别？websocket是七层中的哪一层？（答应用层，不知道对不对），为什么不用socket而用websocket？

6. websocket和http的关系和区别？（答websocket能双向传输信息）又问http不能双向传输信息没？为什么你搭建的服务器不用http？

## 场景题

1. **在浏览器地址栏输入一个URL后回车，背后会进行哪些技术步骤?**
   - 参考该链接：[经典面试题：在浏览器地址栏输入一个 URL 后回车，背后发生了什么-腾讯云开发者社区-腾讯云](https://cloud.tencent.com/developer/article/1793846)

   - DNS解析域名 -> IP地址
     - 搜索**浏览器的DNS缓存**，其中维护着一张域名与IP地址的对应表
     - 若没有命中，则继续搜索**操作系统的DNS缓存**
     - 若没有命中，则操作系统将域名发送至**本地域名服务器**，它查询自己的DNS缓存，成功则返回结果，此处是递归查询
     - 若没有命中，则本地域名服务器向上级域名服务器进行迭代查询，得到IP地址后返回给操作系统，同时将其放在缓存里：
       - 本地域名服务器向**根域名服务器**发起请求，根域名服务器是最高层次的，它并不会直接指明这个域名对应的 IP 地址，而是返回顶级域名服务器的地址，也就是说给本地域名服务器指明一条道路，让他去这里寻找答案
       - 本地域名服务器拿到这个**顶级域名服务器**的地址后，就向其发起请求，获取**权限域名服务器**的地址
       - 本地域名服务器根据权限域名服务器的地址向其发起请求，最终得到该域名对应的 IP 地址
     - 操作系统将IP地址返回给浏览器，同时也将其放在缓存里
     - DNS使用UDP协议，以上所有请求转发过程都是基于UDP
   - 建立TCP连接，发送封装好的HTTP请求报文
     - 先通过三次握手为浏览器和服务器之间建立可靠的连接
     - TCP 会将 HTTP 报文按序号分割成若干报文段并加上 TCP 首部，分别进行传输。接收方在收到这些报文段后，按照序号以原来的顺序重组 HTTP 报文
   - IP封装数据报
     - TCP在各阶段操作时，都是通过IP协议进行传输的，IP将数据添加IP首部封装成IP数据包再进行传输
     - IP数据报首部存有**源IP地址、目标IP地址**
   - ARP查询目的MAC地址
     - ARP协议将IP地址转化为MAC地址，每个主机都有一个ARP高速缓存，里面有本局域网上各主机和路由器的**IP地址到MAC地址的映射表**
   - 物理层在硬件之间传输
   - 服务器响应请求
     - 浏览器的 HTTP 请求报文通过 TCP 三次握手建立的连接通道被切分成若干报文段分别发送给服务器，服务器在收到这些报文段后，按照序号以原来的顺序重组 HTTP 请求报文。然后处理并返回一个 HTTP 响应。当然，HTTP 响应报文也要经过和 HTTP 请求报文一样的过程
   - 断开TCP连接、浏览器显示界面



# C++

## 基本概念

1. **内存数据存储位置**

   | 内存区域        | 存储内容                     | 生命周期         | 特点                      |
   | :-------------- | :--------------------------- | :--------------- | :------------------------ |
   | **栈(Stack)**   | 局部变量、函数参数、返回值等 | 函数执行期间     | 自动分配释放，速度快      |
   | **堆(Heap)**    | 动态分配的内存(`new/malloc`) | 直到手动释放     | 大容量，分配较慢          |
   | **全局/静态区** | 全局变量、静态变量           | 程序整个运行期间 | 初始化为0，线程安全需注意 |
   | **常量区**      | 字符串常量和其他常量         | 程序整个运行期间 | 只读，不可修改            |
   | **代码区**      | 程序执行的机器指令           | 程序整个运行期间 | 只读，存放函数体          |

2. **`virtual` 的意义**

   没有加 `virtual` 的话，创建/销毁子类对象的时候找不到子类的构造函数/析构函数，就会只调用父类的，造成内存泄漏，加了 `virtual` 可以：

   - 通过虚函数机制确保调用正确的析构函数链
   - 基类虚析构函数会使得所有派生类析构函数自动成为虚函数
   - 多态基类必须声明虚析构函数

3. **`new`和 `delete`（C++）， `malloc` 和 `free`（C）**

   这两对搭配是不可以混合使用的，因为:

   - `free` 不会调用析构函数，导致资源泄漏

   - `new` 调用构造函数，可能分配额外内存，而 `free` 不知道这些额外信息，导致堆损坏

   - 关键区别

     | 特性         | new/delete                | malloc/free            |
     | :----------- | :------------------------ | :--------------------- |
     | **语言层面** | C++运算符                 | C库函数                |
     | **内存大小** | 自动计算                  | 需手动计算             |
     | **初始化**   | 调用构造函数              | 只分配内存             |
     | **清理**     | 调用析构函数              | 只释放内存             |
     | **失败处理** | 抛出bad_alloc异常         | 返回NULL               |
     | **重载方式** | 可重载operator new/delete | 不可重载               |
     | **内存对齐** | 遵循类型对齐要求          | 通常按最大基本类型对齐 |
     | **数组支持** | 有new[]/delete[]专用形式  | 需要手动计算数组大小   |
     | **放置形式** | 支持placement new         | 无对应功能             |
     | **类型安全** | 类型安全                  | 返回void*需要转换      |

4. **`new`和 `delete` 的资源消耗原因**

   - 系统调用开销：需要从操作系统申请/释放内存、涉及用户态/内核态切换
   - 构造函数/析构函数调用：
     - `new`：先分配内存，再调用构造函数
     - `delete`：先调用析构函数，再释放内存

5. **下面这段代码有没有问题：**

   ```cpp
   class A { 
   public:
       void func(){
           cout<<"hello";
       }
   }; 
   A* a=nullptr;
   a->func();
   ```

   没有问题。成员函数代码 `func()` 存储在代码段中，静态编译时就已经确定位置，与对象实例无关，所有实例共享同一份函数代码。当调用 `a->func()` 时，编译器生成的代码相当于 `A::func(a)`，这里 `a` 是作为隐式的 `this` 指针参数传递，由于 `func()` 内部没有访问任何成员变量，不需要解引用 `this` 指针。关键点在于 `func()` 没有访问任何成员变量或虚函数，如果函数尝试访问 `this->member`，则会因解引用空指针而崩溃

## 数据结构

1. **`vector` 和 `list` 的区别？**

   | 特性                | vector             | list               |
   | :------------------ | :----------------- | :----------------- |
   | **底层结构**        | 动态数组           | 双向链表           |
   | **内存布局**        | 连续内存           | 非连续内存         |
   | **随机访问**        | O(1)               | O(n)               |
   | **插入/删除(头部)** | O(n)               | O(1)               |
   | **插入/删除(中间)** | O(n)               | O(1)（已知位置）   |
   | **插入/删除(尾部)** | 均摊O(1)           | O(1)               |
   | **内存分配**        | 偶尔需要重新分配   | 每次操作可能分配   |
   | **缓存友好性**      | 高                 | 低                 |
   | **迭代器失效**      | 容量变化时全部失效 | 只有被删除元素失效 |

2. **如果 `vector` 要加入的内容很多应该怎么做？**

   - 预先分配足够空间，避免多次扩容
   - 使用移动而非拷贝

3. **`push_back` 和 `emplace_back` 的区别？**

   | 特性         | push_back                   | emplace_back             |
   | :----------- | :-------------------------- | :----------------------- |
   | **参数**     | 接受对象本身                | 接受构造参数             |
   | **构造方式** | 先构造对象再拷贝/移动到容器 | 直接在容器内存中构造对象 |
   | **效率**     | 可能多一次拷贝/移动         | 通常更高效               |
   | **使用场景** | 已有对象需要放入容器        | 直接构造新对象到容器     |
   | **C++版本**  | C++98                       | C++11引入                |

4. **模板类、模板函数**

   模板是C++泛型编程的基础，允许编写与数据类型无关的代码，编译器根据参数自动确定模板参数类型

   ```cpp
   // 模板函数
   template <typename T>  // 或 template <class T>
   T max(T a, T b) {
       return (a > b) ? a : b;
   }
   ```

   ```cpp
   template <typename T>
   class Stack {
   private:
       std::vector<T> elements;
   public:
       void push(const T& element);
       T pop();
       bool empty() const { return elements.empty(); }
   };
   ```

   - 适用场景
     - 需要编写与数据类型无关的通用代码
     - 需要高性能的泛型实现
     - 实现容器类或算法库
     - 比如把线程池的任务队列中的任务类作为T，之后无论什么具体任务都可以复用代码

5. **STL 容器分类详解**

   - 序列式容器

     - 数组风格容器

       | 容器     | 底层实现     | 特点                              | 时间复杂度                     |
       | :------- | :----------- | :-------------------------------- | :----------------------------- |
       | `array`  | 固定大小数组 | C++11引入，封装原生数组，安全访问 | 随机访问: O(1)                 |
       | `vector` | 动态数组     | 尾部操作高效，支持随机访问        | 插入/删除末尾: O(1) 中间: O(n) |

     - 链表风格容器

       | 容器           | 底层实现 | 特点                                 | 时间复杂度                     |
       | :------------- | :------- | :----------------------------------- | :----------------------------- |
       | `list`         | 双向链表 | 任意位置高效插入删除，不支持随机访问 | 插入/删除: O(1) 访问: O(n)     |
       | `forward_list` | 单向链表 | C++11引入，更省空间，只支持前向遍历  | 插入/删除: O(1) 访问: O(n)     |
       | `deque`        | 分块数组 | 双端队列，头尾操作高效，支持随机访问 | 头尾插入/删除: O(1) 中间: O(n) |

   - 关联式容器

     - 有序关联容器（基于红黑树）

       | 容器       | 特点                         | 时间复杂度               |
       | :--------- | :--------------------------- | :----------------------- |
       | `set`      | 唯一键集合，自动排序         | 插入/删除/查找: O(log n) |
       | `multiset` | 允许重复键的集合，自动排序   | 同上                     |
       | `map`      | 键值对集合，键唯一且排序     | 同上                     |
       | `multimap` | 允许重复键的键值对集合，排序 | 同上                     |

     - 无序关联容器（基于哈希表）

       | 容器                 | 特点                     | 时间复杂度         |
       | :------------------- | :----------------------- | :----------------- |
       | `unordered_set`      | 唯一键集合，哈希存储     | 平均O(1)，最差O(n) |
       | `unordered_multiset` | 允许重复键的哈希集合     | 同上               |
       | `unordered_map`      | 键值对哈希表，键唯一     | 同上               |
       | `unordered_multimap` | 允许重复键的键值对哈希表 | 同上               |

   - 容器适配器

     | 适配器           | 底层容器     | 特点                                           |
     | :--------------- | :----------- | :--------------------------------------------- |
     | `stack`          | `deque/list` | LIFO(后进先出)结构，默认使用deque              |
     | `queue`          | `deque/list` | FIFO(先进先出)结构，默认使用deque              |
     | `priority_queue` | `vector`     | 优先级队列，默认最大堆，使用vector作为底层容器 |

6. **`unordered_map` 和 `map` 的区别？为什么一般都用 `map`？**

   | 特性                    | unordered_map (哈希表) | map (红黑树)                |
   | :---------------------- | :--------------------- | :-------------------------- |
   | **底层实现**            | 哈希表                 | 红黑树                      |
   | **元素顺序**            | 无序                   | 按键值排序                  |
   | **查找时间复杂度**      | 平均O(1)，最差O(n)     | O(log n)                    |
   | **插入/删除时间复杂度** | 平均O(1)，最差O(n)     | O(log n)                    |
   | **内存使用**            | 较高(哈希桶)           | 较低                        |
   | **迭代器稳定性**        | 插入/删除可能导致失效  | 除删除元素外保持稳定        |
   | **自定义键类型要求**    | 需要哈希函数和相等比较 | 只需严格弱序比较(operator<) |

   一般用 `map` 的原因：

   - **确定性**：元素始终有序，便于调试和序列化
   - **稳定性**：迭代器在插入时不会失效
   - **范围查询**：支持lower_bound/upper_bound等有序操作
   - **内存可预测性**：没有哈希表的rehash问题
   - **默认可用**：不需要为键类型定义哈希函数
   - **最差情况性能稳定**：不会因哈希冲突退化

7. **`vector` 扩容机制**

   - **超出容量时**：
     - 分配新的更大的内存块(通常是原大小的1.5或2倍)
     - 将原有元素**移动或拷贝**到新内存
     - 释放旧内存
     - 更新容量和迭代器
   - **扩容基数**：
     - 标准未规定具体值，各实现不同
     - VS通常用1.5倍，gcc通常用2倍
     - 1.5倍在长期多次插入后能更好地复用之前释放的内存块

   

## 新特性

1. **三种智能指针**

   - `std::unique_ptr`

     - 特点
       - **独占所有权**：一个资源只能由一个 `std::unique_ptr` 拥有
       - **不可复制**：不能通过拷贝构造函数或赋值运算符复制 `std::unique_ptr`
       - **可移动**：可以通过 `std::move` 转移所有权
     - 使用场景：适用于需要独占资源所有权的场景，如动态分配的对象
     - 实现原理：

   - `std::shared_ptr`

     - 特点

       - **共享所有权**：多个 `std::shared_ptr` 可以共享同一个资源

       - **引用计数**：内部维护一个引用计数器，当引用计数为 0 时自动释放资源

       - **可复制**：可以通过拷贝构造函数或赋值运算符复制 `std::shared_ptr`

     - 使用场景：适用于需要共享资源所有权的场景，如多个对象共享同一个资源

     - 实现原理：

   - `std::weak_ptr`

     - **特点**
       - **弱引用**：不增加引用计数，不会影响资源的生命周期。
       - **解决循环引用**：用于打破 `std::shared_ptr` 的循环引用问题。
       - **需要转换为 `std::shared_ptr`**：通过 `lock()` 方法获取一个 `std::shared_ptr`
     - 使用场景：适用于需要观察资源但不拥有资源的场景，如缓存、观察者模式、

2. **智能指针的线程安全**

   不是线程安全的，14新加了 `atomic_shared_ptr` 才保证

   解决方案是给智能指针加锁

   | 智能指针类型 | 引用计数线程安全                | 指向对象线程安全 | 典型使用场景               |
   | :----------- | :------------------------------ | :--------------- | :------------------------- |
   | `shared_ptr` | **是** (原子操作)               | **否**           | 多线程共享对象             |
   | `unique_ptr` | 无引用计数                      | **否**           | 独占所有权，线程内使用     |
   | `weak_ptr`   | **是** (与关联的shared_ptr同步) | **否**           | 解决 `shared_ptr` 循环引用 |

3. **`unique_ptr` 怎么赋值给另一个 `unique_ptr`？**

   - 只能通过**移动语义**将所有权转移来赋值

     ```c++
     std::unique_ptr<int> ptr1(new int(42));
     std::cout << "ptr1: " << *ptr1 << std::endl; // 输出 42
     
     // 将 ptr1 的所有权转移给 ptr2
     std::unique_ptr<int> ptr2 = std::move(ptr1);
     
     // ptr1 现在为空
     if (!ptr1) {
         std::cout << "ptr1 is now null" << std::endl;
     }
     
     // ptr2 现在拥有资源
     std::cout << "ptr2: " << *ptr2 << std::endl; // 输出 42
     ```

4. **`move` 的应用场景？**

   - 用于将对象的所有权从一个实例转移到另一个实例。它主要用于实现 **移动语义**，避免不必要的拷贝操作，从而提高性能

   - 应用场景：

     - 转移 `shard_ptr` 的所有权

     - 优化容器操作，避免拷贝构造，直接移动元素

       ```c++
       int main() {
           std::vector<std::string> vec;
           std::string str = "Hello";
       
           // 使用 std::move 将字符串移动到容器中
           vec.push_back(std::move(str));
       
           std::cout << "str after move: " << str << std::endl; // 输出空字符串
           std::cout << "vec[0]: " << vec[0] << std::endl; // 输出 Hello
       
           return 0;
       }
       ```

     - 实现移动构造函数和移动赋值运算符

     - 从函数返回局部对象

       ```c++
       std::string createString() {
           std::string str = "Hello, World!";
           return std::move(str); // 使用 std::move 返回
       }
       
       int main() {
           std::string result = createString();
           std::cout << result << std::endl; // 输出 Hello, World!
       
           return 0;
       }
       ```

     - 在需要传递或返回大型对象时，使用 `std::move` 避免深拷贝

5. **左值和右值、右值引用及其作用？**

   | 特性     | 左值 (lvalue)      | 右值 (rvalue)                  |
   | :------- | :----------------- | :----------------------------- |
   | 定义     | 有持久身份的对象   | 临时对象或字面量               |
   | 示例     | 变量、函数返回引用 | 临时对象、字面量、move后的对象 |
   | 地址     | 有确定地址         | 通常无持久地址                 |
   | 生命周期 | 作用域内持续       | 表达式结束后销毁               |

   右值引用的核心作用：

   - 实现移动语义
   - 完美转发：保持参数原始类型
   - 优化临时对象处理

   **如果没有右值引用，怎么延长右值的生存期**？

   - 使用 `const` 左值引用延长临时对象生命周期

6. 

7. snprintf sprintf 

8. 

9. unordered_map和map的区别？为什么一般都用map？

10. 禁用掉的构造函数或运算符去使用会报什么错？在哪个时期？

11. 几种类型转换的方式有什么区别

12. crtp特性

13. 模板元编程？比如让templae T这个T只能接收某一个基类如何去实现？

14. const用在哪？（常量，常成员函数，底层const）

15. const &amp; 传参为什么效率高？（不需要拷贝）

16. vector超出容量会怎样？（以1.5或者2倍扩容）扩容基数？

17. 虚函数表是类还是对象拥有的？（类）

18. 怎么获取虚函数表？（虚表指针）

19. map查询效率?unordered_map是哈希表，O(1)；map是红黑树，O(logn)

20. map的key是自定义的类，需要注意什么?类要实现<的重载，保证key可以比较（也可以是函数对象）

21. 遇到过内存泄露吗？这里以为问的是项目（傻），说没有，使用了智能指针（应该举小例子）

22. 到过内存越界吗？这里答错了，讲成栈溢出（举例数组下标越界就行）

23. 编程遇到错误怎么解决？用过GDB吗？用vscode断点调试，没用过

24. **抽象类和接口类的区别？**

    - 所有成员函数都是纯虚函数（没有非虚函数或成员变量），即**接口类**。
    - **能否实例化**：
      - **直接实例化** ❌ 不能（所有方法均未实现）。
      - **通过派生类实例化** ❌ 仍然不能（除非派生类实现所有方法）。

    | 特性          | 抽象类 (Abstract Class)  | 接口(Interface)                 |
    | :------------ | :----------------------- | :------------------------------ |
    | **语法实现**  | 包含至少一个纯虚函数     | C++中无原生接口，用纯抽象类模拟 |
    | **成员变量**  | 可以包含成员变量         | 只应包含静态常量(模拟接口时)    |
    | **方法实现**  | 可以提供部分方法的实现   | 所有方法都是纯虚函数(无实现)    |
    | **继承关系**  | 类继承(可多重继承)       | 类继承(推荐用纯抽象类模拟)      |
    | **构造/析构** | 可以有构造函数和析构函数 | 只有虚析构函数                  |
    | **使用场景**  | 提供部分通用实现         | 定义行为契约                    |

25. **内存泄漏是什么？举例子，如何排查内存泄漏？**

    内存泄漏指程序在动态分配内存后，失去对该内存的控制而无法释放，导致该内存区域无法再被程序或操作系统使用的情况

    检测工具：Valgrind、AddressSanitizer

## 程序设计

1. 虚析构函数的必要性

## 语言特性

1. **C++ 怎么保证线程安全？**

   - 保证线程安全是确保多个线程并发访问共享资源时不会导致数据竞争或未定义行为的关键
   - **标准库中的容器不是线程安全的**
   - 使用互斥锁：线程同步，保护共享资源
   - 使用原子操作：简单的共享变量
   - 使用条件变量：用于线程间的通信，通常与互斥锁一起用
   - 使用无锁数据结构：通过原子操作实现线程安全，避免锁的开销

2. **多态底层怎么实现的？**

   - 虚函数表（vtable）机制：

     1. 每个包含虚函数的类都有一个虚函数表
     2. 每个对象包含一个指向vtable的指针(vptr)
     3. 调用虚函数时通过vptr找到vtable再定位具体函数

     ```cpp
     class Base {
     public:
         virtual void func1() {} // 虚函数
         virtual void func2() {}
     };
     
     class Derived : public Base {
     public:
         void func1() override {} // 重写虚函数
     };
     
     // 内存布局实例：
     Derived对象内存布局：
     +-------------------+
     | vptr (指向Derived的vtable) |
     | Base类成员变量      |
     | Derived类成员变量   |
     +-------------------+
     
     Derived的vtable：
     +-------------------+
     | &Derived::func1   | // 重写的函数
     | &Base::func2      | // 继承的函数
     +-------------------+
     ```

   - 动态绑定的运行时行为

     ```cpp
     Base* b = new Derived();
     b->func1(); // 实际调用Derived::func1()
     ```

     1. 通过b找到vptr
     2. 通过vptr找到vtable
     3. 在vtable中找到func1的地址
     4. 调用该地址的函数

3. C++内存泄漏如何判断

4. 面向对象的好处和优势

# Linux 命令

1. 如何查找一个进程

   - `ps`

     ```shell
     ps aux | grep <进程名>   # 查找进程的PID
     # ps 是查看后台进程
     # ps aux 是输出特定的格式：
     # USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND
     ```

2. 查看端口使用情况

   - `netstat`

     ```shell
     netstat -tulnp    # 查看端口使用情况
     netstat -n		  # 用 "源IP", "源端口号", "目的IP", "目的端口号", "协议号" 这样一个五元组来标识一个通信
     ```

3. 显示系统当前内存的使用情况，包括已用内存、可用内存和交换内存

   - `free`

     ```shell
     free -h       # 以人类可读的方式显示内存使用情况
     ```

4. 如何杀死一个进程

   - `kill`

     ```shell
     kill <PID>      # 终止该进程
     kill -9 <PID>   # 强制终止该进程
     ```

   - `killall`

     ```shell
     killall <进程名>  # 终止所有该进程
     ```

5. 如何查看操作系统日志

   - Linux 系统日志通常位于 `/var/log` 目录下

   - `journalctl`

     ```shell
     journalctl -xe           # 查看系统日志
     journalctl -f            # 实时查看日志
     journalctl -u sshd       # 查看 SSH 服务日志
     ```

   - `cat/tail`

     ```shell
     cat /var/log/syslog      # 读取系统日志
     dmesg | tail             # 查看最近的内核日志
     ```

6. 查看磁盘空间

   - `df`

     ```shell
     df -h    # 查看磁盘空间使用情况
     ```

7. 如何打印文件的绝对路径

   - `realpath`

     ```shell
     realpath <文件名>
     ```

8. 如何读取日志文件的末尾/开头10行

   - `head`

     ```shell
     head -n 10 <文件名>
     ```

   - `tail`

     ```shell
     tail -n 10 <文件名>
     ```

9. sed命令用过吗？有什么作用？如何查看文件的指定行数的内容？

   - 'sed' 是一个流编辑器，可用于文本处理

   - 替换文本

     ```shell
     sed 's/old-text/new-text/' <文件名>
     ```

   - 删除某行

     ```shell
     sed '3d' <文件名>   # 删除第3行
     ```

   - 查看指定行数的内容

     ```shell
     sed -n '10p' <文件名>   # 查看第10行内容
     ```

10. 常用的Linux系统版本

    - Ubuntu22.04

11. linux启动服务的命令

    - `systemctl`

      ```shell
      systemctl start <服务名>   # 启动服务
      systemctl stop <服务名>    # 停止服务
      systemctl restart <服务名> # 重启服务
      systemctl status <服务名>  # 查看服务状态
      ```

12. 将文件移动到别的路径，并解压文件，运行输出

    - `mv`, `tar`

      ```shell
      mv <文件名> <目标路径>        # 移动文件
      cd <目标路径>           
      tar -xzvf <name.tar.gz>     # 解压文件
      ./run.sh
      ```

13. Linux有哪些监控命令

    - `top`：查看所有进程和资源使用情况，CPU
    - `htop`：可以看做是`top`的高级版本
    - `NetHogs`：能够监控到每个进程的网络流量
    - `IPTraf`：网络流量监控，可以基于网卡、IP、协议等监控
    - `iotop`：监控进程磁盘I/O
    - `lsof`：显示打开的文件和进程，包括磁盘文件、网络套接字、管道、设备和进程
    - `iftop`：监控TCP\UDP流的网络流量，显示两台主机之间当前宽带的使用情况
    - `netstat`：监控TCP\UDP网络数据包传入和传出
    - `iostat`：监控每个磁盘分区的读写情况，通常用于查找存储设备性能问题
    - `vmstat`： 监控linux负载，报告关于内核线程、虚拟内存、CPU等活动的统计信息，展示平均负载
    - `tcpdump`：命令行网络数据包分析器，用于捕获和过滤 TCP/IP 包

14. linux环境cpu过高如何排查原因

    - 定位：
      - `top`确认cpu高的应用和进程
      - 定位异常进程对应的线程
    - 分析线程堆栈信息：
      - 获取堆栈信息，结合应用日志等进行分析
    - 方案验证
      - 修改代码，重新部署，观察是否解决

15. cpu使用率过高原因

    - 进程异常：某个进程进入死循环
    - 负载过高：同时运行的任务太多
    - I/O 争用：进程等待磁盘 I/O
    - 网络瓶颈：高网络中断消耗 CPU
    - 内存不足：导致频繁 Swap，CPU 等待数据

16. 进程线程控制操作命令

17. 性能监控与调试

    - **strace 跟踪系统调用**：

      ```bash
      # 只跟踪read,write两类系统调用
      # cat /proc/cpuinfo是被跟踪的目标命令
      strace -e trace=read,write cat /proc/cpuinfo
      # 运行这个命令后 strace 会启动 cat /proc/cpuinfo 进程，然后记录执行过程中的所有 read 和 write 系统调用，输出以下内容：
      read(3, "processor\t: 0\nvendor_id\t: GenuineIntel\n"..., 131072) = 512
      write(1, "processor\t: 0\nvendor_id\t: GenuineIntel\n"..., 512) = 512
      read(3, "cpu family\t: 6\nmodel\t\t: 142\n"..., 131072) = 512
      write(1, "cpu family\t: 6\nmodel\t\t: 142\n"..., 512) = 512
      ```

    - **perf 分析系统调用开销**：

      ```bash
      perf stat -e 'syscalls:sys_enter_*' ls
      ```

    - **内核跟踪点**：

      ```bash
      # 查看所有系统调用跟踪点
      sudo ls /sys/kernel/debug/tracing/events/syscalls/
      ```

## perf

1. 核心组件

   ```
   用户空间工具层
   ├── perf stat    # 统计计数
   ├── perf record  # 采样记录  
   ├── perf report  # 分析报告
   ├── perf top     # 实时监控
   └── perf probe   # 动态探针
   
   内核接口层
   ├── perf_event_open 系统调用
   ├── 硬件PMU (Performance Monitoring Unit)驱动
   ├── 软件事件抽象
   └── 环形缓冲区管理
   
   硬件支持层
   ├── CPU性能计数器
   ├── 缓存事件监控
   └── 分支预测统计
   ```

2. 事件类型

   - **CPU 相关**：
     - cpu-cycles (CPU周期数)
     - instructions (退休指令数)
     - branch-misses (分支预测失败)
     - cache-references (缓存访问)
     - cache-misses (缓存未命中)
   - **内存相关**：
     - mem-loads (内存加载)
     - mem-stores (内存存储)
     - tlb-load-misses (TLB未命中)
   - **内核抽象事件**：
     - context-switches (上下文切换)
     - page-faults (缺页异常)
     - cpu-migrations (CPU迁移)
   - 静态内核探针点：
     - `kmem:mm_page_alloc` (内存分配)
     - `sched:sched_switch` (任务切换)

3. 基本用法

   - 统计命令执行的基本性能指标

     ```bash
     # 统计 ls 命令的 CPU 周期、指令数、缓存命中率等
     perf stat ls
     ```

     ```
      Performance counter stats for 'ls':
     
               1.234567      task-clock (msec)         #    0.789 CPUs utilized          
                     12      context-switches          #    0.009 M/sec                  
                      0      cpu-migrations            #    0.000 K/sec                  
                    123      page-faults               #    0.100 M/sec                  
        <not supported>      cycles                                                      
        <not supported>      instructions                                                
        <not supported>      branches                                                    
        <not supported>      branch-misses                                               
     
            0.001563456 seconds time elapsed
     ```

   - 记录并分析CPU使用情况

     ```bash
     # 记录系统10秒的CPU使用情况
     sudo perf record -a -g -- sleep 10
     
     # 查看记录结果
     perf report
     ```

     在 `perf report` 界面中，你可以看到：

     - 热点函数调用
     - 调用栈信息
     - 各函数占用的CPU比例

   - 分析特定进程

     ```bash
     # 启动一个要分析的进程
     ./my_program &
     
     # 记录该进程的性能数据
     sudo perf record -p $(pidof my_program) -g -- sleep 30
     
     # 生成火焰图
     perf script | stackcollapse-perf.pl | flamegraph.pl > perf.svg
     ```

4. 工作模式

   - 计数模式（适合算子基础分析）

     ```bash
     # 统计矩阵乘法程序的缓存表现
     perf stat -e cache-misses,cache-references,instructions ./matrix_multiply
     ```

   - 采样模式（适合热点分析）

   ```bash
   # 每1000次缓存未命中采样一次调用栈
   perf record -e cache-misses -c 1000 -g -- ./ai_workload
   ```

   - 剖析模式（结合您的可视化经验）

   ```bash
   # 生成火焰图
   perf record -F 99 -g --call-graph dwarf -p $(pidof app)
   perf script | stackcollapse-perf.pl | flamegraph.pl > flame.svg
   ```

5. 实际案例：分析nginx性能

   ```bash
   # 1. 找到 nginx worker 进程
   ps aux | grep nginx
   
   # 2. 记录该进程的性能数据 (假设PID是1234)
   sudo perf record -p 1234 -g -- sleep 30
   
   # 3. 生成报告
   perf report
   
   # 或者生成火焰图
   perf script | stackcollapse-perf.pl | flamegraph.pl > nginx_perf.svg
   ```

## ebpf

eBPF（extended Berkeley Packet Filter）是一种可编程的内核扩展机制，最初由BPF（Berkeley Packet Filter）演化而来，BPF最初是为了在Unix系统上进行网络数据包过滤而设计的。它最早由Steven McCanne和Van Jacobson于1992年在BSD系统中引入，旨在提供一种轻量级的过滤机制，以帮助网络管理员监视和分析网络流量。最初的BPF具有一组预定义的指令集，用于过滤和处理网络数据包。

随着计算机网络和操作系统的发展，对BPF的需求也逐渐增加。在Linux内核中，BPF被广泛应用于网络包过滤、性能监控、安全审计等方面。然而，传统的BPF存在着功能受限、安全性差等问题，限制了其在复杂场景下的应用。为了解决这些问题，在2013年对BPF技术进行了改造升级并命名为eBPF。eBPF最早由Brendan Gregg和其他内核开发者在Linux3.15内核中引入到源码，用于安全有效地扩展内核的功能，而无需通过更改内核源代码或加载内核模块的方式来实现。

eBPF是对传统的BPF的扩展和增强。它引入了许多重要的变化，使得其功能更加强大、灵活和安全：

·可编程性增强：eBPF引入了一种基于LLVM的新的BPF编译器，使得BPF程序可以使用更丰富的指令集和语言特性编写。这使得eBPF程序具有更高的灵活性和表达能力，能够实现更复杂的功能。

·安全性提升：eBPF引入了一套严格的安全验证机制，包括对程序代码进行静态分析和动态验证，以及对程序访问的资源进行严格控制。这使得eBPF程序在内核中执行时更加安全，不会对系统的稳定性和安全性造成影响。

·支持更多的功能和用途：eBPF扩展了BPF的功能和用途，不仅可以用于网络包过滤和转发，还可以用于性能监控、安全审计、动态追踪等领域。这使得eBPF成为一种通用的内核扩展机制，为内核开发人员提供了更多的选择和可能性。

·支持用户态程序：eBPF引入了一种新的用户态BPF虚拟机，使得用户态程序也可以利用eBPF的功能。这使得eBPF不仅可以在内核中执行，还可以在用户态执行，从而扩展了其应用范围和灵活性。

eBPF的灵活强大功能使其不再仅局限于网络包过滤等网络分析场景，其在系统观测和网络安全监控领域也被广泛使用，它允许用户在不修改内核源代码的情况下，通过加载和执行自定义的eBPF程序来扩展内核功能。这些eBPF程序通过Hook机制与内核交互，它们可以对进入和离开内核的事件进行过滤和处理，以实现网络数据包的监控、性能统计和故障追踪等功能。

具体来说，用户根据自己的观测需求编写并编译eBPF程序生成eBPF指令，随后使用bpf()系统调用将生成的指令加载到内核的指定挂载点，当特定事件触发时系统执行这些eBPF指令，从而实现将所需观测信息向用户层的传递，这个过程是完全无侵入，对应用系统来说完全无感知的。

具体的插入eBPF程序实现hook观测点挂载的过程如下图所示：用户编写的eBPF程序（通常是C语言）通过编译器套件编译为eBPF字节码，然后使用 bpf 系统调用将 eBPF 程序加载到 Linux 内核中，当程序被加载到 Linux 内核中时，它在被附加到所请求的钩子上之前需要经过验证和JIT编译两个步骤，前者用来确保 eBPF 程序可以安全运行，后者将程序的通用字节码转换为机器特定的指令集，用以优化程序的执行速度。这样就成功的将机器码hook到用户想要进行挂载观测的点上。

从上面过程可以看出eBPF技术实现挂载与观测的诸多优点：用户可以根据自身需求灵活自定义eBPF程序，将更多观测内容导入到用户空间进行分析；验证过程通过检查程序的特权级以及死循环等指标，避免了eBPF程序对内核运行的安全稳定性造成影响；JIT即时编译使得eBPF程序可以像本地编译的内核代码或作为内核模块加载的代码一样高效地运行，有效减小了代码执行开销，尽可能小的影响系统的执行效率。

 BPF Map 读取
eBPF 程序运行时通常会将收集的数据存放在 BPF map 中，用户态程序可以周期性地查询或拉取这些 map 中的数据，用来统计、聚合和分析监控指标。
例如，可以统计函数调用次数、网络数据包统计、资源使用量等数据，然后通过命令行或程序接口展示。
环形缓冲区 (Ring Buffer)
利用 BPF ring buffer 可以实时传输事件数据，从内核空间向用户空间传递事件消息。这种方式适合处理高频、低延迟的数据流，用户态可以以流的方式接收和处理这些事件。
内核日志输出
通过 bpf_printk 函数输出调试信息，这些信息可以通过查看 /sys/kernel/debug/tracing/trace_pipe 或 dmesg 获取。这种方式适合简单的调试和验证，但一般不用于正式的监控数据采集。
集成至监控系统
将 eBPF 采集到的数据以 Prometheus 格式导出，再利用 Prometheus 进行数据拉取，并结合 Grafana 等工具生成实时的图表、直方图、折线图、热力图等。这样可以将 eBPF 监控数据以可视化面板的形式展示给用户。
高级工具展示
利用像 bcc、bpftrace、bpftool 等工具，用户可以直接在命令行中以动态追踪、实时统计的方式查看 eBPF 的输出，或结合各类专用平台（如 Cilium、SkyWalking、Falco 等）实现更复杂的监控、追踪和安全检测。

eBPF程序的一个核心概念是bpf_map，它是驻留在内核中的以键/值方式存储的数据结构，可以被任何知道它们的BPF程序访问，在用户空间运行的程序也可以通过使用文件描述符来访问bpf_map，所以其经常被用于用户空间和内核空间之间的数据交换和信息传递。eBPF提供了多种类型的maps，例如数组、队列、环形缓冲区等

有一些这个bpf_map_update_elem,bpf_map_lookup_elem之类的函数来更改和读取相关检测数据，然后读取的数据你可以在用户态程序保存，然后你想咋输出都可以滴

## git

1. `git merge` 和 `git rebase` 的区别及用法
   - `git merge` 是安全、保留历史的，适合团队协作； `git rebase` 是整洁、线性历史的，适合本地整理，建议只对未推送的提交使用 `rebase`
   - `git merge` 是保留分支历史的合并，生成一个新的 merge commit
   - `git rebase` 是将分支提交 “重放” 到目标分支上，无额外合并提交

# 中间件/开源软件/框架

## Redis

### 基本概念

1. **简单介绍**

   - 一种高性能的 **内存键值数据库**，核心价值是**用内存换速度**
   - 核心作用：
     - 缓存加速：将热点数据**存入内存**，减少对慢速存储如 MySQL 的访问
     - 高性能读写：支持每秒数十万级操作（读 10W+/s，写 8W+/s），适合高并发场景
   - 典型适用场景：缓存、分布式系统中会话存储、排行榜实时更新、消息队列
   - 不适合大数据量持久化存储、不支持完整ACID事务、不支持关系型查询

2. **redis的两种持久化机制？**

   - RDB（定时生成内存快照二进制文件）：适合数据备份，恢复速度快，对性能影响小，但可能丢失最后一次快照后的数据
   - AOF（记录所有写操作命令）：数据安全性高，支持秒级持久化，但文件较大，恢复速度慢
   - 建议同时使用：RDB做冷备，AOF做热备，利用各自优势

3. **redis的基本数据结构**

   | **数据结构**    | **底层实现**                  | **特点**                                | **常用命令**                   |
   | :-------------- | :---------------------------- | :-------------------------------------- | :----------------------------- |
   | **String**      | 动态字符串（SDS）             | 可存文本、数字、二进制数据（最大512MB） | `SET`, `GET`, `INCR`           |
   | **List**        | 双向链表或压缩列表（ziplist） | 支持双向操作，可作队列或栈              | `LPUSH`, `RPOP`, `LRANGE`      |
   | **Hash**        | 压缩列表或哈希表              | 适合存储对象（如用户信息）              | `HSET`, `HGET`, `HGETALL`      |
   | **Set**         | 哈希表或整数集合              | 无序、去重，支持交并差运算              | `SADD`, `SMEMBERS`, `SINTER`   |
   | **ZSet**        | 跳表（SkipList） + 哈希表     | 有序集合，按分数（score）排序           | `ZADD`, `ZRANGE`, `ZREVRANK`   |
   | **Bitmaps**     | String 的位操作               | 节省空间的布尔统计（如用户签到）        | `SETBIT`, `GETBIT`, `BITCOUNT` |
   | **HyperLogLog** | 概率算法                      | 基数统计（去重计数），误差0.81%         | `PFADD`, `PFCOUNT`             |

4. **redis中 `Hash` 结构的 `rehash` 过程是什么？**

   `Hash` 在扩缩容时触发渐进式 `rehash`

   1. **触发条件**：
      - 扩容：元素数 > 哈希表大小 × 负载因子（默认1）。
      - 缩容：元素数 < 哈希表大小 × 0.1。
   2. **过程**：
      - 分配新哈希表（大小为当前表的2倍或0.5倍）。
      - 逐步将旧表数据迁移到新表（每次增删改查迁移一个桶）。
      - 迁移完成后，用新表替换旧表。
   3. **优点**：
      - 避免一次性迁移导致服务阻塞

5. **LRU 和 LFU 的区别**

   | **策略** | **全称**              | **淘汰规则**                            | **适用场景**                 | 实现细节                                                     |
   | :------- | :-------------------- | :-------------------------------------- | :--------------------------- | ------------------------------------------------------------ |
   | **LRU**  | Least Recently Used   | 淘汰最久未访问的键                      | 访问模式随时间变化均匀       | 近似算法，随机采样部分键，淘汰其中最久未访问的               |
   | **LFU**  | Least Frequently Used | 淘汰访问频率最低的键（Redis 4.0+ 支持） | 存在热点数据，需长期统计频率 | 基于计数器（访问频率衰减 + 概率对数化），避免历史访问影响当前决策 |

### 集群

1. **集群相对于单机来说有什么不同点？**
   - 易于扩展，高性能，高可用性，但是需要额外维护成本
2. **集群如何进行数据同步？**
   - 主从同步，增量同步，全量同步，异步复制
   - 同步的时候有一个replication buffer缓冲区，会写入同步期间新增的数据，同步完rdb之后再同步这个命令，然后重放一次
3. **集群模式是否容易丢失数据？以及如何解决丢失数据的情况？**
   - 集群模式可能丢失数据，主要原因是异步复制
   - 解决方法：开启持久化（RDB/AOF），调整 `min-slaves-to-write` 和 `min-slaves-max-lag` 参数
5. **缓存穿透如果用空值法的话，如何避免大面积的内存被白白占用？**
   - 可以空值设置较短的TTL、使用布隆过滤器、后台任务定期检查和清理空值
6. **redisson相比于setnx灵活在哪？**
   -  同一线程可多次获取锁
   - 自动续期
   - 锁超时
   - 分布式支持
7. 采用延迟双删的情况下，如果MySQL数据库操作失败了怎么办？
8. redis刷新token是如何保证用户无感？

## Nginx

1. nginx的七层和四层
1. 反向代理和正向代理的区别及对应的使用场景
1. 正向代理如何实现负载均衡
1. **多线程好处很多，Nginx 为什么使用多进程而不是多线程?**
   - 因为 Nginx 最核心的目的是要保持**高可用性、高可靠性**，如果使用多线程，线程之间是共享同一个地址空间的，所以当某第三方模块引发地址空间导致段错误时，会导致整个nginx进程挂掉

## gRPC

## webSocket

1. Stream 流的实现原理？
2. 讲讲服务器、
   - 服务器是专门为提供服务、计算、存储或其他服务而设计的计算机，通常具有高性能、高可靠性、高安全性等特点
   - 会有不同的类型，用于托管网站、应用、数据库等
3. 如何进行项目部署，Docker用过吗？
   - 项目部署是指将开发完成的代码放到服务器上运行
   - 部署方式有：
     - 使用 shell 脚本，自动化执行部署步骤
     - 使用Docker容器化技术，打包应用及其依赖环境，实现一键部署
     - 大规模分布式部署使用 K8s，自动管理容器应用
   - Docker部署流程
     - 编写 Dockerfile
     - 构建镜像
     - 运行容器
4. 如何查看服务器的内存使用情况
   - 和在本机上一样
5. 介绍nginx，什么时候反向代理
   - Nginx 是一个高性能的 HTTP 服务器和反向代理服务器，指客户端请求被 Nginx 接收，然后转发到后端服务器
   - 特点：高并发、静态资源托管、负载均衡、反向代理

# 数据库

## 底层原理

1. 数据库采用的引擎？
2. MVCC 底层原理是什么？
3. **MySQL内部如何提高扫描效率？**
   - B+树索引，减少磁盘IO次数
   - 根据成本选择最优执行计划
   - InnoDB buffer pool缓存热数据
   - 提前读取可能需要的数据页
4. 为什么一般使用自增作为主键？（从数据库相关原理、索引方面回答）
5. 事务的隔离级别、索引？
6. 如何优化索引？
7. innodb 如何实现事务？
8. 还知道什么存储数据库引擎？

## 锁

1. 说说 MySQL 的锁机制
2. 乐观锁和悲观锁
3. **如何实现乐观锁？**为什么要用乐观锁？
   - 表中增加 `version` 字段，更新时检查版本
   - 条件更新 `UPDATE table SET data=?, version=version+1 WHERE id=? AND version=?`
4. 什么情况会出现超卖现象？乐观锁解决超卖如何实现？
5. 间隙锁是什么？用来处理什么情况？达到哪一种隔离级别

## SQL语句

1. 多表连接怎么优化
2. 多变连接的情况下，如果要分页查询该怎么改造？
3. 多表连接如何创建索引？联合索引是作用在哪里？
4. `join`, `from`, `groupby`, `order` 的执行顺序？

   - `FROM` > `JOIN` > `WHERE` > `GROUP BY` > `HAVING` > `SELECT` > `DISTINCT` > `ORDER BY` > `LIMIT`
5. 如何进行 SQL 语句优化？
6. 怎么判断加了索引？SQL 语句有没有用到索引？
7. 索引下推是什么？
8. 进行 `set` 语句的时候，undo log ,bin log ,redo log是怎么变化的？
9. MySQL 的 `join` 怎么优化

# 设计模式

## 微服务架构

**微服务架构**是一种将应用程序拆分成多个小型、独立、可部署的服务的架构风格。每个服务专注于实现某个业务功能，并通过网络（通常是 HTTP/REST、gRPC 等）与其他服务通信

1. 特点：

   | 特性           | 说明                                                     |
   | -------------- | -------------------------------------------------------- |
   | **单一职责**   | 每个服务只负责一个明确的业务功能（如用户服务、订单服务） |
   | **独立部署**   | 每个服务可以独立构建、测试、部署、扩展                   |
   | **技术多样性** | 不同服务可以使用不同的编程语言、数据库或框架             |
   | **松耦合**     | 服务间通过 API 通信，不共享内部数据结构                  |
   | **自治性**     | 每个服务拥有自己的数据库或存储，避免共享数据源           |
   | **水平扩展性** | 可单独对瓶颈服务扩容，提升资源利用率                     |

2. 挑战：

   | 挑战               | 描述                                                         |
   | ------------------ | ------------------------------------------------------------ |
   | **运维复杂度高**   | 服务数量庞大，需要自动化部署与监控                           |
   | **分布式问题**     | 网络延迟、容错处理、服务依赖管理                             |
   | **数据一致性**     | 各服务独立数据库，事务一致性需特别设计（如使用 Saga、Eventual Consistency） |
   | **测试复杂度增加** | 单元测试变简单，但集成测试变难                               |

3. 为什么选择微服务？

   - 适合大规模系统
   - 多团队并行开发
   - 更容易做 **CI/CD（持续集成/持续部署）**
   - 便于故障隔离、快速迭代、模块化演进

## 后端

### 概念

1. **认证和鉴权的区别？**
   - 认证是确认用户是谁的过程，验证用户的身份
   - 鉴权是确认用户能有权限做什么的过程

### 场景

1. 
1. 如果有一个内存敏感性应用，从哪些方面做考虑？（池化，合理管理对象生命周期，避免内存泄漏，单例复用对象）
1. 如果现在一个10WQPS去生成订单号的服务接口，你怎么设计(我以为是下订单，一直说异步)，雪花算法，独立出服务加集群(忘了说etcd和zookeeper了)
1. **主流电商用的是多进程还是多线程**
   - 通常采用多进程和多线程混合架构，前者用于任务隔离和横向扩展，后者用于高并发请求处理和 I/O 密集型任务
   - 多进程架构：
     - 应用场景：任务隔离、高可靠性、横向扩展
     - 优点：隔离性强、资源管理简单、适合CPU密集型任务
     - 缺点：IPC开销大、内存占用高
     - 典型应用：微服务架构、任务队列
   - 多线程架构：
     - 应用场景：高并发请求处理、共享内存频繁数据交换、I/O密集型任务
     - 优点：资源共享、开销低、适合I/O密集型任务
     - 缺点：线程安全问题、调试复杂、一个线程崩溃可能影响整个进程
     - 典型应用：web 服务器、数据库连接池、异步任务处理
1. 贪心和DP在实际应用中的选用
1. 怎么对大型网络进行监测
   - 使用网络监控工具，如 Nagios、Zabbix、Prometheus 等
1. 批处理工具
   - linux中用shell， python脚本
   - windows中使用 `.bat` 脚本
   - 主要用于自动执行重复性任务
1. 两个vLan新加一台设备，问arp协议的工作过程？
   - ARP 协议用于在局域网中解析 IP 地址到 MAC 地址
   - 设备加入 VLAN：
     - 设备连接到交换机，并被配置在某个 VLAN（例如 VLAN 10）
     - 交换机会为该设备分配一个 IP（如果使用 DHCP）。
   - 设备发送 ARP 请求：
     - 设备需要访问同 VLAN 设备时，发送 ARP Request 广播，询问“某个 IP 地址对应的 MAC 地址”。
   - ARP 响应：
     - 目标设备（192.168.10.20）返回 ARP Reply
   - 跨 VLAN 访问（需要路由）：
     - 如果 Host A 需要访问 VLAN 20 的设备，则 VLAN 之间不能直接通信，必须通过三层设备（如路由器或三层交换机）。
     - Host A 发送 ARP 请求，查找 网关（Router/Layer 3 Switch）的 MAC 地址。
     - 通过网关进行路由，VLAN 10 和 VLAN 20 的数据才能互通。
1. 当公司设备出现紧急故障影响业务该如何处理？
   - 迅速通知 运维团队、开发团队、管理人员的相关人员，避免问题扩大
   - 初步排查故障：
     - 硬件问题：服务器是否宕机、磁盘是否满了 (df -h)、CPU 负载 (top)、内存 (free -m)
     - 网络问题：使用 ping、traceroute 检查网络连通性，查看 iptables 或 firewalld 配置
     - 应用问题：查看日志、监控指标，观察 CPU/内存是否异常
   - 采取紧急应对措施
     - 重启服务
     - 回滚版本
     - 切换灾备
   - 事后总结和优化
1. 客户端、服务端传输数据，分别储存数据在哪里？

### 与1、3项目相关可能问题

#### 项目一

1. **如果项目需要升级扩展，会使用什么办法？**
   - 使用微服务架构拆分核心功能
   - 引入K8s进行容器编排，实现弹性伸缩
2. **网络编程怎样实现多用户管理？**
   - 使用 tokio 的异步任务处理每个连接
   - 用 `Arc+Mutex` 保证连接池的线程安全
   - 基于 Session Token 的用户身份验证
   - 连接心跳检测和超时断开机制
3. **项目使用了 Redis，如果要高缓存一致性又要并发应该怎么做？**
   - 一致性策略：
     - 写穿透(Write-through)模式：先更新数据库，再更新缓存
     - 使用Redis事务或Lua脚本保证原子性
     - 采用双删策略防止并发更新问题
   - 并发控制：
     - `tokio`
4. **如何提升服务的可用性？**
   - 用 etcd 实现服务发现和健康检查
   - 引入负载均衡
   - 交易数据多副本存储
   - 定期灾备演练
5. **日志系统设计与线程安全**
   - 分级分段日志（Trace/Debug/Info/Warn/Error）（日志分为多个文件，按日期线程等维度划分，每个日志用一个锁）
   - 暂存日志信息到缓冲区中，缓冲区满的时候线程处理日志（如批量写入减少 I/O 操作），或者使用异步线程后台处理避免阻塞主业务
   - 使用 MPSC 通道实现多生产者单消费者模式

# 人性问答

### 个人经历

#### 有和导师做过真实的项目吗？

我们组不接横向项目，主要是做科研然后主动联系企业找落地机会。比如我参与的 vkernel 项目已经部署在真实集群环境中，并且给多家企业做过演示，得到了比较积极的反馈。业务场景主要是政企部门、信创企业，会有一些数字化转型，把传统业务上云改造，还有安全定制的需求

#### 有得过什么奖或打过什么比赛吗？

拿过学校的多个奖学金，也参加过美赛、全国大学生系统能力赛，分别获得奖项。另外本科期间参加过一些没有拿奖但收获很多的比赛，比如数模国赛、挑战杯、数学竞赛之类的

#### 你在团队合作方面有什么经验？如果让你复盘，你怎么优化这个团队合作？

我参与过多个多人项目的合作，比如课程设计、比赛、实验室项目。我的经验是前期目标和分工要对齐清楚，中间要定期同步、及时沟通。如果复盘的话，我觉得可以在**流程工具使用**和**时间节点管理**上更主动一些，避免出现某个环节进度不一致影响整体节奏。

#### 你想通过实习获得什么？

我希望通过实习在几个方面成长：

- 一是在真实项目中提升技术能力；
- 二是和厉害的工程师一起工作，学习他们的思维方式和做事方法；
- 三是更深入地了解企业的项目流程和氛围，看是否匹配未来长期发展的方向，实现一次双向选择。

#### 如果你实习期间 mentor对你爱答不理的，或者他很忙，你怎么办?

我会先尊重 mentor 的工作安排，尽量自己多查资料、多总结，实在卡住就尽量把问题聚合起来，一次性高效提问。同时，我也会主动争取更多交流的机会，比如定期同步、汇报进展，用行动争取 mentor 的关注。

#### 最近学了些什么内容

除了实验室分配的任务，我最近也在关注 AI 领域底层面临的一些挑战，比如如何提升GPU资源的隔离性、实现GPU资源的虚拟化与细粒度分配、如何高效管理节点上不同的LLM任务/实例，看了点论文

#### 最近读了什么书

平时有读书的习惯，专业书籍的话手头放着一本《Linux 内核设计与实现》，想从底层理解系统的调度、内存管理等机制，对做系统开发或高性能计算都很有帮助。

#### 未来的职业规划

我希望未来能进入一些有前途、对社会有实际贡献的大型互联网公司做技术，我研究生的方向是操作系统，我也一直对底层系统充满兴趣。虽然这些技术离终端用户很远，但我相信正是这些基础设施支撑着整个互联网的效率与可靠性。**如果我写的代码能让后端系统更稳定、更高效，就能间接让成千上万的用户体验到更好的服务**，我觉得这是非常有价值的事情。所以未来我希望能在一条技术路线深耕发展，不断提升解决复杂问题的能力，把基础设施做得更稳、更优，同时也在过程中成长为有长期影响力的工程师。

像拼多多这样的公司，服务的是全国范围内海量的用户，尤其是很多下沉市场用户，他们对稳定、响应快、实惠的平台依赖很强。能参与这样一个系统的建设，不仅技术挑战大，而且是**在用技术真正服务大众、创造实际价值**，我会觉得特别有意义。

#### 优缺点

优点：

- **精力旺盛、抗压能力强**：我平时作息比较规律，精力充沛，也能在高强度的工作中保持专注和稳定输出，面对压力有较强的心理承受力。
- **学习能力强**：我对于新技术接受很快，遇到不会的问题会主动查资料、看源码、做记录、实操验证，形成自己的理解和体系。
- **乐观外向、沟通力不错**：我性格比较开朗，和团队沟通顺畅，合作意识比较强，在实验室、项目中也比较愿意主动承担责任。
- **技术栈偏底层，数理基础好**：我本科学的是数学，研究生转到计算机，对系统方向特别感兴趣，喜欢研究操作系统、虚拟化、内核安全等偏底层的内容，也做过一些这方面的项目，能沉下心打磨细节。

缺点：

- 我有时候**对事情缺乏规划性**，比较“p人”风格（指做事更偏执行而非提前规划），比如在项目中遇到问题会直接上手解决，但不太会提前做 roadmap 或拆解计划。这个问题我也在持续改进，比如通过写 TODO 清单、复盘总结、提前列出项目节奏，来让自己更有条理地推进任务。

### 岗位理解

#### 知道技术运维是做什么的吗？

- 应该有更细致的岗位划分，总体就是确保公司的互联网业务能不间断地为用户提供高质量服务
- 需要对业务所依赖的基础设施、基础服务、线上业务进行稳定性加强
- 通过日常巡检、监控、日志分析等技术手段，发现服务可能存在的隐患和安全问题、时发现和响应服务故障，减少服务中断的时间
- 对整体架构进行优化以屏蔽常见的运行故障，多数据中接入提高业务的容灾能力

### 企业文化

#### 有了解过pdd的作息吗？能接受吗？为什么觉得自己能接受？

- 是的，我有了解过pdd的作息安排，相对其他公司可能工作节奏较快、强度较高、工作时长也会多一点，公司的人均产能很高
- 我觉得自己能够接受，因为我首先比较适应快节奏、充满挑战的工作和环境
  - 首先，我**目标感强 & 抗压能力好**，我一直是一个目标驱动型的人，只要目标明确、事情有价值，我愿意全力以赴地投入其中，也具备持续稳定输出的能力
  - 其次，我对**快节奏、高强度**的环境本身是适应的。我从本科到研究生阶段，学的都是难度比较大的理工科专业，而且基本没有什么娱乐型爱好，物欲也比较低，大部分课余时间都在图书馆或实验室自学或者做项目，长期以来我都保持着高强度的学习和工作状态，也养成了自我管理、自我加压的习惯
  - **第三，我是一个 genuinely 喜欢工作的类型**。我在做事的过程中会获得成就感，喜欢把复杂的问题逐步拆解、攻克。比起单纯的“工作-生活平衡”，我更追求的是“在工作中成长，在成长中获得满足”
- 此外我也清楚，拼多多当前处于一个高速发展期，很多事情是要**拼时间、拼效率、拼执行力**才能做成的。能在这样的平台上与一群有冲劲的人一起打仗，对我来说是很有吸引力的。

#### 了解pdd哪些？对pdd什么看法+选择理由

- 我对pdd的了解主要包括以下几个方面：
  - **商业模式**：拼多多最初以社交电商起家，创造了拼团、砍价等创新玩法，如今已经成长为覆盖百亿补贴、农产品直供、制造品牌升级的平台型企业，在下沉市场和用户心智方面建立了深厚的护城河。
  - **技术驱动**：背后拼多多有很强的技术团队在支撑，比如推荐系统、分布式系统、风控和供应链协同，这些技术和数据驱动能力支撑了极致的性价比模式。
  - **执行力文化**：拼多多一直以执行力著称，是一个非常强调结果导向和责任心的公司
  - **扁平化管理**：职级少，述职少，能够更专注于技术工作
- 从我的角度来看，拼多多代表了新时代互联网企业的一种典型发展模式：快速迭代、注重用户体验以及利用技术驱动商业变革
- 我的看法是，我觉得pdd比较务实创新，不盲目追求表面繁荣，我个人是很欣赏这种接地气、能打硬仗的企业风格的，也很认同公司的使命和愿景，并且，我相信个人成长和事业发展很多时候是靠阶段性的努力积累的。我现在还比较年轻，在目前这个阶段，我希望自己能在高密度信息、高速成长的环境里快速提升能力，而拼多多提供的正是这样的土壤。

#### 你怎么看待现在这个社会很卷的风气的?

- 我觉得“卷”本身不是绝对的贬义词，要看我们**卷的目的和方式**：
  - 如果是**为了成长而努力、为了把事情做到极致而自驱地学习与挑战**，这种“卷”是正向的，是社会进步和个人发展的必要阶段。
  - 但如果是**低效内耗、盲目竞争、形式主义的加班文化**，那种“卷”我认为是值得反思的。
- 就我个人而言，我愿意在一个**有价值、有目标、有协作氛围**的团队中拼一拼，也相信努力总会积累复利回报

### 反问

#### 业务是什么





