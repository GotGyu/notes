# linux_monitor

## 项目背景

1. 做这个系统的原因：
2. 对接的需求：

## docker相关 

 [](./docker使用.md)

## 设计思路

```powershell
.
├── build # 编译过程产生的文件
│   ├── CMakeCache.txt
│   ├── CMakeFiles
│   │   ├── ...
│   ├── cmake_install.cmake
│   ├── display_monitor
│   │   ├── ...
│   ├── Makefile
│   ├── proto
│   │   ├── ...
│   ├── rpc_manager
│   │   ├── ...
│   └── test_monitor
│       ├── ...
├── cmake
│   ├── CMakeCache.txt # 核心配置文件，包含所有缓存设置，make过程中的各种变量值
│   ├── CMakeFiles # 构建过程中创建的目录，存储中间构建文件
│   │   ├── ...
│   ├── cmake_install.cmake
│   ├── display_monitor
│   │   ├── CMakeFiles
│   │   │   ├── ...
│   │   ├── cmake_install.cmake
│   │   ├── display
│   │   ├── display_autogen
│   │   │   ├── EWIEGA46WW
│   │   │   │   ├── moc_cpu_load_model.cpp
│   │   │   │   ├── moc_cpu_stat_model.cpp
│   │   │   │   ├── moc_monitor_inter.cpp
│   │   │   │   ├── moc_monitor_model.cpp
│   │   │   │   └── moc_monitor_widget.cpp
│   │   │   ├── moc_predefs.h
│   │   │   └── mocs_compilation.cpp
│   │   └── Makefile
│   ├── Makefile # 描述如何构建项目
│   ├── proto # 根据.proto文件自动生成的文件，会通过编译器集成
│   │   ├── CMakeFiles
│   │   │   ├── CMakeDirectoryInformation.cmake
│   │   │   ├── monitor_proto.dir
│   │   │   │   ├── ...
│   │   │   └── progress.marks
│   │   ├── cmake_install.cmake
│   │   ├── libmonitor_proto.a
│   │   ├── Makefile
│   │   ├── monitor_info.grpc.pb.cc # 实现了下面文件中声明的接口，包含与 gRPC 服务器进行交互的逻辑
│   │   ├── monitor_info.grpc.pb.h # 声明了 gRPC 服务的客户端和服务器接口
│   │   ├── monitor_info.pb.cc # 实现了下面文件中声明的类的成员函数，负责数据的序列化和反序列化等
│   │   └── monitor_info.pb.h # 包含了protobuf消息类的声明，并提供对数据的操作方法
│   ├── rpc_manager
│   │   ├── client
│   │   │   ├── CMakeFiles
│   │   │   │   ├── ...
│   │   │   ├── cmake_install.cmake
│   │   │   ├── libclient.a
│   │   │   └── Makefile
│   │   ├── CMakeFiles
│   │   │   ├── CMakeDirectoryInformation.cmake
│   │   │   └── progress.marks
│   │   ├── cmake_install.cmake
│   │   ├── Makefile
│   │   └── server
│   │       ├── CMakeFiles
│   │       │   ├── ...
│   │       ├── cmake_install.cmake
│   │       ├── Makefile
│   │       └── server
│   └── test_monitor
│       ├── CMakeFiles
│       │   ├── CMakeDirectoryInformation.cmake
│       │   └── progress.marks
│       ├── cmake_install.cmake
│       ├── Makefile
│       └── src
│           ├── CMakeFiles
│           │   ├── ...
│           ├── cmake_install.cmake
│           ├── Makefile
│           └── monitor
├── CMakeLists.txt
├── display_monitor # 监控面板
│   ├── CMakeLists.txt
│   ├── cpu_load_model.cpp
│   ├── cpu_load_model.h # 用于展示来自监控系统的CPU负载数据，并支持数据更新和视图同步
│   ├── cpu_softirq_model.cpp
│   ├── cpu_softirq_model.h # 用于展示来自监控系统的软中断数据，并支持数据更新和视图同步
│   ├── cpu_stat_model.cpp
│   ├── cpu_stat_model.h # 用于展示来自监控系统的CPU使用数据，并支持数据更新和视图同步
│   ├── main.cpp # 基于Qt的GUI应用程序，是一个监控面板，与gRPC服务器通信，获取和显示监控信息
│   ├── mem_model.cpp
│   ├── mem_model.h # 用于展示来自监控系统的内存数据，并支持数据更新和视图同步
│   ├── monitor_inter.cpp
│   ├── monitor_inter.h #提供一个抽象的数据模型类，用于管理表格数据
│   ├── monitor_widget.cpp
│   ├── monitor_widget.h # 包含自定义的监视器小部件类，用于在 GUI 中显示监控数据
│   ├── net_model.cpp
│   └── net_model.h # 用于展示来自监控系统的网络数据，并支持数据更新和视图同步
├── docker
│   ├── build
│   │   ├── apt
│   │   │   └── sources.list
│   │   ├── base.dockerfile # 编译构建容器镜像
│   │   └── install # 一些压缩包和安装脚本
│   │       ├── abseil
│   │       ├── cmake
│   │       ├── grpc
│   │       ├── protobuf
│   │       └── qt
│   └── scripts # 用户用来进入容器的脚本
│       ├── monitor_docker_into.sh # 进入容器
│       └── monitor_docker_run.sh # 启动容器
├── proto  # 包含所有监控信息的.proto文件，定义数据结构和服务接口，为gRPC通信服务
│   ├── CMakeLists.txt
│   ├── cpu_load.proto
│   ├── cpu_softirq.proto
│   ├── cpu_stat.proto
│   ├── mem_info.proto
│   ├── monitor_info.proto
│   └── net_info.proto
├── rpc_manager
│   ├── client
│   │   ├── CMakeLists.txt
│   │   ├── main.cpp # 创建一个RpcClient实例，将monitor_info发送到gRPC服务器
│   │   ├── rpc_client.cpp
│   │   └── rpc_client.h # 自定义的客户端类 RpcClient，用于与远程gRPC服务器通信
│   ├── CMakeLists.txt
│   └── server # 实现gRPC服务器，监听来自客户端的请求并提供服务
│       ├── CMakeLists.txt
│       ├── main.cpp
│       ├── rpc_manager.cpp
│       └── rpc_manager.h # 定义一个gRPC服务实现类
└── test_monitor # 获得监控数据
    ├── CMakeLists.txt
    ├── include
    │   ├── monitor
    │   │   ├── cpu_load_monitor.h # 获取cpu负载数据，下类似
    │   │   ├── cpu_softirq_monitor.h
    │   │   ├── cpu_stat_monitor.h
    │   │   ├── mem_monitor.h
    │   │   ├── monitor_inter.h
    │   │   └── net_monitor.h
    │   └── utils
    │       ├── read_file.h # 读文件
    │       └── utils.h
    └── src
        ├── CMakeLists.txt
        ├── main.cpp # 启动一个线程，定期从不同的监控模块获取系统监控数据，并通过 gRPC 客户端将这些数据发送到服务器
        ├── monitor
        │   ├── cpu_load_monitor.cpp
        │   ├── cpu_softirq_monitor.cpp
        │   ├── cpu_stat_monitor.cpp
        │   ├── mem_monitor.cpp
        │   └── net_monitor.cpp
        └── utils
            └── read_file.cpp 
```

## 构建过程

1. 构建项目需要的环境容器
   
   `base.dockerfile` 中构建了装有所有环境的容器，安装了各种工具如`git`, `vim`,`cmake`,`grpc`等，执行完成后可以在 `docker images` 中看到
   ```sh
   # ./docker/build
   docker build --network host -f base.dockerfile . 
   ```
2. 进入容器
   
   启动刚才构建的容器，并且将容器内的 `work` 目录挂载到主机的工作目录，随后以root用户身份，交互式地启动并进入容器
   ```sh
   cd <scripts_content>
   #启动容器
   ./monitor_docker_run.sh 
   #进入容器
   ./monitor_docker_into.sh
   ```
3. 在容器中编译项目代码
   ```sh
   # 进入挂载目录
   cd /work
   # 进入编译目录
   cd cmake
   # 根据..的CMakeLists.txt文件生成构建系统
   cmake ..
   # 使用8个并行任务加速构建
   make -j8
   ```
4. `./CmakeLists.txt` 
   
   先指定了 `Cmake` 版本，然后设置 `cmake` 模块所在路径和C++编译标准版本，然后依次 `add_subsidirectory` 添加并构建子目录：
   - `add_subdirectory(rpc_manager)`
     
     添加并构建子目录：
     - `add_subdirectory(server)`
       
       将 `server` 编译为可执行文件
     - `add_subdirectory(client)`
       
       将 `client` 编译为静态库
   - `add_subdirectory(test_monitor)`
     
     将 `monitor` 编译为可执行文件
   - `add_subdirectory(proto)`
     
     加载系统中安装的 `protobuf, gRPC, c-ares` 库，将 `monitor_info` 编译为静态库，然后根据 `.proto` 文件生成 `gRPC` 和 C++代码
   - `add_subdirectory(display_monitor)`
     
     加载系统中安装的 `Qt5, Core, Widgets` 库，将 `display_monitor` 编译为可执行文件
5. 先运行 `gRPC` 的服务器
   ```sh
   cd /work/build/rpc_manager/server
   ./server
   ```
   
   若不执行这步，而直接 `./monitor` 的话，会显示连接失败
6. 启动监控服务
   
   新建一个终端，进入容器
   ```sh
   cd /work/build/test_monitor/src
   ./monitor 
   ```
7. 在客户端显示
   
   新建一个终端，进入容器
   ```sh
   cd /work/build/display_monitor
   ./display 
   ```
8. adf

## CMake

### 简介

- 管理源代码构建的工具，广泛用于C/C++，也可以其他语言，便于**跨平台安装、编译**，简化软件的构建、测试、打包过程。
- 支持多种操作系统，可以为不同的编译环境生成相应的构建文件，如Unix Makefiles、Ninja、Visual Studio

### 配置文件

- 通过编写 `CMakeLists.txt` 配置文件，CMake能够生成标准的构建文件（如Makefile或Visual Studio项目文件），从而简化了项目的构建过程。开发者只需使用`cmake`和`make`等命令即可完成编译和链接等操作
- `CMakeLists.txt` 文件中描述了如何编译和构建项目，cmake构建过程中，该文件会告诉CMake如何查找源代码、依赖库、设置编译选项、生成目标文件、如何组织整个构建过程

### 常用命令

1. 指定 `cmake` 的最小版本
   ```
   // 可选命令，但如果使用了高版本cmake特有的命令时，就需要加这一行
   cmake_minimum_required(VERSION 3.4.1)
   ```
2. 设置项目名称
   ```
   // 非强制，但最好写
   // 会引入两个变量 demo_BINARY_DIR 和 demo_SOURCE_DIR
   // 自动定义两个等价的变量 PROJECT_BINARY_DIR 和 PROJECT_SOURCE_DIR
   project(demo)
   ```
3. 设置编译类型
   ```
   add_executable(demo demo.cpp) # 生成可执行文件
   add_library(common STATIC util.cpp) # 生成静态库
   add_library(common SHARED util.cpp) # 生成动态库或共享库
   ```
   
   `add_library` **默认生成静态库**，通过以上命令生成文件名字
   - 在 Linux 中是：
     - `demo`
     - `libcommon.a`
     - `libcommon.so`
   - 在 Windows 中是：
     - `demo.exe`
     - `common.lib`
     - `common.dll`
4. 指定编译包含的源文件
   - 明确指定包含哪些源文件
     ```
     # demo.cpp相当于demo的main函数文件
     # demo.cpp include "test.h"和"util.h"，所以要把其cpp函数链接进来
     # 一般会先用test.cpp以及其所有用到的所有相关文件先做一个动态库
     add_library(demo demo.cpp test.cpp util.cpp)
     ```
   - 搜索所有的 `cpp` 文件
     ```
     # aux_source_directory(dir VAR) 发现一个目录下所有的源代码文件并将列表存储在一个变量中
     aux_source_directory(. SRC_LIST) # 搜索当前目录下的所有.cpp文件
     add_library(demo ${SRC_LIST})
     ```
   - 自定义搜索规则
     ```
     file(GLOB SRC_LIST "*.cpp" "protocol/*.cpp")
     add_library(demo ${SRC_LIST})
     # 或者
     file(GLOB SRC_LIST "*.cpp")
     file(GLOB SRC_PROTOCOL_LIST "protocol/*.cpp")
     add_library(demo ${SRC_LIST} ${SRC_PROTOCOL_LIST})
     # 或者
     file(GLOB_RECURSE SRC_LIST "*.cpp") #递归搜索
     FILE(GLOB SRC_PROTOCOL RELATIVE "protocol" "*.cpp") # 相对protocol目录下搜索
     add_library(demo ${SRC_LIST} ${SRC_PROTOCOL_LIST})
     # 或者
     aux_source_directory(. SRC_LIST)
     aux_source_directory(protocol SRC_PROTOCOL_LIST)
     add_library(demo ${SRC_LIST} ${SRC_PROTOCOL_LIST})
     ```
5. 查找指定的库文件
   
   `find_library(VAR name path)`查找到指定的预编译库，并将它的路径存储在变量中。
   默认的搜索路径为 `cmake` 包含的系统库。类似的命令还有 `find_file()`、`find_path()``、`find_program()`、`find_package()`
   ```
   find_library( # Sets the name of the path variable.
                 log-lib
    
                 # Specifies the name of the NDK library that
                 # you want CMake to locate.
                 log )
   ```
6. 设置包含的目录
   
   将指定目录添加到编译器的头文件搜索路径之下
   ```
   include_directories(
       ${CMAKE_CURRENT_SOURCE_DIR}
       ${CMAKE_CURRENT_BINARY_DIR}
       ${CMAKE_CURRENT_SOURCE_DIR}/include
   )
   ```
7. 设置链接库搜索目录
   ```
   link_directories(
       ${CMAKE_CURRENT_SOURCE_DIR}/libs
   )
   ```
8. 指定目标需要包含的头文件路径
   - 需要用关键字来指定参数的范围
   ```
   target_include_directories(monitor PUBLIC
     ${PROJECT_SOURCE_DIR}/test_monitor/include
     ${PROJECT_SOURCE_DIR}/rpc_manager
   )
   ```
9. 设置 target 需要链接的库
   
   用于指定一个目标（如可执行文件或库）依赖于哪些其他目标。
   
   此处可以使用关键字来定义链接关系的作用范围：如 ` target_link_libraries(client PUBLIC monitor_proto)`
   - `PUBLIC`：链接到 `client` 的库会传播到依赖 `client` 的其他目标。也就是说，如果有其他目标链接到 `client`，那么这些目标也会自动链接 `monitor_proto`
   - `PRIVATE`：只有 `client` 目标会链接这个库，依赖 `client` 的其他目标不会继承这个链接关系
   - `INTERFACE`：这个库不会直接链接到 `client`，而是通过 `client` 传递给其他依赖 client 的目标
   ```
   target_link_libraries( # 目标库
                          demo
    
                          # 目标库需要链接的库
                          # log-lib 是上面 find_library 指定的变量名
                          ${log-lib} )
   ```
   - 指定链接动态库或静态库
     ```
     target_link_libraries(demo libface.a) # 链接libface.a
     target_link_libraries(demo libface.so) # 链接libface.so
     ```
   - 指定全路径
     ```
     target_link_libraries(demo ${CMAKE_CURRENT_SOURCE_DIR}/libs/libface.a)
     target_link_libraries(demo ${CMAKE_CURRENT_SOURCE_DIR}/libs/libface.so)
     ```
   - 指定链接多个库
     ```
     target_link_libraries(demo
         ${CMAKE_CURRENT_SOURCE_DIR}/libs/libface.a
         boost_system.a
         boost_thread
         pthread)
     ```
10. 设置变量
    - set 直接设置变量的值
      ```
      set(SRC_LIST main.cpp test.cpp)
      add_executable(demo ${SRC_LIST})
      ```
    - set 追加设置变量的值
      ```
      set(SRC_LIST main.cpp)
      set(SRC_LIST ${SRC_LIST} test.cpp)
      add_executable(demo ${SRC_LIST})
      ```
    - list 追加或者删除变量的值
      ```
      set(SRC_LIST main.cpp)
      list(APPEND SRC_LIST test.cpp)
      list(REMOVE_ITEM SRC_LIST main.cpp)
      add_executable(demo ${SRC_LIST})
      ```
11. 条件控制
12. 添加子目录并构建该子目录
    - 指定一个子目录 `sub_dir`，子目录下应该包含 `CMakeLists.txt` 文件和代码文件
    - `binary_dir` 为可选参数，指定一个目录，用于存放输出文件
    ```
    add_subdirectory(sub_dir [binary_dir])
    ```
13. 打印信息
    ```
    message(${PROJECT_SOURCE_DIR})
    message("build with debug mode")
    message(WARNING "this is warnning message")
    message(FATAL_ERROR "this build has many error") # FATAL_ERROR 会导致编译失败
    ```
14. 包含其他 `cmake` 文件
    ```
    include(./common.cmake) # 指定包含文件的全路径
    include(def) # 在搜索路径中搜索def.cmake文件
    set(CMAKE_MODULE_PATH ${CMAKE_CURRENT_SOURCE_DIR}/cmake) # 设置include的搜索路径
    ```

## protobuf

### 简介

- 全称为Protocol Buffers，是Google开发的一种轻量级的数据交换格式，可以理解为一种**更灵活、高效的数据格式**
- 能够序列化（数据结构/对象->二进制串）和反序列化（二进制串->数据结构/对象），属于通信协议的一部分，在数据结构和对象 与 用于存储和传输的格式 之间相互传输
- 在网络传输和数据存储等场景中广泛应用，特别适用于**对时间效率或空间效率方面有极高要求**的场景，如服务器间的海量数据传输与通信。通过使用Protobuf，可以简化数据的存储和传输过程，提高系统的性能和可靠性

### 为什么需要（反）序列化

- 数据可持久化：
  - 序列化：通过将内存中的对象或数据结构转换为可存储的结构，如：二进制、json、xml等，数据就可以被保存在文件系统、数据库或其他持久存储介质中
  - 反序列化：从存储介质中读取序列化的数据，并还原为内存中的对象或数据结构，允许数据在应用程序关闭后得以保留和恢复

- 网络通信：
  - 发送方将数据序列化为可传输的格式，数据能够在不同的计算机之间通过网络传递。接收方通过反序列化将接收到的数据还原成原始对象和数据结构，以便在本地使用。

- 跨语言：

### 序列化协议特性

每种序列化协议都有优缺点，系统设计过程中需根据特性选择合适的

- 通用性：是否与语言、平台无关
- 鲁棒性
- 可调试性/可读性：protobuf不可读，XML、JSON可读
- 性能：因为使用二进制格式，相比于其他序列化机制，如XML和JSON，具有更高的性能和更小的数据体积
- 可扩展性/兼容性：protobuf支持数据结构的向前和向后兼容。当数据结构发生变化时，可以向旧的数据结构中添加新的字段，而不会影响已有的数据，可扩展性强
- 安全性/访问限制：往往考虑跨局域网访问的场景

**为什么pb会提高传输效率？**

- XML、JSON在进行数据编译时，数据文本格式更容易阅读，但进行数据交换时，设备就需要耗费大量的CPU在I/O动作上，会影响整个传输速率
- 而pb会将字符串序列化后（即**二进制数据**）再进行传输，字节数会比JSON、XML少很多，速率更快
- 序列化数据非常简洁、紧凑，与XML相比，序列化之后的数据量约为1/3-1/10
- 解析速度非常快，比对应的XML快约20-100倍

### 序列化底层组件

- IDL（Interface description language）文件：参与通讯的各方需要对通讯的内容做相关的约定，为建立一个与语言和平台无关的约定，约定需要采用与具体开发语言、平台无关的语言来进行描述，这种语言被称为接口描述语言（IDL），采用IDL撰写的协议约定称之为IDL文件。
- IDL Compiler：编译器，将IDL文件转换成各语言对应的动态库。
- Stub/Skeleton Lib：负责序列化和反序列化的工作代码。Stub是一段部署在分布式系统客户端的代码，一方面接收应用层的参数，并对其序列化后通过底层协议栈发送到服务端，另一方面接收服务端序列化后的结果数据，反序列化后交给客户端应用层；Skeleton部署在服务端，其功能与Stub相反，从传输层接收序列化参数，反序列化后交给服务端应用层，并将应用层的执行结果序列化后最终传送给客户端Stub。
- Client/Server：指的是应用层程序代码，他们面对的是IDL所生存的特定语言的class或struct。
- 底层协议栈和互联网：序列化之后的数据通过底层的传输层、网络层、链路层以及物理层协议转换成数字信号在互联网中传递。

### proto文件最终生成了什么

当编译 `xxx.proto` 时，编译器会以您选择的语言生成代码，您需要使用文件中描述的消息类型，包括获取和设置字段值、将消息序列化为输出流，并从输入流解析消息。

- 对于C++，编译器会根据每个 `.proto` 生成一个 `.h` 和 `.cc` 文件，其中包含文件中描述的每种消息类型的类。
  - `protoc` 处理 `.proto` 文件时，会为 message 定义数据结构成类，并且为其中的每个字段生成 ：
    - Getter（获取值）
    - Setter（设置值）
    - Mutable 方法（获取可变引用）
    - 内部访问方法
    
    这些函数名字都是比较类似、固定的，所以看开发文档就可以知道调用什么
- 对于Java，编译器会生成一个 `.java` 文件，其中包含每个消息类型类，以及 `Builder` ，用于创建消息类实例的特殊类。

```powershell
protoc --proto_path=IMPORT_PATH --cpp_out=DST_DIR --java_out=DST_DIR  path/to/file.proto
```

### ProtoBuf使用步骤

1. Step1：定义 proto 文件，文件的内容就是定义我们需要存储或者传输的数据结构，也就是定义我们自己的数据存储或者传输的协议
   ```protobuf
   // 定义 test.proto 文件
   syntax = "proto3";
   package monitor.proto;
   
   // message关键字用于定义消息类型，允许嵌套
   message CpuLoad {
       float load_avg_1 = 1;
       float load_avg_3 = 2;
       float load_avg_15 = 3;
     }
     
   message NetInfo {
       string name = 1;
       float send_rate = 2;
     }
   
   // service关键字用于定义gRPC服务接口
   // 用于声明一个服务，服务包含多个 RPC 方法，每个方法对应于客户端和服务器之间的一个远程调用
   service GrpcManager {
     rpc SetMonitorInfo(MonitorInfo) returns (google.protobuf.Empty) {
     }
   
     rpc GetMonitorInfo(google.protobuf.Empty) returns (MonitorInfo) {
     }
   }
   ```
2. Step2：使用编译器 protoc 来编译自定义的 proto 文件，用于生成 .pb.h 文件（proto 文件中自定义类的头文件）和 .pb.cc（proto文件中自定义类的实现文件）
   ```powershell
   # 编译
   protoc -I$SRC_DIR --cpp_out=$DST_DIR test.proto
   # 参数解释
   # -I$SRC_DIR 指定test.proto所在目录
   # --cpp_out=$DST_DIR 指定生成cpp相关文件，并指定生成路径
   # test.proto 需要编译的proto文件
   ```
3. 使用 ProtoBuf 的 C++ API 来读写消息

## proc

### 简介

在 Linux 中，`/proc` 是位于内存中的 **虚拟文件系统**，其中保存**运行时信息**，比如系统内存、磁盘IO、设备挂载信息、硬件配置等，所以proc是一个控制中心，用户可以通过更改其中某些文件来改变内核的运行状态；也是查询中心，可以通过这些文件查看有关系统硬件及当前正在运行进程的信息。在Linux系统中，许多工具的数据来源正是proc目录中的内容。相当于是内核空间和用户空间之间的通信窗口。

### 使用和指标

- `/proc/stat` 提供系统的CPU和任务统计信息，`top` 命令就是通过其中数据进行换算得出
- `/proc/loadavg` 保存了系统负载的平均值，其前三列分别表示最近1分钟、5分钟及15分的平均负载，平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数，它和 CPU 使用率并没有直接关系。CPU使用率是指在单位时间内CPU处在非空闲态的时间比，反映了CPU的繁忙程度。平均负载最理想的情况是等于 CPU 个数。
- `/proc/softirqs` 记录自开机以来软中断累积次数
- `/proc/interrupts` 记录自开机以来的累积中断次数
- `/proc/meminfo` 当前内存使用的统计信息
- `/proc/net/dev` 网络流入流出的统计信息，包括接收包的数量、发送包的数量，发送数据包时的错误和冲突情况等

## stress

### 简介

Linux `stress` 命令主要用来模拟系统负载较高时的场景

### 语法

```powershell
stress <options>
# 参数
-c, --cpu N  # 产生 N 个进程，每个进程都反复不停的计算随机数的平方根
-i, --io N  # 产生 N 个进程，每个进程反复调用 sync() 将内存上的内容写到硬盘上
-m, --vm N  # 产生 N 个进程，每个进程不断分配和释放内存
    --vm-bytes B  # 指定分配内存的大小
    --vm-stride B  # 不断的给部分内存赋值，让 COW(Copy On Write)发生
    --vm-hang N  # 指示每个消耗内存的进程在分配到内存后转入睡眠状态 N 秒，然后释放内存，一直重复执行这个过程
    --vm-keep  # 一直占用内存，区别于不断的释放和重新分配(默认是不断释放并重新分配内存)
-d, --hadd N  # 产生 N 个不断执行 write 和 unlink 函数的进程(创建文件，写入内容，删除文件)
    --hadd-bytes B  # 指定文件大小
-t, --timeout N  # 在 N 秒后结束程序        
--backoff N  # 等待N微妙后开始运行
-q, --quiet  # 程序在运行的过程中不输出信息
-n, --dry-run  # 输出程序会做什么而并不实际执行相关的操作
--version  # 显示版本号
-v, --verbose  # 显示详细的信息
```

## gRPC

### 简介

- 一个现代的、高性能的开源远程过程调用（RPC）框架，它可以在任何环境中运行，并高效地连接数据中心内和跨数据中心的服务
- gRPC的高性能和多语言支持使其成为微服务架构中的理想选择，适用于实时数据流的传输，如聊天应用、视频流、股票市场数据等，还有物联网场景

### 特点

- 基于**HTTP2.0**协议，支持双向流、头部压缩和多路复用，这些特性使得gRPC具有**更低的网络延迟和更高的吞吐量**
- 支持多种编程语言，如C、C++、Java、Go、Python、Ruby等，这使得它能够在**多语言协作**的分布式系统中发挥重要作用
- 序列化支持PB和JSON，**默认使用PB**，提供自动生成客户端和服务器代码的工具，大大简化开发流程，提高开发效率
- 安装简单、扩展方便（用该框架每秒可达到百万个RPC）

### 交互过程

- 在gRPC中，客户端应用程序可以直接调用不同机器上服务器应用程序的方法，就像调用本地对象一样，它基于定义服务的思想，指定可以远程调用的方法、参数、返回类型；**在服务器端**，服务器实现此接口并运行gRPC服务器来处理客户端调用；**在客户端**，客户端有一个stub存根，提供与服务器相同的方法

  ![1741869841983](D:\WeChat\WeChat Files\wxid_4njvjhupxgbc22\FileStorage\Temp\1741869841983.png)

  

- 若**使用Protocol Buffers（protobuf）作为接口定义语言**，定义严格的接口和数据结构，这有助于避免数据格式不一致的问题。gRPC 使用带特殊 gRPC 插件的 `protoc` 从 `.proto` 文件生成代码，从而可以获得生成的 gRPC 客户端和服务器代码，以及用于填充、序列化和检索消息类型的常规 pb 代码。比如下图中的2-11步全都封装起来，对用户透明

  ![1741872071247](D:\WeChat\WeChat Files\wxid_4njvjhupxgbc22\FileStorage\Temp\1741872071247.png)

  ![image-20250313213022181](C:\Users\GotGyu\AppData\Roaming\Typora\typora-user-images\image-20250313213022181.png)

### 和http协议比较

![2041a9ae2025b9f96a70ff0a04c3dad.png](6571cc310d34578820d7ee8db407a087.png)

### 高性能

介绍如何从gRPC、利用http2.0特性获得最佳性能

1. **重用 gRPC 通道**

   进行gRPC调用时，应重用通道，可以在现有的HTTP2.0连接上对调用进行多路复用，不然如果为每个gRPC调用创建一个新通道的话，每次都需要通过以下步骤创建新的HTTP2.0连接：

   - 打开套接字
   - 建立 TCP 连接
   - 协商 TLS
   - 启动 HTTP/2 连接
   - 进行 gRPC 调用

2. **连接并发**

   http2.0连接通常会限制一个连接上同时存在的最大并发流

   - 可以为具有高负载的应用的区域创建单独的gRPC通道
   - 可以使用gRPC通道池，例如创建gRPC通道列表

3. **客户端应用中的异步调用**

   - 首选调用gRPC方法时将异步编程与async,await配合使用，使用阻塞（如 `Task.Result` 或 `Task.wait()`）进行 gRPC 调用会使其他任务无法使用线程，这可能会导致线程池资源不足、性能不佳、应用程序因死锁而挂起
   - 所有 gRPC 方法类型都在 gRPC 客户端上生成异步 API

4. **负载均衡**

   - 只有两种方法，其他的负载均衡器不能与gRPC一起高效工作：

     - **客户端负载均衡**

       （没看懂）

     - **L7（应用程序）代理负载均衡**

       L7代理在一个HTTP2.0连接上接收多路复用的gRPC调用，并将它们分发到多个后端终结点上，比上一个方案简单，但是可能效率没那么高

5. **保持活动 ping**

   - 可用于在非活动期间使HTTP2.0连接保持为活动状态，如果在应用恢复活动时已准备好现有 HTTP2连接，则可以快速进行初始gRPC调用，不会因重新建立连接而导致延迟

# rust量化交易系统

## 设计思路

### 目录架构

```powershell
.
├── LICENSE
├── README.md
└── xcrypto
    ├── binance
    │   ├── Cargo.toml
    │   ├── spot
    │   │   ├── Cargo.toml
    │   │   └── src
    │   │   │   └── main.rs         # 主函数，读取配置文件，启动主线程持续接受市场数据和执行交易策略
    │   │   │   └── trade.rs        # 实现了一个spottrade交易逻辑，包含ws监听、订单处理、会话管理等功能
    │   ├── src
    │   │   ├── account.rs          # 实现一个ws客户端，用于与某个ws服务进行连接
    │   │   ├── app.rs              # 实现了一个 WebSocket 服务器，用于管理 WebSocket 连接，并与 Trade 交易逻辑进行交互
    │   │   ├── chat.rs             # Binance 交易所的 WebSocket 数据解析，通过 serde 序列化和反序列化结构体，来处理实时市场数据
    │   │   ├── handler.rs          # 实现了一个 ws 服务器的 Handler（处理器），是 ws server的核心，用于管理客户端连接、处理 WebSocket 消息，并与交易系统进行交互
    │   │   ├── lib.rs              # 定义了一个交易相关的 Rust 模块系统，并声明了一些核心的 trait（特性）用于管理市场数据、订单处理和交易行为
    │   │   ├── market.rs           # 订阅管理模块，用于处理客户端连接、订阅、取消订阅和市场数据流的转发
    │   │   ├── session.rs          # 管理用户的交易会话，包括用户的持仓信息、订单处理和消息发送
    │   │   └── subscriber.rs       # 管理用户的订阅关系，维护订阅的交易对，并处理 WebSocket 消息转发
    │   └── usdt
    │   │   ├── Cargo.toml
    │   │   └── src
    │   │   │   └── main.rs         # 和./spot差不多，另一种市场
    │   │   │   └── trade.rs
    ├── Cargo.lock
    ├── Cargo.toml
    ├── logger                      # 日志模块
    │   ├── Cargo.toml
    │   └── src
    │       └── lib.rs
    ├── pyalgo                      # python 策略模块
    │   ├── Cargo.toml
    │   ├── pyproject.toml
    │   ├── python                  # python写的策略
    │   │   └── pyalgo
    │   └── src                     # rust 提供的接口
    │       ├── chat.rs
    │       ├── constant.rs
    │       ├── lib.rs              # Rust + PyO3 绑定模块，用于提供 Python 接口，使 Python 代码可以调用 Rust 代码的功能
    │       ├── phase.rs
    │       ├── rest.rs
    │       ├── session.rs
    │       ├── subscription.rs
    │       └── ws.rs                 
    ├── src
    │   ├── chat.rs                 # 定义了一套用于金融交易的数据结构
    │   ├── error.rs                # 定义了几个error id
    │   ├── lib.rs                  # 导入        
    │   ├── parser.rs               # 封装了 serde_json 的解析功能，提供了 Parser 结构体用于管理 JSON 数据
    │   ├── position.rs             # 封装了 Position 数据的数据库操作，提供数据存取、异步操作
    │   ├── rest.rs                 # REST API客户端，用于发送http请求到binance API，并提供基础的下单/撤单
    │   └── ws.rs                   # 实现了一个基于 WebSocket 协议的通信模块，支持 客户端 和 服务端 角色
    └── target
        ├── CACHEDIR.TAG
        └── debug
```

### 模块

- 数据获取模块
  - 用 `reqwest` 定期请求API数据，解析API返回的JSON数据，提取所需字段，存到Redis或SQLite
- websocket服务模块：实时推送市场数据到客户端
  - 用 `tokio-tungstenite` 实现ws服务器
  - 支持多客户端连接，每个客户端独立订阅不同的数据
- 策略执行模块：根据市场数据执行交易策略
  - 得到市场数据，根据策略逻辑生成交易信号（比如买入或卖出），传给下一层
  - 使用 `tokio::spawn` 并行执行多策略
- 订单管理模块：处理订单生成、发送、状态更新 
  - 生成订单，监听订单状态，更新本地记录
- 会话管理模块：管理客户端连接、会话状态
  - 为每个客户端分配唯一的会话ID，记录客户端的订阅消息，在断开连接后清理会话状态
- 风控模块

![1742046300013](D:\WeChat\WeChat Files\wxid_4njvjhupxgbc22\FileStorage\Temp\1742046300013.png)

## 开发流程

1. 市场数据处理（行情网关）
   - 使用 ashares 库获取行情数据（K 线、逐笔成交、盘口等）
   - 解析数据并存储到合适的数据结构（如 struct Kline {}）
   - 提供数据存取接口（如 get_kline()）
   - 选择数据存储方式（什么数据库）
   - 设计数据库表结构，存储历史行情数据（需要吗）
   - 架构：
     - 数据获取层
     - 数据解析层
     - 数据存储层
     - 数据接口层
2. 交易系统架构
   - 账户管理
     - 维护账户资金、持仓、交易记录
     - 设计 struct Account {} 结构体，包含可用资金、持仓等信息
   - 订单管理（订单管理模块）
     - 设计 struct Order {}，包括订单类型、状态、价格、数量等
     - 订单撮合逻辑（可选择模拟交易所撮合或使用实盘 API）
     - 订单生命周期管理（Pending → Executed → Completed）
3. 交易策略开发（策略引擎）
   - 策略引擎
     - 设计策略接口 trait Strategy，允许不同策略实现
     - 示例策略：均线策略、动量策略、回归策略
   - 回测框架
     - 读取历史数据，按时间推进，模拟执行订单
     - 计算策略的收益率、最大回撤、Sharpe 比率等指标
   - 风控（风控子系统）
     - 设计风控机制，如最大亏损限制、仓位控制
4. 交易执行（交易网关、交易核心、算法交易模块）
   - 交易API
     - 连接券商或交易所 API（如 ashares 提供的交易接口）
     - 提供下单、撤单、查询订单等功能
   - WebSocket 订阅
     - 订阅实时行情数据
     - 处理市场事件，并通知策略模块

## 依赖库

### anyhow

- 用于高效且灵活的错误处理，简化错误传播

### base64

- 正确、快速、可配置的 base64 解码和编码
- 在只允许使用纯文本的情况下，Base64 可以高效地传输二进制数据

### binance

- 使用 Binance API 相关的 Rust 库，包含市场数据、交易功能等

### chrono

- 提供所有关于日期和时间的操作

  DateTime 类型默认具有时区感知功能，并具有单独的无时区感知类型。
可能产生无效或模糊日期和时间的操作会返回 Option 或 MappedLocalTime。
使用 strftime 启发的日期和时间格式化语法，可配置解析和格式化。
本地时区与操作系统的当前时区一致。
类型和操作的实现具有合理的效率。
为了限制二进制文件的大小，时区数据默认不随 chrono 一起提供。请使用配套的 Chrono-TZ 或 tzfile 获取完整的时区支持。

### clap

- 简单易用、高效且功能齐全的命令行参数解析器

### criterion

- 统计驱动的微基准测试库，为检测和估算性能改进和回归的大小提供强大的统计置信度

### crossbeam-channel

- 用于消息传递的**多生产者多消费者**通道
- 该板块可替代 `std::sync::mpsc`，具有更多功能和更好的性能
- 非常适合用于**多线程环境**下的消息传递            

### ctp2rs

- 也许未来可以用
- 对接CTP（期货）官方API，适用于期货、期权市场
- 依赖 `ctpx` C++ 绑定，目前Rust生态支持较少，需要自己维护

### log

- 轻量级日志界面

### maybe-async

- 在一个 crate 中实现同步异步版本时，大多数接口的区别仅在于 `async` `await` 关键字

### native-json

- 为 Rust 提供原生 JSON 语法，将 JSON 语法分析为原生 Rust 结构
- 可以像在 JavaScript 中一样本地声明 JSON 对象。

### reqwest*重点

- 功能丰富、易用性强的HTTP客户端库
- 异步网络库，可以提高并发性能
- 提供了：
  - 支持异步和阻塞式API
  - 灵活的请求体处理(纯文本、JSON、urlencoded、multipart)
  - 可自定义的重定向策略
  - HTTP代理支持
  - 基于系统原生TLS的HTTPS(可选使用rustls)
  - Cookie存储
  - WebAssembly(WASM)支持

### serde-json

- 通常与 `serde` 一起使用，支持 `no_std`

### sqlx

- Rust SQL 工具包，支持异步，纯Rust编写
- 支持 PostgreSQL、MySQL 和 SQLite

### tokio

- tokio 是一个异步运行时，适合高性能网络编程
- **如何利用 tokio 实现高性能网络通信：**
  - 异步编程：`async/await` 语法实现非阻塞操作，避免了线程切换的开销
  - 并发处理：使用tokio 的任务调度器，处理大量并发连接
  - 性能优化：减少锁竞争、优化内存分配、合理配置tokio的线程池

### tokio-tungstenite*重要

- 一个基于 Rust 的异步 WebSocket 库，为 Tokio 提供了非阻塞/异步的 TCP 流绑定和包装
- 支持 TLS（一种密码通信框架），可以通过特性标志启用，适用于需要安全 WebSocket (wss://) 支持的场景

### url

基于 URL 标准的 Rust URL 库

### ws

适用于 Rust 的轻量级事件驱动 WebSockets

## WebSocket

### 简介

- 基于 TCP 的一种新的应用层网络协议
- 提供一个全双工的通道，允许服务器和客户端之间实时双向通信。因此，浏览器和服务器只需要完成**一次握手**，两者之间就直接可以创建持久性的连接，并进行双向数据传输

### 特点

- 建立在 TCP 协议之上，服务器端的实现比较容易
- 与 HTTP 协议有着良好的兼容性，默认端口也是80和443，并且握手阶段采用 HTTP 协议，因此握手时不容易屏蔽，能通过各种 HTTP 代理服务器
- 数据格式比较轻量，性能开销小，通信高效
- 可以发送文本，也可以发送二进制数据
- 没有同源限制，客户端可以与任意服务器通信
- 协议标识符是ws（如果加密，则为wss），服务器网址就是 URL

### 和HTTP协议的对比

- HTTP 协议有一个缺陷：通信只能由客户端发起，不具备服务器推送能力。这种单向请求的特点，注定了如果服务器有连续的状态变化，客户端要获知就非常麻烦。我们只能使用’轮询’：每隔一段时候，就发出一个询问，了解服务器有没有新的信息。轮询的效率低，非常浪费资源
- http协议本身是没有持久通信能力的，但是我们在实际的应用中，是很需要这种能力的，所以，为了解决这些问题，WebSocket协议由此而生
- 在HTML5标准中增加了有关WebSocket协议的相关api，所以只要实现了HTML5标准的客户端，就可以与支持WebSocket协议的服务器进行全双工的持久通信

|性质|websocket|http|
|--|--|--|
|实时性能|更高，允许服务器和客户端之间实时双向通信||
|网络开销|更少，在同一个连接上双向通信|请求和响应之间需要额外的数据传输|
|通信方式|更加灵活，可以以多种方式进行通信，如消息Push、事件推送等|请求和响应一一对应|
|API|API更简洁||
|无连接|不支持无连接，连接不会在一次请求之后立即断开，消除了建立连接的开销，但是也可能导致一些资源泄漏的问题||
|应用范围|一些旧的浏览器可能不支持，且WebSocket 需要服务端支持，只有特定的服务器才能够实现 WebSocket 协议。这可能会增加系统的复杂性和部署的难度||
|兼容性|数据流格式与 HTTP 不同||

### 工作流程

- 通过已建立的TCP连接来传输数据（和http一样），体实现上是通过http协议建立通道，然后在此基础上用真正的WebSocket协议进行通信
- 握手阶段：
  - 客户端向服务端发送请求，请求建立WebSocket连接。请求中包含一个Sec-WebSocket-Key参数，用于生成WebSocket的随机密钥
  - 服务端接收到请求后，生成一个随机密钥，并使用随机密钥生成一个新的Sec-WebSocket-Accept参数
  - 客户端接收到服务端发送的新的Sec-WebSocket-Accept参数后，使用原来的随机密钥和新的Sec-WebSocket-Accept参数共同生成一个新的Sec-WebSocket-Key参数，用于加密数据传输
  - 客户端将新的Sec-WebSocket-Key参数发送给服务端，服务端接收到后，使用该参数加密数据传输
- 数据传输阶段：
  - 建立连接后，客户端和服务端就可以通过WebSocket进行实时双向通信
  - 客户端向服务端发送数据，服务端收到数据后将其转发给其他客户端
  - 服务端向客户端发送数据，客户端收到数据后进行处理
  - 过程中 WebSocket 的每条消息可能会被切分成多个数据帧（最小单位）。发送端会将消息切割成多个帧发送给接收端，接收端接收消息帧，并将关联的帧重新组装成完整的消息
  - 发送方 -> 接收方：ping
  - 接收方 -> 发送方：pong
  - ping 、pong 的操作，对应的是 WebSocket 的两个控制帧
- 关闭阶段： 
  - 当不再需要WebSocket连接时，可以关闭
  - 客户端向服务端发送关闭请求，请求中包含一个WebSocket的随机密钥
  - 服务端接收到关闭请求后，向客户端发送关闭响应，关闭响应中包含服务端生成的随机密钥
  - 客户端收到关闭响应后，关闭WebSocket连接
- 数据帧和控制帧
  - 数据帧
    - 主要包括两个部分：帧头和有效载荷
    - 帧头包括四个部分：fin、rsv1、rsv2、rsv3、opcode、masked 和 payload_length。其中，fin 表示数据帧的结束标志，rsv1、rsv2、rsv3 表示保留字段，opcode 表示数据帧的类型，masked 表示是否进行掩码处理，payload_length 表示有效载荷的长度
    - 有效载荷是数据帧中实际的数据部分，它由客户端和服务端进行数据传输
  - 控制帧
    - Ping 帧：Ping 帧用于测试客户端和服务端之间的连接状态，客户端向服务端发送 Ping 帧，服务端收到后需要向客户端发送 Pong 帧进行响应。
    - Pong 帧：Pong 帧用于响应客户端的 Ping 帧，它用于测试客户端和服务端之间的连接状态。
    - Close 帧：Close 帧用于关闭客户端和服务端之间的连接，它包括四个部分：fin、rsv1、rsv2、rsv3、opcode、masked 和 payload_length。其中，opcode 的值为 8，表示 Close 帧。

### 应用场景

- **即时**聊天通信
- 多玩家游戏
- 在线协同编辑/编辑
- **实时**数据流的拉取与推送
- 体育/游戏实况
- **实时**地图位置
- 即时Web应用程序：即时Web应用程序使用一个Web套接字在客户端显示数据，这些数据由后端服务器连续发送。在WebSocket中，数据被连续推送/传输到已经打开的同一连接中，这就是为什么WebSocket更快并提高了应用程序性能的原因。例如在交易网站或比特币交易中，这是最不稳定的事情，它用于显示价格波动，数据被后端服务器使用Web套接字通道连续推送到客户端
- 游戏应用程序：在游戏应用程序中，你可能会注意到，服务器会持续接收数据，而不会刷新用户界面。屏幕上的用户界面会自动刷新，而且不需要建立新的连接，因此在WebSocket游戏应用程序中非常有帮助
- 聊天应用程序：聊天应用程序仅使用WebSocket建立一次连接，便能在订阅户之间交换，发布和广播消息。它重复使用相同的WebSocket连接，用于发送和接收消息以及一对一的消息传输
- 不能使用WebSocket的场景：如果要获取旧数据，或者只想获取一次数据供应用程序使用，则应该使用HTTP协议，不需要很频繁或仅获取一次的数据可以通过简单的HTTP请求查询

## REST

客户端和服务端通信的一组规则，例如客户端向服务端请求访问指定数据、或在服务端保存数据服务端响应客户端请求过程的过程

### 限制条件

- REST是**无状态**的：通讯过程中，服务端不会保存客户端的上下文信息，即每个请求都需要携带必要的数据
